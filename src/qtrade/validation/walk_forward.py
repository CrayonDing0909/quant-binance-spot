"""
Walk-Forward Analysis & Parameter Sensitivity

æä¾›ï¼š
- Expanding-window Walk-Forward é©—è­‰ï¼ˆå«æ­£ç¢º warmupï¼‰
- åƒæ•¸æ•æ„Ÿæ€§åˆ†æ
- éæ“¬åˆæª¢æ¸¬
- Walk-Forward çµæœæ‘˜è¦çµ±è¨ˆ
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Walk-Forward Analysisï¼ˆExpanding Windowï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def walk_forward_analysis(
    symbol: str,
    data_path: Path,
    cfg: dict,
    n_splits: int = 5,
    data_dir: Path | None = None,
) -> pd.DataFrame:
    """
    Expanding-window Walk-Forward é©—è­‰ï¼ˆå«æ­£ç¢º warmupï¼‰

    å°‡æ•¸æ“šç­‰åˆ†æˆ (n_splits + 1) å€‹å€é–“ï¼š
      Split 1: train = å€é–“[0]ï¼Œ           test = å€é–“[1]
      Split 2: train = å€é–“[0:1]ï¼ˆç´¯åŠ ï¼‰ï¼Œ  test = å€é–“[2]
      ...
      Split N: train = å€é–“[0:N-1]ï¼Œ       test = å€é–“[N]

    **é—œéµä¿®æ­£**ï¼šæ¸¬è©¦é›†å›æ¸¬æ™‚ï¼Œç­–ç•¥å¾ bar 0 é–‹å§‹è·‘ï¼ˆç¢ºä¿æŒ‡æ¨™ warmupï¼‰ï¼Œ
    ä½†åªç”¨ test å€é–“çš„äº¤æ˜“è¨ˆç®—ç¸¾æ•ˆï¼ˆåˆ©ç”¨ _apply_date_filterï¼‰ã€‚

    Args:
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ
        data_path: æ•¸æ“šæ–‡ä»¶è·¯å¾‘
        cfg: å›æ¸¬é…ç½®å­—å…¸ï¼ˆto_backtest_dict() çš„æ ¼å¼ï¼‰
        n_splits: åˆ†å‰²æ•¸é‡ï¼ˆé è¨­ 5ï¼Œç”¢ç”Ÿ 6 å€‹å€é–“ï¼‰
        data_dir: æ•¸æ“šæ ¹ç›®éŒ„ï¼ˆç”¨æ–¼è¼‰å…¥ funding rateï¼‰

    Returns:
        åŒ…å«æ¯å€‹ split çµæœçš„ DataFrame
    """
    from ..data.storage import load_klines
    from ..backtest.run_backtest import run_symbol_backtest

    df = load_klines(data_path)
    total_len = len(df)

    # Walk-forward è‡ªè¡Œç®¡ç†æ•¸æ“šåˆ‡ç‰‡ï¼Œç§»é™¤ cfg ä¸­çš„ start/end é¿å…æ—¥æœŸéæ¿¾è¡çª
    wf_cfg = {k: v for k, v in cfg.items() if k not in ("start", "end")}
    strategy_name = wf_cfg.get("strategy_name")

    # ç­‰åˆ†æˆ n_splits+1 å€‹å€é–“
    n_segments = n_splits + 1
    seg_len = total_len // n_segments
    if seg_len < 500:  # è‡³å°‘ 500 æ ¹ barï¼ˆ1h Ã— 500 â‰ˆ 21 å¤©ï¼‰
        print(f"  âš ï¸  æ•¸æ“šå¤ªçŸ­ï¼Œæ¯æ®µåªæœ‰ {seg_len} æ ¹ barï¼Œè‡ªå‹•ç¸®æ¸› splits")
        n_segments = max(2, total_len // 500)
        n_splits = n_segments - 1
        seg_len = total_len // n_segments

    print(f"\n  ğŸ“Š Walk-Forward è¨­å®š:")
    print(f"     æ•¸æ“šé‡: {total_len:,} bars ({df.index[0].strftime('%Y-%m-%d')} â†’ {df.index[-1].strftime('%Y-%m-%d')})")
    print(f"     Splits: {n_splits} (æ¯æ®µ ~{seg_len:,} bars â‰ˆ {seg_len/24:.0f} å¤©)")
    print()

    results = []

    for i in range(n_splits):
        train_end = seg_len * (i + 1)
        test_start = train_end
        test_end = min(seg_len * (i + 2), total_len)

        if test_end - test_start < 200:
            break

        period_train = f"{df.index[0].strftime('%Y-%m')} â†’ {df.index[train_end-1].strftime('%Y-%m')}"
        period_test = f"{df.index[test_start].strftime('%Y-%m')} â†’ {df.index[test_end-1].strftime('%Y-%m')}"
        print(f"  Split {i+1}/{n_splits}: train {period_train}  |  test {period_test}", end="")

        # â”€â”€ Train å›æ¸¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # æ•¸æ“šï¼š[0, train_end)ï¼Œç„¡æ—¥æœŸéæ¿¾
        train_df = df.iloc[:train_end].copy()
        train_tmp = data_path.parent / f"_wf_{symbol}_train_{i}.parquet"
        train_df.to_parquet(train_tmp)

        try:
            train_res = run_symbol_backtest(
                symbol, train_tmp, wf_cfg, strategy_name,
                data_dir=data_dir,
            )
            train_stats = train_res.stats
        except Exception as e:
            print(f" âŒ train failed: {e}")
            train_tmp.unlink(missing_ok=True)
            continue

        # â”€â”€ Test å›æ¸¬ï¼ˆå« warmupï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # æ•¸æ“šï¼š[0, test_end)ï¼ˆåŒ…å« train å€é–“ä½œç‚º warmupï¼‰
        # æ—¥æœŸéæ¿¾ï¼šåªå– [test_start, test_end) çš„ç¸¾æ•ˆ
        #
        # é€™æ¨£åšçš„å¥½è™•ï¼š
        # 1. ç­–ç•¥å¾ bar 0 é–‹å§‹è·‘ï¼ŒæŒ‡æ¨™æœ‰å®Œæ•´ warmup
        # 2. _apply_date_filter åªæˆªå– OOS å€é–“çš„äº¤æ˜“ç¸¾æ•ˆ
        # 3. ä¸æœƒæœ‰ look-ahead biasï¼ˆç­–ç•¥åªçœ‹åˆ° test_end ä¹‹å‰çš„æ•¸æ“šï¼‰
        test_full_df = df.iloc[:test_end].copy()
        test_tmp = data_path.parent / f"_wf_{symbol}_test_{i}.parquet"
        test_full_df.to_parquet(test_tmp)

        test_cfg = {**wf_cfg}
        test_cfg["start"] = str(df.index[test_start])
        test_cfg["end"] = str(df.index[test_end - 1])

        try:
            test_res = run_symbol_backtest(
                symbol, test_tmp, test_cfg, strategy_name,
                data_dir=data_dir,
            )
            test_stats = test_res.stats
        except Exception as e:
            print(f" âŒ test failed: {e}")
            train_tmp.unlink(missing_ok=True)
            test_tmp.unlink(missing_ok=True)
            continue

        # å¦‚æœæœ‰ adjusted_statsï¼ˆå« funding æˆæœ¬ï¼‰ï¼Œå„ªå…ˆä½¿ç”¨
        # BacktestResult æ˜¯ dataclassï¼Œä¸èƒ½ç”¨ .get()
        train_adj = getattr(train_res, "adjusted_stats", None)
        test_adj = getattr(test_res, "adjusted_stats", None)

        # adjusted_stats æ˜¯ dictï¼›stats æ˜¯ pd.Series â€” å…©è€…éƒ½æ”¯æ´ .get()
        train_ret = (train_adj or train_stats).get("Total Return [%]", 0)
        test_ret = (test_adj or test_stats).get("Total Return [%]", 0)
        train_sharpe = (train_adj or train_stats).get("Sharpe Ratio", 0)
        test_sharpe = (test_adj or test_stats).get("Sharpe Ratio", 0)
        train_mdd = (train_adj or train_stats).get("Max Drawdown [%]", 0)
        test_mdd = (test_adj or test_stats).get("Max Drawdown [%]", 0)
        train_trades = train_stats.get("Total Trades", 0)
        test_trades = test_stats.get("Total Trades", 0)

        cost_tag = " ğŸ’°" if train_adj or test_adj else ""
        print(f"  â†’ train: {train_ret:+.1f}% (SR {train_sharpe:.2f})"
              f"  test: {test_ret:+.1f}% (SR {test_sharpe:.2f}){cost_tag}")

        results.append({
            "split": i + 1,
            "train_period": period_train,
            "test_period": period_test,
            "train_bars": train_end,
            "test_bars": test_end - test_start,
            "train_return": train_ret,
            "test_return": test_ret,
            "train_sharpe": train_sharpe,
            "test_sharpe": test_sharpe,
            "train_dd": train_mdd,
            "test_dd": test_mdd,
            "train_trades": train_trades,
            "test_trades": test_trades,
        })

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        train_tmp.unlink(missing_ok=True)
        test_tmp.unlink(missing_ok=True)

    return pd.DataFrame(results)


def walk_forward_summary(wf_results: pd.DataFrame) -> dict:
    """
    Walk-Forward çµæœæ‘˜è¦çµ±è¨ˆ

    è¨ˆç®— Sharpe è¡°é€€ç‡ã€OOS ä¸€è‡´æ€§ã€å¹´é–“ç©©å®šæ€§ç­‰ã€‚

    Args:
        wf_results: walk_forward_analysis è¿”å›çš„ DataFrame

    Returns:
        {
            "n_splits": int,
            "avg_train_sharpe": float,
            "avg_test_sharpe": float,
            "std_test_sharpe": float,
            "sharpe_degradation_pct": float,  # Sharpe è¡°é€€ç‡ (%)
            "oos_positive_pct": float,         # æ¸¬è©¦é›† Sharpe > 0 çš„æ¯”ä¾‹
            "oos_profitable_pct": float,       # æ¸¬è©¦é›† Return > 0 çš„æ¯”ä¾‹
            "worst_test_sharpe": float,
            "best_test_sharpe": float,
            "avg_test_return": float,
            "avg_test_dd": float,
            "is_robust": bool,                 # Sharpe è¡°é€€ < 30% ä¸” OOS å…¨éƒ¨ > 0
            "summary_text": str,               # äººé¡å¯è®€æ‘˜è¦
        }
    """
    if wf_results.empty:
        return {"n_splits": 0, "summary_text": "âŒ æ²’æœ‰æˆåŠŸçš„ Walk-Forward split"}

    n = len(wf_results)
    avg_train_sr = wf_results["train_sharpe"].mean()
    avg_test_sr = wf_results["test_sharpe"].mean()
    std_test_sr = wf_results["test_sharpe"].std()

    # Sharpe è¡°é€€ç‡
    if abs(avg_train_sr) > 0.01:
        degradation_pct = (avg_train_sr - avg_test_sr) / abs(avg_train_sr) * 100
    else:
        degradation_pct = 0.0

    # OOS ä¸€è‡´æ€§
    oos_positive = (wf_results["test_sharpe"] > 0).mean() * 100
    oos_profitable = (wf_results["test_return"] > 0).mean() * 100

    # ç©©å¥æ€§åˆ¤æ–·
    is_robust = degradation_pct < 30 and oos_positive == 100

    # æ§‹å»ºæ‘˜è¦æ–‡å­—
    lines = [
        f"  === éæ“¬åˆé¢¨éšªè©•ä¼° ===",
        f"  å¹³å‡ Train Sharpe:  {avg_train_sr:.2f}",
        f"  å¹³å‡ Test Sharpe:   {avg_test_sr:.2f} (Â±{std_test_sr:.2f})",
        f"  Sharpe è¡°é€€ç‡:      {degradation_pct:.1f}%",
        f"  OOS Sharpe > 0:     {oos_positive:.0f}% ({int(oos_positive/100*n)}/{n} splits)",
        f"  OOS ç›ˆåˆ©:           {oos_profitable:.0f}% ({int(oos_profitable/100*n)}/{n} splits)",
        f"  æœ€å·® Test Sharpe:   {wf_results['test_sharpe'].min():.2f}",
        f"  æœ€ä½³ Test Sharpe:   {wf_results['test_sharpe'].max():.2f}",
        f"  Test Sharpe ç¯„åœ:   {wf_results['test_sharpe'].max() - wf_results['test_sharpe'].min():.2f}x",
        "",
    ]

    if is_robust:
        lines.append(f"  âœ… é€šéï¼šè¡°é€€ < 30% ä¸” OOS å…¨æ­£ â†’ ä½éæ“¬åˆé¢¨éšª")
    elif degradation_pct < 50 and oos_positive >= 80:
        lines.append(f"  âš ï¸  ä¸­åº¦é¢¨éšªï¼šè¡°é€€ {degradation_pct:.0f}%ï¼Œå»ºè­°é€²ä¸€æ­¥ç”¨ CPCV é©—è­‰")
    else:
        lines.append(f"  âŒ é«˜é¢¨éšªï¼šè¡°é€€ {degradation_pct:.0f}%ï¼ŒOOS æ­£å‘ {oos_positive:.0f}% â†’ å¯èƒ½éæ“¬åˆ")

    return {
        "n_splits": n,
        "avg_train_sharpe": avg_train_sr,
        "avg_test_sharpe": avg_test_sr,
        "std_test_sharpe": std_test_sr,
        "sharpe_degradation_pct": degradation_pct,
        "oos_positive_pct": oos_positive,
        "oos_profitable_pct": oos_profitable,
        "worst_test_sharpe": wf_results["test_sharpe"].min(),
        "best_test_sharpe": wf_results["test_sharpe"].max(),
        "avg_test_return": wf_results["test_return"].mean(),
        "avg_test_dd": wf_results["test_dd"].mean(),
        "is_robust": is_robust,
        "summary_text": "\n".join(lines),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åƒæ•¸æ•æ„Ÿæ€§åˆ†æ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parameter_sensitivity_analysis(
    symbol: str,
    data_path: Path,
    base_cfg: dict,
    param_grid: Dict[str, List],
    data_dir: Path | None = None,
) -> pd.DataFrame:
    """
    åƒæ•¸æ•æ„Ÿæ€§åˆ†æ - æª¢æ¸¬éæ“¬åˆ
    
    æ¸¬è©¦ä¸åŒåƒæ•¸çµ„åˆçš„è¡¨ç¾ï¼Œæª¢æŸ¥ç­–ç•¥å°åƒæ•¸è®ŠåŒ–çš„æ•æ„Ÿåº¦ã€‚
    é«˜æ•æ„Ÿåº¦å¯èƒ½è¡¨ç¤ºéæ“¬åˆã€‚
    
    Args:
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ
        data_path: æ•¸æ“šæ–‡ä»¶è·¯å¾‘
        base_cfg: åŸºç¤é…ç½®
        param_grid: åƒæ•¸ç¶²æ ¼ {åƒæ•¸å: [å€¼åˆ—è¡¨]}
        data_dir: æ•¸æ“šæ ¹ç›®éŒ„ï¼ˆç”¨æ–¼è¼‰å…¥ funding rateï¼‰
        
    Returns:
        åŒ…å«æ‰€æœ‰åƒæ•¸çµ„åˆçµæœçš„ DataFrame
    """
    import itertools
    from ..backtest.run_backtest import run_symbol_backtest

    param_names = list(param_grid.keys())
    param_values = list(param_grid.values())
    combos = list(itertools.product(*param_values))
    total = len(combos)

    results = []

    for idx, combo in enumerate(combos, 1):
        params = dict(zip(param_names, combo))
        cfg = base_cfg.copy()
        cfg["strategy_params"] = {**base_cfg["strategy_params"], **params}

        try:
            res = run_symbol_backtest(
                symbol, data_path, cfg, cfg.get("strategy_name"),
                data_dir=data_dir,
            )
            stats = res.stats
        except Exception as e:
            print(f"  âš ï¸  {params} failed: {e}")
            continue

        result = {name: val for name, val in zip(param_names, combo)}
        result.update({
            "total_return": stats.get("Total Return [%]", 0),
            "sharpe_ratio": stats.get("Sharpe Ratio", 0),
            "max_drawdown": stats.get("Max Drawdown [%]", 0),
            "win_rate": stats.get("Win Rate [%]", 0),
            "total_trades": stats.get("Total Trades", 0),
        })
        results.append(result)

        if idx % 5 == 0 or idx == total:
            print(f"  é€²åº¦: {idx}/{total} ({idx/total*100:.0f}%)")

    return pd.DataFrame(results)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# éæ“¬åˆæª¢æ¸¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_overfitting(
    train_metrics: pd.Series,
    test_metrics: pd.Series,
    threshold: float = 0.3,
) -> Dict[str, bool]:
    """
    æª¢æ¸¬éæ“¬åˆæŒ‡æ¨™
    
    æ¯”è¼ƒè¨“ç·´é›†å’Œæ¸¬è©¦é›†çš„ç¸¾æ•ˆæŒ‡æ¨™ï¼Œæª¢æ¸¬æ˜¯å¦å­˜åœ¨éæ“¬åˆã€‚
    
    Args:
        train_metrics: è¨“ç·´é›†ç¸¾æ•ˆæŒ‡æ¨™
        test_metrics: æ¸¬è©¦é›†ç¸¾æ•ˆæŒ‡æ¨™
        threshold: è¡°é€€é–¾å€¼ï¼ˆè¶…éæ­¤æ¯”ä¾‹è¦–ç‚ºéæ“¬åˆï¼‰
        
    Returns:
        åŒ…å«å„é …éæ“¬åˆæª¢æ¸¬çµæœçš„å­—å…¸
    """
    warnings = {}

    train_return = train_metrics.get("Total Return [%]", 0)
    test_return = test_metrics.get("Total Return [%]", 0)
    if train_return > 0:
        return_drop = (train_return - test_return) / abs(train_return)
        warnings["return_drop"] = return_drop > threshold

    train_sharpe = train_metrics.get("Sharpe Ratio", 0)
    test_sharpe = test_metrics.get("Sharpe Ratio", 0)
    if train_sharpe > 0:
        sharpe_drop = (train_sharpe - test_sharpe) / abs(train_sharpe)
        warnings["sharpe_drop"] = sharpe_drop > threshold

    train_dd = abs(train_metrics.get("Max Drawdown [%]", 0))
    test_dd = abs(test_metrics.get("Max Drawdown [%]", 0))
    if train_dd > 0:
        dd_increase = (test_dd - train_dd) / train_dd
        warnings["drawdown_increase"] = dd_increase > threshold

    warnings["overfitting_risk"] = any(warnings.values())

    return warnings
