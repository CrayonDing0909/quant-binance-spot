from __future__ import annotations
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional
import logging
import warnings
import numpy as np
import pandas as pd
import vectorbt as vbt

from ..strategy.base import StrategyContext
from ..strategy import get_strategy
from ..data.storage import load_klines
from ..data.quality import validate_data_quality, clean_data
from ..risk.risk_limits import RiskLimits, apply_risk_limits
from .metrics import benchmark_buy_and_hold
from .costs import (
    compute_funding_costs,
    adjust_equity_for_funding,
    compute_adjusted_stats,
    compute_volume_slippage,
    FundingCostResult,
    SlippageResult,
)
from ..data.funding_rate import (
    load_funding_rates,
    get_funding_rate_path,
    align_funding_to_klines,
)

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BacktestResult â€” æ¨™æº–åŒ–å›æ¸¬è¼¸å‡ºï¼ˆå–ä»£ raw dictï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class BacktestResult:
    """
    æ¨™æº–åŒ–çš„å›æ¸¬çµæœã€‚

    æ‰€æœ‰å›æ¸¬å…¥å£ï¼ˆsingle / portfolio / validation / kellyï¼‰éƒ½è¿”å›é€™å€‹ç‰©ä»¶ï¼Œ
    ç¢ºä¿æˆæœ¬æ¨¡å‹ä¸€è‡´ã€æ¬„ä½ä¸éºæ¼ã€‚
    """
    # â”€â”€ æ ¸å¿ƒ â”€â”€
    pf: object                          # vbt.Portfolioï¼ˆç­–ç•¥ï¼‰
    pf_bh: object                       # vbt.Portfolioï¼ˆBuy & Hold åŸºæº–ï¼‰
    stats: object                       # pf.stats() åŸå§‹çµ±è¨ˆ
    df: pd.DataFrame                    # K ç·š DataFrameï¼ˆå·²éæ¿¾ï¼‰
    pos: pd.Series                      # æŒå€‰åºåˆ—

    # â”€â”€ æˆæœ¬æ¨¡å‹ â”€â”€
    funding_cost: FundingCostResult | None = None
    slippage_result: SlippageResult | None = None

    # â”€â”€ èª¿æ•´å¾Œç¸¾æ•ˆï¼ˆå« funding æ‰£é™¤ï¼‰â”€â”€
    adjusted_stats: dict | None = None
    adjusted_equity: pd.Series | None = None

    # â”€â”€ æˆæœ¬æ¨¡å‹é…ç½®æ——æ¨™ï¼ˆç”¨æ–¼å¯©è¨ˆï¼‰â”€â”€
    funding_rate_enabled: bool = False
    slippage_model_enabled: bool = False

    def equity(self) -> pd.Series:
        """å–å¾—ç­–ç•¥è³‡é‡‘æ›²ç·šï¼ˆå„ªå…ˆç”¨ adjustedï¼Œæ²’æœ‰å‰‡ç”¨åŸå§‹ï¼‰"""
        if self.adjusted_equity is not None:
            return self.adjusted_equity
        return self.pf.value()

    def total_return_pct(self) -> float:
        """ç¸½å›å ±ç‡ %ï¼ˆå«æˆæœ¬èª¿æ•´ï¼‰"""
        if self.adjusted_stats:
            return self.adjusted_stats.get("Total Return [%]", 0.0)
        return self.stats.get("Total Return [%]", 0.0)

    def sharpe(self) -> float:
        """Sharpe Ratioï¼ˆå«æˆæœ¬èª¿æ•´ï¼‰"""
        if self.adjusted_stats:
            return self.adjusted_stats.get("Sharpe Ratio", 0.0)
        return self.stats.get("Sharpe Ratio", 0.0)

    def max_drawdown_pct(self) -> float:
        """Max Drawdown %ï¼ˆå«æˆæœ¬èª¿æ•´ï¼‰"""
        if self.adjusted_stats:
            return self.adjusted_stats.get("Max Drawdown [%]", 0.0)
        return abs(self.stats.get("Max Drawdown [%]", 0.0))

    def cost_summary(self) -> str:
        """æˆæœ¬æ¨¡å‹æ‘˜è¦å­—ä¸²ï¼ˆç”¨æ–¼æ—¥èªŒ/å ±å‘Šï¼‰"""
        parts = []
        if self.funding_rate_enabled:
            if self.funding_cost:
                parts.append(
                    f"FR: ${self.funding_cost.total_cost:,.0f} "
                    f"({self.funding_cost.total_cost_pct*100:.2f}%)"
                )
            else:
                parts.append("FR: enabled (no data)")
        else:
            parts.append("FR: OFF")

        if self.slippage_model_enabled:
            if self.slippage_result:
                parts.append(
                    f"Slip: avg {self.slippage_result.avg_slippage_bps:.1f}bps"
                )
            else:
                parts.append("Slip: enabled (no data)")
        else:
            parts.append("Slip: fixed")

        return " | ".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®å®‰å…¨é©—è­‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_backtest_config(cfg: dict) -> None:
    """
    æª¢æŸ¥å›æ¸¬é…ç½®çš„å®‰å…¨æ€§ï¼Œå°å¯ç–‘é…ç½®ç™¼å‡ºè­¦å‘Šã€‚

    é€™å€‹å‡½æ•¸åœ¨æ¯æ¬¡ run_symbol_backtest é–‹é ­å‘¼å«ï¼Œç¢ºä¿ä½¿ç”¨è€…ä¸æœƒ
    ä¸å°å¿ƒè·‘å‡ºã€Œå¿«æ¨‚è¡¨ã€ã€‚

    è¦å‰‡ï¼š
    1. futures + funding_rate æœªå•Ÿç”¨ â†’ WARNING
    2. futures + slippage_model æœªå•Ÿç”¨ â†’ WARNING
    3. ç¼ºå°‘ funding_rate / slippage_model éµ â†’ WARNINGï¼ˆå¯èƒ½æ˜¯æ‰‹å‹•å»ºæ§‹çš„ dictï¼‰
    """
    market_type = cfg.get("market_type", "spot")

    if market_type != "futures":
        return  # Spot ä¸éœ€è¦ funding rate / volume slippage æª¢æŸ¥

    # â”€â”€ Funding Rate â”€â”€
    fr_cfg = cfg.get("funding_rate")
    if fr_cfg is None:
        warnings.warn(
            "âš ï¸  Futures å›æ¸¬ç¼ºå°‘ 'funding_rate' é…ç½®ï¼"
            "çµæœå°‡ä¸åŒ…å« funding æˆæœ¬ï¼Œå¯èƒ½åš´é‡é«˜ä¼°æ”¶ç›Šã€‚"
            "è«‹ç”¨ cfg.to_backtest_dict() ç”¢ç”Ÿé…ç½®ï¼Œæˆ–æ‰‹å‹•åŠ å…¥ "
            "funding_rate: {enabled: true}ã€‚",
            UserWarning,
            stacklevel=3,
        )
    elif not fr_cfg.get("enabled", False):
        warnings.warn(
            "âš ï¸  Futures å›æ¸¬ funding_rate.enabled=falseï¼"
            "Funding rate å¹´åŒ–æˆæœ¬ç´„ 5-15%ï¼Œé—œé–‰æœƒåš´é‡é«˜ä¼°æ”¶ç›Šã€‚"
            "å¦‚éœ€å¿«é€Ÿè¿­ä»£ï¼Œè«‹ä½¿ç”¨ --simple flag æ˜ç¢ºæ¨™è¨˜ã€‚",
            UserWarning,
            stacklevel=3,
        )

    # â”€â”€ Slippage Model â”€â”€
    sm_cfg = cfg.get("slippage_model")
    if sm_cfg is None:
        warnings.warn(
            "âš ï¸  Futures å›æ¸¬ç¼ºå°‘ 'slippage_model' é…ç½®ï¼"
            "å°‡ä½¿ç”¨å›ºå®šæ»‘é»ï¼Œå°å¹£ç¨®å¯èƒ½åš´é‡ä½ä¼°å¯¦éš›æ»‘é»ã€‚"
            "è«‹ç”¨ cfg.to_backtest_dict() ç”¢ç”Ÿé…ç½®ã€‚",
            UserWarning,
            stacklevel=3,
        )
    elif not sm_cfg.get("enabled", False):
        logger.info(
            "â„¹ï¸  Volume slippage model æœªå•Ÿç”¨ï¼Œä½¿ç”¨å›ºå®š slippage_bpsã€‚"
            "å¦‚éœ€æ›´ç²¾ç¢ºçš„æˆæœ¬ä¼°ç®—ï¼Œè¨­å®š slippage_model.enabled=trueã€‚"
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Shared constants â€” æ‰€æœ‰å›æ¸¬ç›¸é—œæ¨¡çµ„å…±ç”¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# æˆ‘å€‘çš„ direction â†’ vectorbt direction æ˜ å°„
VBT_DIRECTION_MAP: dict[str, str] = {
    "both": "both",
    "long_only": "longonly",
    "short_only": "shortonly",
}


def to_vbt_direction(direction: str) -> str:
    """å°‡æˆ‘å€‘çš„ direction å­—ä¸²è½‰ç‚º vectorbt æ¥å—çš„æ ¼å¼"""
    return VBT_DIRECTION_MAP.get(direction, "longonly")


def clip_positions_by_direction(
    pos: pd.Series,
    market_type: str,
    direction: str,
) -> pd.Series:
    """
    æ ¹æ“š market_type / direction éæ¿¾æŒå€‰ä¿¡è™Ÿ
    
    - spot / long_only  â†’ clip æ‰åšç©ºä¿¡è™Ÿ
    - short_only        â†’ è½‰æ›ç¬¦è™Ÿè®“ vectorbt shortonly æ­£ç¢ºé‹ä½œ
    - both              â†’ ä¸åšè™•ç†
    """
    if market_type == "spot" or direction == "long_only":
        return pos.clip(lower=0.0)
    elif direction == "short_only":
        # vectorbt shortonly: size>0 = é–‹ç©º, size<0 = å¹³ç©º
        # ç­–ç•¥çš„ pos=-1 è¡¨ç¤ºåšç©º â†’ è½‰æ›ç‚º +1
        return (-pos).clip(lower=0.0)
    return pos  # "both": ä¿ç•™ [-1, 1]


def _bps_to_pct(bps: float) -> float:
    return bps / 10_000.0


def _resolve_backtest_params(cfg: dict, **kwargs) -> dict:
    """
    å¾ cfg dict + explicit kwargs è§£æå›æ¸¬åƒæ•¸
    
    explicit kwargs å„ªå…ˆï¼ˆå¦‚æœå‚³å…¥é None å€¼ï¼‰ï¼Œå¦å‰‡ fallback åˆ° cfg dictã€‚
    é€™æ¨£ç„¡è«–å‘¼å«è€…æ˜¯ç”¨ explicit args é‚„æ˜¯ cfg dict éƒ½èƒ½æ­£ç¢ºé‹ä½œã€‚
    """
    return {
        "market_type": kwargs.get("market_type") or cfg.get("market_type", "spot"),
        "direction": kwargs.get("direction") or cfg.get("direction", "both"),
        "validate_data": kwargs.get("validate_data") if kwargs.get("validate_data") is not None else cfg.get("validate_data", True),
        "clean_data_before": kwargs.get("clean_data_before") if kwargs.get("clean_data_before") is not None else cfg.get("clean_data_before", True),
        "start": kwargs.get("start") or cfg.get("start"),
        "end": kwargs.get("end") or cfg.get("end"),
    }


def _apply_date_filter(
    df: pd.DataFrame,
    pos: pd.Series,
    start: str | None,
    end: str | None,
) -> tuple[pd.DataFrame, pd.Series]:
    """
    æ ¹æ“š start / end æ—¥æœŸéæ¿¾æ•¸æ“šå’ŒæŒå€‰ä¿¡è™Ÿ
    
    ç­–ç•¥åœ¨å®Œæ•´æ•¸æ“šä¸Šè¨ˆç®—ï¼ˆç¢ºä¿æŒ‡æ¨™ warmup æ­£ç¢ºï¼‰ï¼Œ
    ä¹‹å¾Œåªæˆªå– [start, end] å€é–“é€å…¥ VBT å›æ¸¬ã€‚
    
    é€™æ¨£åšçš„å¥½è™•ï¼š
    1. æŒ‡æ¨™ä¸æœƒæœ‰ NaN warmup å•é¡Œ
    2. å›æ¸¬çµæœåªåæ˜ æŒ‡å®šæ™‚é–“ç¯„åœ
    3. Total Return / Sharpe / MDD ç­‰æŒ‡æ¨™æ›´ç²¾ç¢º
    """
    if start is None and end is None:
        return df, pos
    
    original_len = len(df)
    
    if start is not None:
        start_ts = pd.Timestamp(start, tz="UTC") if df.index.tz is not None else pd.Timestamp(start)
        mask = df.index >= start_ts
        df = df.loc[mask]
        pos = pos.loc[mask]
    
    if end is not None:
        end_ts = pd.Timestamp(end, tz="UTC") if df.index.tz is not None else pd.Timestamp(end)
        mask = df.index <= end_ts
        df = df.loc[mask]
        pos = pos.loc[mask]
    
    if len(df) < original_len:
        logger.info(
            f"ğŸ“… æ—¥æœŸéæ¿¾: {original_len} â†’ {len(df)} bars "
            f"({df.index[0].strftime('%Y-%m-%d')} â†’ {df.index[-1].strftime('%Y-%m-%d')})"
        )
    
    return df, pos


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ³¢å‹•ç‡ç›®æ¨™å€‰ä½ç¸®æ”¾
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _apply_vol_scaling(
    pos: pd.Series,
    df: pd.DataFrame,
    target_vol: float = 0.15,
    vol_lookback: int = 168,
    max_scale: float = 2.0,
    min_scale: float = 0.1,
    interval: str = "1h",
) -> pd.Series:
    """
    æ ¹æ“šå¯¦ç¾æ³¢å‹•ç‡åå‘ç¸®æ”¾å€‰ä½ï¼ˆVolatility Targetingï¼‰

    é«˜æ³¢å‹•æœŸ â†’ é™ä½å€‰ä½ï¼Œä½æ³¢å‹•æœŸ â†’ æé«˜å€‰ä½ï¼ˆä½†ä¸è¶…é max_scaleï¼‰
    
    å…¬å¼: scale = target_vol / realized_vol
    
    Args:
        pos: åŸå§‹ä¿¡è™Ÿ [-1, 1]
        df: K ç·š DataFrameï¼ˆéœ€è¦ close æ¬„ä½ï¼‰
        target_vol: ç›®æ¨™å¹´åŒ–æ³¢å‹•ç‡ï¼ˆé è¨­ 15%ï¼‰
        vol_lookback: æ³¢å‹•ç‡è¨ˆç®—å›çœ‹æœŸï¼ˆbar æ•¸ï¼‰
        max_scale: æœ€å¤§ç¸®æ”¾å€æ•¸
        min_scale: æœ€å°ç¸®æ”¾å€æ•¸
        interval: æ™‚é–“é–“éš”ï¼ˆç”¨æ–¼å¹´åŒ–ï¼‰
    
    Returns:
        ç¸®æ”¾å¾Œçš„å€‰ä½ä¿¡è™Ÿï¼ˆé€£çºŒå€¼ï¼‰
    """
    # æ ¹æ“š interval æ±ºå®šå¹´åŒ–å› å­
    annualize_factors = {
        "1m": np.sqrt(525_600),
        "5m": np.sqrt(105_120),
        "15m": np.sqrt(35_040),
        "1h": np.sqrt(8_760),
        "4h": np.sqrt(2_190),
        "1d": np.sqrt(365),
    }
    annualize = annualize_factors.get(interval, np.sqrt(8_760))
    
    returns = df["close"].pct_change()
    realized_vol = returns.rolling(window=vol_lookback).std() * annualize
    
    # é¿å…é™¤ä»¥é›¶ & warmup æœŸç”¨ target_vol
    realized_vol = realized_vol.replace(0, np.nan).ffill().fillna(target_vol)
    
    scale = (target_vol / realized_vol).clip(lower=min_scale, upper=max_scale)
    
    scaled_pos = pos * scale
    # æœ€çµ‚ä»ç„¶é™åˆ¶åœ¨ [-1, 1]
    scaled_pos = scaled_pos.clip(lower=-1.0, upper=1.0)
    
    logger.info(
        f"ğŸ“Š Vol Targeting: target={target_vol:.0%}, "
        f"avg_realized={realized_vol.mean():.1%}, "
        f"avg_scale={scale.mean():.2f}, "
        f"avg_|pos|={scaled_pos.abs().mean():.3f}"
    )
    
    return scaled_pos


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¸å¿ƒå›æ¸¬å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_symbol_backtest(
    symbol: str,
    data_path: Path,
    cfg: dict,
    strategy_name: str = None,
    validate_data: Optional[bool] = None,
    clean_data_before: Optional[bool] = None,
    risk_limits: Optional[RiskLimits] = None,
    market_type: str | None = None,
    direction: str | None = None,
    data_dir: Path | None = None,
) -> BacktestResult:
    """
    é‹è¡Œå–®å€‹äº¤æ˜“å°çš„å›æ¸¬ï¼ˆå”¯ä¸€çš„ VBT Portfolio æ§‹å»ºå…¥å£ï¼‰

    **é‡è¦**ï¼šæ‰€æœ‰å›æ¸¬è·¯å¾‘ï¼ˆå–®å¹£ / çµ„åˆ / é©—è­‰ / Kellyï¼‰éƒ½å¿…é ˆé€é
    é€™å€‹å‡½æ•¸ä¾†ç”¢ç”Ÿ VBT Portfolioï¼Œç¢ºä¿æˆæœ¬æ¨¡å‹ä¸€è‡´ã€‚

    Args:
        symbol: äº¤æ˜“å°
        data_path: K ç·šæ•¸æ“šè·¯å¾‘
        cfg: é…ç½®å­—å…¸ï¼ˆå»ºè­°ç”¨ AppConfig.to_backtest_dict() ç”¢ç”Ÿï¼‰
        strategy_name: ç­–ç•¥åç¨±
        validate_data: æ˜¯å¦é©—è­‰æ•¸æ“š
        clean_data_before: æ˜¯å¦æ¸…æ´—æ•¸æ“š
        risk_limits: é¢¨éšªé™åˆ¶
        market_type: "spot" æˆ– "futures"ï¼ˆNone â†’ å¾ cfg è®€å–ï¼Œé è¨­ "spot"ï¼‰
        direction: "both" / "long_only" / "short_only"ï¼ˆNone â†’ å¾ cfg è®€å–ï¼‰
        data_dir: æ•¸æ“šæ ¹ç›®éŒ„ï¼ˆç”¨æ–¼è¼‰å…¥ funding rate ç­‰è¼”åŠ©æ•¸æ“šï¼‰

    Returns:
        BacktestResultï¼ˆæ¨™æº–åŒ–å›æ¸¬çµæœï¼‰
    """
    # â”€â”€ é…ç½®å®‰å…¨é©—è­‰ï¼ˆé˜²æ­¢ã€Œå¿«æ¨‚è¡¨ã€ï¼‰â”€â”€
    validate_backtest_config(cfg)

    df = load_klines(data_path)

    # è§£æåƒæ•¸ï¼ˆexplicit args å„ªå…ˆï¼Œfallback åˆ° cfg dictï¼‰
    resolved = _resolve_backtest_params(
        cfg,
        market_type=market_type,
        direction=direction,
        validate_data=validate_data,
        clean_data_before=clean_data_before,
    )
    mt = resolved["market_type"]
    dr = resolved["direction"]

    # æ•¸æ“šè³ªé‡æª¢æŸ¥
    if resolved["validate_data"]:
        quality_report = validate_data_quality(df)
        if not quality_report.is_valid:
            print(f"âš ï¸  è­¦å‘Š: {symbol} æ•¸æ“šè³ªé‡å•é¡Œ")
            for error in quality_report.errors:
                print(f"  - {error}")
            for warning in quality_report.warnings:
                print(f"  - {warning}")

    # æ•¸æ“šæ¸…æ´—
    if resolved["clean_data_before"]:
        df = clean_data(df, fill_method="forward", remove_outliers=False, remove_duplicates=True)

    # â”€â”€ trade_on=next_open â†’ signal_delay=1ï¼ˆæ¶ˆé™¤ look-ahead biasï¼‰â”€â”€
    trade_on = cfg.get("trade_on", "next_open")
    signal_delay = 1 if trade_on == "next_open" else 0

    ctx = StrategyContext(
        symbol=symbol,
        interval=cfg.get("interval", "1h"),
        market_type=mt,
        direction=dr,
        signal_delay=signal_delay,
    )

    # ç²å–ç­–ç•¥å‡½æ•¸
    strategy_name = strategy_name or cfg.get("strategy_name", "rsi_adx_atr")
    strategy_func = get_strategy(strategy_name)

    # è‡ªå‹•æ³¨å…¥ _data_dirï¼ˆè®“ç­–ç•¥å¯ä»¥è‡ªå‹•è¼‰å…¥ OI/FR ç­‰è¼”åŠ©æ•¸æ“šï¼‰
    if data_dir is not None and "_data_dir" not in cfg["strategy_params"]:
        cfg["strategy_params"]["_data_dir"] = data_dir

    # positions: [-1, 1] (Futures) æˆ– [0, 1] (Spot)
    pos = strategy_func(df, ctx, cfg["strategy_params"])

    # â”€â”€ Overlay å¾Œè™•ç†ï¼ˆå¯é¸ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¦‚æœ cfg ä¸­æœ‰ overlay é…ç½®ï¼Œåœ¨ direction clip å‰å¥—ç”¨
    # é€™ç¢ºä¿ overlay ä¹Ÿè‡ªå‹•æ•´åˆåˆ° walk-forward pipeline
    overlay_cfg = cfg.get("overlay")
    if overlay_cfg and overlay_cfg.get("enabled", False):
        from ..strategy.overlays.oi_vol_exit_overlay import apply_overlay_by_mode
        overlay_mode = overlay_cfg.get("mode", "vol_pause")
        overlay_params = overlay_cfg.get("params", {})

        # OI è³‡æ–™ï¼šå„ªå…ˆä½¿ç”¨å‘¼å«è€…æ³¨å…¥çš„ _oi_seriesï¼Œå¦å‰‡è‡ªå‹•å¾ data_dir è¼‰å…¥
        # æ”¯æ´è¤‡åˆæ¨¡å¼ï¼šå¦‚ "oi_vol+lsr_confirmatory" ä¹Ÿéœ€è¼‰å…¥ OI
        oi_series = cfg.get("_oi_series")
        _needs_oi = any(m in overlay_mode for m in ("oi_only", "oi_vol"))
        if oi_series is None and _needs_oi and data_dir:
            from ..data.open_interest import get_oi_path, load_open_interest, align_oi_to_klines
            for _prov in ["merged", "coinglass", "binance"]:
                _oi_path = get_oi_path(data_dir, symbol, _prov)
                _oi_df = load_open_interest(_oi_path)
                if _oi_df is not None and not _oi_df.empty:
                    oi_series = align_oi_to_klines(_oi_df, df.index, max_ffill_bars=2)
                    break

        # LSR è³‡æ–™ï¼šoverlay mode å« lsr_confirmatory æ™‚è‡ªå‹•è¼‰å…¥
        if "lsr_confirmatory" in overlay_mode and "_lsr_series" not in overlay_params:
            if data_dir:
                try:
                    from ..data.long_short_ratio import load_lsr, align_lsr_to_klines
                    lsr_type = overlay_params.get("lsr_type", "lsr")
                    deriv_dir = data_dir / "binance" / "futures" / "derivatives"
                    lsr_raw = load_lsr(symbol, lsr_type, data_dir=deriv_dir)
                    if lsr_raw is not None and not lsr_raw.empty:
                        lsr_aligned = align_lsr_to_klines(lsr_raw, df.index, max_ffill_bars=2)
                        overlay_params["_lsr_series"] = lsr_aligned
                        logger.debug(f"  {symbol}: overlay LSR è¼‰å…¥æˆåŠŸ ({len(lsr_raw)} rows)")
                    else:
                        logger.warning(f"  {symbol}: overlay LSR æ•¸æ“šä¸å­˜åœ¨ ({lsr_type})")
                except Exception as e:
                    logger.warning(f"  {symbol}: overlay LSR è¼‰å…¥å¤±æ•—: {e}")

        # OI ç¢ºèªå±¤æ•¸æ“šï¼šlsr_confirmatory + oi_confirm_enabled æ™‚è¼‰å…¥ OI åˆ° overlay_params
        if ("lsr_confirmatory" in overlay_mode
                and overlay_params.get("oi_confirm_enabled", False)
                and "_oi_series" not in overlay_params):
            if data_dir:
                try:
                    from ..data.open_interest import get_oi_path, load_open_interest, align_oi_to_klines
                    for _prov in ["merged", "coinglass", "binance"]:
                        _oi_path = get_oi_path(data_dir, symbol, _prov)
                        _oi_df = load_open_interest(_oi_path)
                        if _oi_df is not None and not _oi_df.empty:
                            overlay_params["_oi_series"] = align_oi_to_klines(
                                _oi_df, df.index, max_ffill_bars=2
                            )
                            logger.debug(f"  {symbol}: overlay OI (for LSR confirm) è¼‰å…¥æˆåŠŸ")
                            break
                except Exception as e:
                    logger.warning(f"  {symbol}: overlay OI (for LSR confirm) è¼‰å…¥å¤±æ•—: {e}")

        # FR ç¢ºèªå±¤æ•¸æ“šï¼šlsr_confirmatory + fr_confirm_enabled æ™‚è¼‰å…¥ FR åˆ° overlay_params
        if ("lsr_confirmatory" in overlay_mode
                and overlay_params.get("fr_confirm_enabled", False)
                and "_fr_series" not in overlay_params):
            if data_dir:
                try:
                    fr_path = get_funding_rate_path(data_dir, symbol)
                    funding_df = load_funding_rates(fr_path)
                    if funding_df is not None and not funding_df.empty:
                        # ä½¿ç”¨åŸå§‹ funding rate å€¼ï¼ˆéå°é½Šåˆ°çµç®—æ™‚åˆ»ï¼‰ï¼Œç”¨æ–¼ pctrank è¨ˆç®—
                        fr_col = "fundingRate" if "fundingRate" in funding_df.columns else funding_df.columns[0]
                        fr_series = funding_df[fr_col]
                        fr_aligned = fr_series.reindex(df.index, method="ffill")
                        overlay_params["_fr_series"] = fr_aligned
                        logger.debug(f"  {symbol}: overlay FR (for LSR confirm) è¼‰å…¥æˆåŠŸ ({len(funding_df)} rows)")
                    else:
                        logger.warning(f"  {symbol}: overlay FR æ•¸æ“šä¸å­˜åœ¨")
                except Exception as e:
                    logger.warning(f"  {symbol}: overlay FR (for LSR confirm) è¼‰å…¥å¤±æ•—: {e}")

        pos = apply_overlay_by_mode(
            position=pos,
            price_df=df,
            oi_series=oi_series,
            params=overlay_params,
            mode=overlay_mode,
        )
        logger.info(f"ğŸ“Š Overlay applied: mode={overlay_mode}")

    # æ ¹æ“š direction éæ¿¾ä¿¡è™Ÿï¼ˆä½¿ç”¨å…±ç”¨å‡½æ•¸ï¼‰
    pos = clip_positions_by_direction(pos, mt, dr)

    # â”€â”€ å€‰ä½ç¸®æ”¾ï¼ˆposition sizingï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # èˆ‡å¯¦ç›¤ runner çš„ _apply_position_sizing ä¸€è‡´ï¼š
    #   - fixed:      pos *= position_pctï¼ˆé è¨­ 1.0ï¼Œä¸ç¸®æ”¾ï¼‰
    #   - kelly:      pos *= kelly_pct * kelly_fractionï¼ˆä½¿ç”¨é…ç½®çš„ win_rate/avg_win/avg_lossï¼‰
    #   - volatility: pos *= target_vol / realized_vol
    ps_cfg = cfg.get("position_sizing", {})
    ps_method = ps_cfg.get("method", "fixed")
    ps_pct = ps_cfg.get("position_pct", 1.0)

    if ps_method == "kelly":
        kelly_fraction = ps_cfg.get("kelly_fraction", 0.25)
        win_rate = ps_cfg.get("win_rate")
        avg_win = ps_cfg.get("avg_win")
        avg_loss = ps_cfg.get("avg_loss")

        if win_rate is not None and avg_win is not None and avg_loss is not None:
            # ä½¿ç”¨é…ç½®æä¾›çš„çµ±è¨ˆï¼ˆèˆ‡ live runner ä¸€è‡´ï¼‰
            try:
                from ..risk.position_sizing import KellyPositionSizer
                ks = KellyPositionSizer(
                    win_rate=win_rate, avg_win=avg_win, avg_loss=avg_loss,
                    kelly_fraction=kelly_fraction,
                )
                scale = ks.kelly_pct  # å·²å« fraction
                if scale > 0:
                    logger.info(
                        f"ğŸ“Š Position Sizing [kelly]: "
                        f"win_rate={win_rate:.1%}, W/L={avg_win/avg_loss:.2f}, "
                        f"fraction={kelly_fraction}, scale={scale:.2f}"
                    )
                    pos = pos * scale
                else:
                    logger.info("ğŸ“Š Position Sizing [kelly]: edge â‰¤ 0ï¼Œä¸ç¸®æ”¾")
            except ValueError as e:
                logger.warning(f"âš ï¸  Kelly åƒæ•¸ç„¡æ•ˆ: {e}ï¼Œä¸ç¸®æ”¾")
        else:
            logger.info(
                "ğŸ“Š Position Sizing [kelly]: æœªè¨­å®š win_rate/avg_win/avg_lossï¼Œ"
                "ä¸ç¸®æ”¾ï¼ˆè«‹å…ˆè·‘ kelly_validation å–å¾—çµ±è¨ˆå¾Œå¡«å…¥é…ç½®ï¼‰"
            )
    elif ps_method == "volatility":
        target_vol = ps_cfg.get("target_volatility", 0.15)
        vol_lookback = ps_cfg.get("vol_lookback", 168)
        pos = _apply_vol_scaling(
            pos, df,
            target_vol=target_vol,
            vol_lookback=vol_lookback,
            interval=cfg.get("interval", "1h"),
        )
    elif ps_pct < 1.0:
        # fixed ä½† position_pct < 1.0 â†’ ç·šæ€§ç¸®æ”¾
        logger.info(f"ğŸ“Š Position Sizing [fixed]: scale={ps_pct:.2f}")
        pos = pos * ps_pct

    # æ‡‰ç”¨é¢¨éšªé™åˆ¶ï¼ˆå¦‚æœæä¾›ï¼‰
    if risk_limits is not None:
        equity_curve = (1 + df["close"].pct_change()).cumprod() * cfg["initial_cash"]
        adjusted_pos = pd.Series(0.0, index=pos.index)
        for i in range(len(pos)):
            current_equity = equity_curve.iloc[i] if i < len(equity_curve) else cfg["initial_cash"]
            adjusted_pos.iloc[i], _ = apply_risk_limits(
                pos.iloc[i],
                equity_curve.iloc[:i+1],
                risk_limits,
                current_equity=current_equity
            )
        pos = adjusted_pos

    # â”€â”€ æ—¥æœŸéæ¿¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ç­–ç•¥å·²åœ¨å®Œæ•´æ•¸æ“šä¸Šè¨ˆç®—å®Œç•¢ï¼ˆç¢ºä¿æŒ‡æ¨™ warmupï¼‰ï¼Œ
    # ç¾åœ¨æˆªå– [start, end] å€é–“é€å…¥ VBT å›æ¸¬
    df, pos = _apply_date_filter(df, pos, resolved.get("start"), resolved.get("end"))

    close = df["close"]
    open_ = df["open"]
    fee = _bps_to_pct(cfg["fee_bps"])

    # â”€â”€ æ§‹å»ºåŸ·è¡Œåƒ¹æ ¼ï¼ˆæ¶ˆé™¤ SL/TP look-ahead biasï¼‰â”€â”€â”€â”€â”€â”€
    # exit_exec_prices: SL/TP è§¸ç™¼æ™‚ç‚ºå¯¦éš›å‡ºå ´åƒ¹ï¼Œå…¶é¤˜ç‚º NaN
    exit_exec_prices = pos.attrs.get("exit_exec_prices")
    if exit_exec_prices is not None:
        # å°é½Šåˆ°æ—¥æœŸéæ¿¾å¾Œçš„ç´¢å¼•
        exit_exec_prices = exit_exec_prices.reindex(pos.index)
        # è‡ªå®šç¾©åŸ·è¡Œåƒ¹æ ¼: SL/TP bar ä½¿ç”¨å‡ºå ´åƒ¹ï¼Œå…¶é¤˜ç”¨ open
        exec_price = open_.copy()
        sl_tp_mask = exit_exec_prices.notna()
        exec_price[sl_tp_mask] = exit_exec_prices[sl_tp_mask]
        logger.info(
            f"ğŸ”§ SL/TP å‡ºå ´åƒ¹ä¿®æ­£: {sl_tp_mask.sum()} bars ä½¿ç”¨å¯¦éš› SL/TP åƒ¹æ ¼"
        )
    else:
        exec_price = open_

    # â”€â”€ æ»‘é»æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sm_cfg = cfg.get("slippage_model", {})
    slippage_result: SlippageResult | None = None

    if sm_cfg.get("enabled", False):
        leverage = cfg.get("leverage", 1)
        slippage_result = compute_volume_slippage(
            pos=pos,
            df=df,
            capital=cfg["initial_cash"],
            base_bps=sm_cfg.get("base_bps", 2.0),
            impact_coefficient=sm_cfg.get("impact_coefficient", 0.1),
            impact_power=sm_cfg.get("impact_power", 0.5),
            adv_lookback=sm_cfg.get("adv_lookback", 20),
            participation_rate=sm_cfg.get("participation_rate", 0.10),
            leverage=leverage,
        )
        slippage = slippage_result.slippage_array
        logger.info(
            f"ğŸ“Š {symbol} Volume slippage: "
            f"avg={slippage_result.avg_slippage_bps:.1f}bps, "
            f"max={slippage_result.max_slippage_bps:.1f}bps, "
            f"high_impact={slippage_result.high_impact_bars} bars"
        )
    else:
        slippage = _bps_to_pct(cfg["slippage_bps"])

    # â”€â”€ ç­–ç•¥ Portfolio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vbt_direction = to_vbt_direction(dr)
    
    pf = vbt.Portfolio.from_orders(
        close=close,
        size=pos,
        size_type="targetpercent",
        price=exec_price,
        fees=fee,
        slippage=slippage,
        init_cash=cfg["initial_cash"],
        freq=cfg.get("interval", "1h"),
        direction=vbt_direction,
    )

    # â”€â”€ Buy & Hold åŸºæº– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pf_bh = benchmark_buy_and_hold(
        df,
        initial_cash=cfg["initial_cash"],
        fee_bps=cfg["fee_bps"],
        slippage_bps=cfg["slippage_bps"],
        interval=cfg.get("interval", "1h"),
    )

    stats = pf.stats()

    # â”€â”€ Funding Rate æˆæœ¬æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fr_cfg = cfg.get("funding_rate", {})
    funding_cost: FundingCostResult | None = None
    adjusted_stats: dict | None = None
    adjusted_equity: pd.Series | None = None

    if fr_cfg.get("enabled", False) and mt == "futures":
        # å˜—è©¦è¼‰å…¥æ­·å² funding rate
        funding_df = None
        if fr_cfg.get("use_historical", True) and data_dir is not None:
            fr_path = get_funding_rate_path(data_dir, symbol)
            funding_df = load_funding_rates(fr_path)
            if funding_df is not None:
                logger.info(f"ğŸ“¥ {symbol} è¼‰å…¥æ­·å² funding rate: {len(funding_df)} records")
            else:
                logger.info(f"â„¹ï¸  {symbol} ç„¡æ­·å² funding rateï¼Œä½¿ç”¨é è¨­è²»ç‡")

        # å°é½Šåˆ° kline æ™‚é–“è»¸
        funding_rates = align_funding_to_klines(
            funding_df,
            df.index,
            default_rate_8h=fr_cfg.get("default_rate_8h", 0.0001),
        )

        # è¨ˆç®— funding æˆæœ¬
        leverage = cfg.get("leverage", 1)
        equity = pf.value()
        funding_cost = compute_funding_costs(
            pos=pos,
            equity=equity,
            funding_rates=funding_rates,
            leverage=leverage,
        )

        # èª¿æ•´å¾Œçš„è³‡é‡‘æ›²ç·šå’Œçµ±è¨ˆ
        adjusted_equity = adjust_equity_for_funding(equity, funding_cost)
        adjusted_stats = compute_adjusted_stats(adjusted_equity, cfg["initial_cash"])

        logger.info(
            f"ğŸ’° {symbol} Funding cost: "
            f"total=${funding_cost.total_cost:,.2f} "
            f"({funding_cost.total_cost_pct*100:.2f}%), "
            f"annualized={funding_cost.annualized_cost_pct*100:.2f}%/yr, "
            f"settlements={funding_cost.n_settlements}"
        )

    result = BacktestResult(
        pf=pf,
        pf_bh=pf_bh,
        stats=stats,
        df=df,
        pos=pos,
        funding_cost=funding_cost,
        slippage_result=slippage_result,
        adjusted_stats=adjusted_stats,
        adjusted_equity=adjusted_equity,
        funding_rate_enabled=fr_cfg.get("enabled", False),
        slippage_model_enabled=sm_cfg.get("enabled", False),
    )

    logger.info(f"ğŸ“Š {symbol} å›æ¸¬å®Œæˆ [{result.cost_summary()}]")
    return result
