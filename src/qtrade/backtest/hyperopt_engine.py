"""
Hyperopt åƒæ•¸å„ªåŒ–å¼•æ“

å€Ÿé‘’ Freqtrade çš„ Hyperopt è¨­è¨ˆï¼Œä½¿ç”¨ Optuna å¯¦ç¾è²è‘‰æ–¯å„ªåŒ–ã€‚

åŠŸèƒ½ï¼š
    1. è‡ªå‹•æœç´¢ç­–ç•¥æœ€ä½³åƒæ•¸çµ„åˆï¼ˆTPE / CMA-ES / Gridï¼‰
    2. æ”¯æ´å¤šç¨®å„ªåŒ–ç›®æ¨™ï¼ˆSharpe ratioã€ç¸½å›å ±ã€å‹ç‡ç­‰ï¼‰
    3. å¤šå¹£ç¨®è¯åˆå„ªåŒ–ï¼ˆè·¨è³‡ç”¢é­¯æ£’æ€§ï¼‰
    4. Train/Test OOS é©—è­‰ï¼ˆé˜²æ­¢éæ“¬åˆï¼‰
    5. Walk-Forward é©—è­‰ï¼ˆæ»¾å‹• OOS é©—è­‰ï¼‰
    6. å¯è¦–åŒ–å„ªåŒ–éç¨‹å’Œåƒæ•¸ç©ºé–“

ä½¿ç”¨æ–¹æ³•ï¼š
    from qtrade.backtest.hyperopt_engine import HyperoptEngine, ParamSpace
    
    # å®šç¾©åƒæ•¸ç©ºé–“
    param_space = {
        "rsi_period": ParamSpace.integer("rsi_period", 10, 30),
        "oversold": ParamSpace.float("oversold", 25, 40),
        "overbought": ParamSpace.float("overbought", 60, 80),
        "min_adx": ParamSpace.float("min_adx", 15, 35),
        "stop_loss_atr": ParamSpace.float("stop_loss_atr", 1.5, 3.5),
        "take_profit_atr": ParamSpace.float("take_profit_atr", 2.0, 5.0),
    }
    
    # é‹è¡Œå„ªåŒ–
    engine = HyperoptEngine(
        strategy_name="rsi_adx_atr",
        data_path=Path("data/BTCUSDT_1h.parquet"),
        base_cfg=cfg,
        param_space=param_space,
    )
    
    best_params, study = engine.optimize(
        n_trials=200,
        objective="sharpe_ratio",
        n_jobs=4,  # ä¸¦è¡Œ
    )
    
    # å¯è¦–åŒ–
    engine.plot_optimization_history()
    engine.plot_param_importances()
"""
from __future__ import annotations

import json
import time
import warnings
from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, Literal

import numpy as np
import optuna
import pandas as pd
from optuna.samplers import TPESampler, CmaEsSampler, GridSampler

from ..utils.log import get_logger
from .run_backtest import run_symbol_backtest

logger = get_logger("hyperopt")

# å¿½ç•¥ Optuna çš„ä¸€äº›è­¦å‘Š
warnings.filterwarnings("ignore", category=optuna.exceptions.ExperimentalWarning)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åƒæ•¸ç©ºé–“å®šç¾©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ParamDef:
    """åƒæ•¸å®šç¾©"""
    name: str
    param_type: Literal["int", "float", "categorical"]
    low: float | int | None = None
    high: float | int | None = None
    choices: list | None = None
    step: float | int | None = None
    log: bool = False  # æ˜¯å¦ä½¿ç”¨å°æ•¸ç©ºé–“


class ParamSpace:
    """
    åƒæ•¸ç©ºé–“å®šç¾©å·¥å…·é¡
    
    å€Ÿé‘’ Freqtrade çš„åƒæ•¸ç©ºé–“è¨­è¨ˆï¼Œæ”¯æ´ï¼š
    - æ•´æ•¸åƒæ•¸ (IntSpace)
    - æµ®é»åƒæ•¸ (DecimalSpace)
    - é¡åˆ¥åƒæ•¸ (CategoricalSpace)
    """
    
    @staticmethod
    def integer(name: str, low: int, high: int, step: int = 1) -> ParamDef:
        """æ•´æ•¸åƒæ•¸ç©ºé–“"""
        return ParamDef(name=name, param_type="int", low=low, high=high, step=step)
    
    @staticmethod
    def float(name: str, low: float, high: float, step: float | None = None, log: bool = False) -> ParamDef:
        """æµ®é»åƒæ•¸ç©ºé–“"""
        return ParamDef(name=name, param_type="float", low=low, high=high, step=step, log=log)
    
    @staticmethod
    def categorical(name: str, choices: list) -> ParamDef:
        """é¡åˆ¥åƒæ•¸ç©ºé–“"""
        return ParamDef(name=name, param_type="categorical", choices=choices)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å„ªåŒ–ç›®æ¨™å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# é å®šç¾©çš„å„ªåŒ–ç›®æ¨™
OBJECTIVES = {
    "sharpe_ratio": lambda stats: stats.get("Sharpe Ratio", -999),
    "sortino_ratio": lambda stats: stats.get("Sortino Ratio", -999),
    "total_return": lambda stats: stats.get("Total Return [%]", -999),
    "win_rate": lambda stats: stats.get("Win Rate [%]", 0),
    "profit_factor": lambda stats: stats.get("Profit Factor", 0),
    "max_drawdown": lambda stats: -abs(stats.get("Max Drawdown [%]", -999)),  # è² æ•¸å› ç‚ºè¦æœ€å¤§åŒ–ï¼ˆæ¸›å°‘ DDï¼‰
    "calmar_ratio": lambda stats: stats.get("Calmar Ratio", -999),
    
    # è¤‡åˆç›®æ¨™ï¼ˆé¢¨éšªèª¿æ•´å¾Œå ±é…¬ï¼‰
    "risk_adjusted": lambda stats: (
        stats.get("Sharpe Ratio", 0) * 0.4 +
        stats.get("Sortino Ratio", 0) * 0.3 +
        (100 + stats.get("Max Drawdown [%]", -100)) / 100 * 0.3  # DD è¶Šå°è¶Šå¥½
    ),
    
    # Sharpe - DD æ‡²ç½°ï¼ˆæœ€å¯¦ç”¨çš„ç›®æ¨™å‡½æ•¸ï¼‰
    "sharpe_dd": lambda stats: (
        stats.get("Sharpe Ratio", 0) -
        0.02 * abs(stats.get("Max Drawdown [%]", 50))  # DD å¤ªå¤§è¦æ‰£åˆ†
    ),
}


def get_objective_fn(objective: str | Callable) -> Callable:
    """ç²å–å„ªåŒ–ç›®æ¨™å‡½æ•¸"""
    if callable(objective):
        return objective
    if objective in OBJECTIVES:
        return OBJECTIVES[objective]
    raise ValueError(f"Unknown objective: {objective}. Available: {list(OBJECTIVES.keys())}")


def _min_trades_penalty(stats: dict, min_trades: int = 10) -> float:
    """äº¤æ˜“æ¬¡æ•¸éå°‘çš„æ‡²ç½°ï¼ˆé˜²æ­¢éæ“¬åˆåˆ°å°‘æ•¸å®Œç¾äº¤æ˜“ï¼‰"""
    total_trades = stats.get("Total Trades", 0)
    if total_trades < min_trades:
        return -100.0  # åš´é‡æ‡²ç½°
    return 0.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Hyperopt å¼•æ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class OptimizationResult:
    """å„ªåŒ–çµæœ"""
    best_params: dict
    best_value: float
    study: optuna.Study
    all_trials: pd.DataFrame
    # OOS çµæœï¼ˆå¦‚æœæœ‰ï¼‰
    oos_stats: dict | None = None
    
    def summary(self) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        lines = [
            "=" * 60,
            "ğŸ¯ Hyperopt Optimization Result",
            "=" * 60,
            f"Best objective value: {self.best_value:.4f}",
            "",
            "Best Parameters:",
        ]
        for k, v in self.best_params.items():
            if isinstance(v, float):
                lines.append(f"  {k}: {v:.4f}")
            else:
                lines.append(f"  {k}: {v}")
        
        completed = len(self.all_trials[self.all_trials['state'] == 'COMPLETE']) if 'state' in self.all_trials.columns else len(self.all_trials)
        lines.append("")
        lines.append(f"Total Trials: {len(self.all_trials)}")
        lines.append(f"Completed: {completed}")
        
        if self.oos_stats:
            lines.append("")
            lines.append("â”€â”€â”€ Out-of-Sample (OOS) Results â”€â”€â”€")
            for k, v in self.oos_stats.items():
                if isinstance(v, float):
                    lines.append(f"  {k}: {v:.4f}")
                else:
                    lines.append(f"  {k}: {v}")
        
        lines.append("=" * 60)
        return "\n".join(lines)
    
    def to_dict(self) -> dict:
        """å°å‡ºç‚ºå¯åºåˆ—åŒ–çš„ dict"""
        return {
            "best_params": self.best_params,
            "best_value": self.best_value,
            "n_trials": len(self.all_trials),
            "oos_stats": self.oos_stats,
        }


class HyperoptEngine:
    """
    Hyperopt åƒæ•¸å„ªåŒ–å¼•æ“
    
    å€Ÿé‘’ Freqtrade çš„è¨­è¨ˆï¼Œä½¿ç”¨ Optuna å¯¦ç¾è²è‘‰æ–¯å„ªåŒ–ã€‚
    
    ç‰¹é»ï¼š
    - æ”¯æ´å¤šç¨®å„ªåŒ–ç›®æ¨™
    - æ”¯æ´ä¸¦è¡Œå„ªåŒ–
    - æ”¯æ´ TPE / CMA-ES / Grid å¤šç¨®æœç´¢ç®—æ³•
    - å¤šå¹£ç¨®è¯åˆå„ªåŒ–
    - Train/Test OOS é©—è­‰ï¼ˆé˜²æ­¢éæ“¬åˆï¼‰
    - å¯è¦–åŒ–å„ªåŒ–éç¨‹
    """
    
    def __init__(
        self,
        strategy_name: str,
        symbol_data: dict[str, Path],
        base_cfg: dict,
        param_space: dict[str, ParamDef],
        market_type: str = "spot",
        direction: str = "both",
        data_dir: Path | None = None,
        min_trades: int = 10,
    ):
        """
        åˆå§‹åŒ– Hyperopt å¼•æ“
        
        Args:
            strategy_name: ç­–ç•¥åç¨±ï¼ˆå¦‚ "rsi_adx_atr"ï¼‰
            symbol_data: {symbol: data_path} å­—å…¸ï¼Œæ”¯æ´å¤šå¹£ç¨®
            base_cfg: åŸºç¤é…ç½®ï¼ˆåŒ…å« initial_cash, fee_bps ç­‰ï¼‰
            param_space: åƒæ•¸ç©ºé–“å®šç¾©
            market_type: å¸‚å ´é¡å‹
            direction: äº¤æ˜“æ–¹å‘
            data_dir: æ•¸æ“šæ ¹ç›®éŒ„ï¼ˆç”¨æ–¼ funding rate ç­‰ï¼‰
            min_trades: æœ€ä½äº¤æ˜“æ¬¡æ•¸ï¼ˆé˜²æ­¢éæ“¬åˆï¼‰
        """
        self.strategy_name = strategy_name
        self.symbol_data = symbol_data  # {symbol: Path}
        self.base_cfg = base_cfg.copy()
        self.param_space = param_space
        self.market_type = market_type
        self.direction = direction
        self.data_dir = data_dir
        self.min_trades = min_trades
        
        self._study: optuna.Study | None = None
        self._results: OptimizationResult | None = None
    
    # å‘å¾Œç›¸å®¹çš„ä¾¿æ·å»ºæ§‹å­
    @classmethod
    def from_single_symbol(
        cls,
        strategy_name: str,
        data_path: Path,
        base_cfg: dict,
        param_space: dict[str, ParamDef],
        symbol: str = "BTCUSDT",
        **kwargs,
    ) -> "HyperoptEngine":
        """å¾å–®å¹£ç¨®å»ºç«‹å¼•æ“ï¼ˆå‘å¾Œç›¸å®¹ï¼‰"""
        return cls(
            strategy_name=strategy_name,
            symbol_data={symbol: data_path},
            base_cfg=base_cfg,
            param_space=param_space,
            **kwargs,
        )
    
    def _suggest_params(self, trial: optuna.Trial) -> dict:
        """å¾ trial ä¸­æ¡æ¨£åƒæ•¸"""
        params = {}
        for name, pdef in self.param_space.items():
            if pdef.param_type == "int":
                params[name] = trial.suggest_int(name, pdef.low, pdef.high, step=pdef.step or 1)
            elif pdef.param_type == "float":
                if pdef.step:
                    params[name] = trial.suggest_float(name, pdef.low, pdef.high, step=pdef.step)
                elif pdef.log:
                    params[name] = trial.suggest_float(name, pdef.low, pdef.high, log=True)
                else:
                    params[name] = trial.suggest_float(name, pdef.low, pdef.high)
            elif pdef.param_type == "categorical":
                params[name] = trial.suggest_categorical(name, pdef.choices)
        return params
    
    def _run_backtest_for_symbol(
        self, symbol: str, data_path: Path, cfg: dict,
    ) -> dict:
        """å°å–®ä¸€å¹£ç¨®é‹è¡Œå›æ¸¬ï¼Œè¿”å› stats dict"""
        result = run_symbol_backtest(
            symbol=symbol,
            data_path=data_path,
            cfg=cfg,
            strategy_name=self.strategy_name,
            market_type=self.market_type,
            direction=self.direction,
            data_dir=self.data_dir,
        )
        return result.stats
    
    def _create_objective(self, objective_fn: Callable) -> Callable:
        """å‰µå»º Optuna ç›®æ¨™å‡½æ•¸ï¼ˆæ”¯æ´å¤šå¹£ç¨®è¯åˆå„ªåŒ–ï¼‰"""
        
        def objective(trial: optuna.Trial) -> float:
            # æ¡æ¨£åƒæ•¸
            sampled_params = self._suggest_params(trial)
            
            # åˆä½µåˆ°ç­–ç•¥åƒæ•¸
            cfg = self.base_cfg.copy()
            cfg["strategy_params"] = {
                **cfg.get("strategy_params", {}),
                **sampled_params,
            }
            
            # å¤šå¹£ç¨®è¯åˆè©•ä¼°
            all_obj_values = []
            all_stats = {}
            
            for symbol, data_path in self.symbol_data.items():
                try:
                    stats = self._run_backtest_for_symbol(symbol, data_path, cfg)
                    
                    # æœ€ä½äº¤æ˜“æ¬¡æ•¸æ‡²ç½°
                    penalty = _min_trades_penalty(stats, self.min_trades)
                    if penalty < 0:
                        trial.set_user_attr(f"{symbol}_penalty", "low_trades")
                        all_obj_values.append(penalty)
                        continue
                    
                    obj_value = objective_fn(stats)
                    
                    if np.isnan(obj_value) or np.isinf(obj_value):
                        all_obj_values.append(-999.0)
                        continue
                    
                    all_obj_values.append(obj_value)
                    all_stats[symbol] = {
                        "total_return": stats.get("Total Return [%]", 0),
                        "sharpe_ratio": stats.get("Sharpe Ratio", 0),
                        "max_drawdown": stats.get("Max Drawdown [%]", 0),
                        "win_rate": stats.get("Win Rate [%]", 0),
                        "total_trades": stats.get("Total Trades", 0),
                    }
                    
                except Exception as e:
                    logger.warning(f"Trial {trial.number} - {symbol} failed: {e}")
                    all_obj_values.append(-999.0)
            
            if not all_obj_values:
                return float("-inf")
            
            # è¯åˆç›®æ¨™ï¼šå–å¹³å‡ï¼ˆè·¨å¹£ç¨®é­¯æ£’æ€§ï¼‰
            combined = float(np.mean(all_obj_values))
            
            # è¨˜éŒ„åˆ° trial attributes
            for symbol, s in all_stats.items():
                for k, v in s.items():
                    trial.set_user_attr(f"{symbol}_{k}", v)
            trial.set_user_attr("combined_objective", combined)
            trial.set_user_attr("n_symbols", len(self.symbol_data))
            
            # å¦‚æœå–®å¹£ç¨®ï¼Œä¹Ÿè¨˜éŒ„ä¸»è¦æŒ‡æ¨™åˆ°é ‚å±¤
            if len(all_stats) == 1:
                s = list(all_stats.values())[0]
                trial.set_user_attr("total_return", s["total_return"])
                trial.set_user_attr("sharpe_ratio", s["sharpe_ratio"])
                trial.set_user_attr("max_drawdown", s["max_drawdown"])
                trial.set_user_attr("win_rate", s["win_rate"])
                trial.set_user_attr("total_trades", s["total_trades"])
            elif all_stats:
                # å¤šå¹£ç¨®ï¼šè¨˜éŒ„å¹³å‡å€¼
                for k in ["total_return", "sharpe_ratio", "max_drawdown", "win_rate", "total_trades"]:
                    avg = np.mean([s[k] for s in all_stats.values()])
                    trial.set_user_attr(f"avg_{k}", avg)
            
            return combined
        
        return objective
    
    def _create_sampler(
        self,
        method: str = "tpe",
        seed: int = 42,
    ) -> optuna.samplers.BaseSampler:
        """æ ¹æ“šæœç´¢æ–¹æ³•å‰µå»ºå°æ‡‰çš„ sampler"""
        if method == "tpe":
            return TPESampler(seed=seed, multivariate=True)
        elif method == "cmaes":
            return CmaEsSampler(seed=seed)
        elif method == "grid":
            # Grid sampler éœ€è¦æœç´¢ç©ºé–“å®šç¾©
            search_space = {}
            for name, pdef in self.param_space.items():
                if pdef.param_type == "int":
                    step = pdef.step or 1
                    search_space[name] = list(range(pdef.low, pdef.high + 1, step))
                elif pdef.param_type == "float":
                    if pdef.step:
                        vals = []
                        v = pdef.low
                        while v <= pdef.high + 1e-9:
                            vals.append(round(v, 6))
                            v += pdef.step
                        search_space[name] = vals
                    else:
                        # ç„¡ step çš„ float â†’ è‡ªå‹•é›¢æ•£åŒ–ç‚º 5 å€‹é»
                        search_space[name] = [
                            round(pdef.low + (pdef.high - pdef.low) * i / 4, 4)
                            for i in range(5)
                        ]
                elif pdef.param_type == "categorical":
                    search_space[name] = pdef.choices
            return GridSampler(search_space, seed=seed)
        else:
            raise ValueError(f"Unknown method: {method}. Available: tpe, cmaes, grid")
    
    def optimize(
        self,
        n_trials: int = 100,
        objective: str | Callable = "sharpe_ratio",
        method: str = "tpe",
        n_jobs: int = 1,
        timeout: int | None = None,
        show_progress: bool = True,
        seed: int = 42,
    ) -> OptimizationResult:
        """
        é‹è¡Œåƒæ•¸å„ªåŒ–
        
        Args:
            n_trials: å„ªåŒ–è¿­ä»£æ¬¡æ•¸
            objective: å„ªåŒ–ç›®æ¨™ï¼ˆå­—ä¸²æˆ–è‡ªå®šç¾©å‡½æ•¸ï¼‰
            method: æœç´¢ç®—æ³• ("tpe", "cmaes", "grid")
            n_jobs: ä¸¦è¡Œæ•¸ï¼ˆ-1 = ä½¿ç”¨æ‰€æœ‰ CPUï¼‰
            timeout: è¶…æ™‚ç§’æ•¸
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦æ¢
            seed: éš¨æ©Ÿç¨®å­
        
        Returns:
            OptimizationResult åŒ…å«æœ€ä½³åƒæ•¸å’Œå„ªåŒ–æ­·å²
        """
        objective_fn = get_objective_fn(objective)
        objective_name = objective if isinstance(objective, str) else "custom"
        
        # å‰µå»º Sampler
        sampler = self._create_sampler(method, seed)
        
        # å‰µå»º Study
        self._study = optuna.create_study(
            direction="maximize",
            sampler=sampler,
            study_name=f"{self.strategy_name}_hyperopt",
        )
        
        # è¨­ç½®æ—¥èªŒç´šåˆ¥
        if not show_progress:
            optuna.logging.set_verbosity(optuna.logging.WARNING)
        else:
            optuna.logging.set_verbosity(optuna.logging.INFO)
        
        symbols_str = ", ".join(self.symbol_data.keys())
        logger.info(f"ğŸš€ Starting Hyperopt: {n_trials} trials, method={method}, objective={objective_name}")
        logger.info(f"   Strategy: {self.strategy_name}, Symbols: [{symbols_str}]")
        logger.info(f"   Param space ({len(self.param_space)} params): {list(self.param_space.keys())}")
        
        t0 = time.time()
        
        # é‹è¡Œå„ªåŒ–
        self._study.optimize(
            self._create_objective(objective_fn),
            n_trials=n_trials,
            n_jobs=n_jobs,
            timeout=timeout,
            show_progress_bar=show_progress,
        )
        
        elapsed = time.time() - t0
        logger.info(f"â±ï¸  Optimization completed in {elapsed:.1f}s ({elapsed/max(n_trials,1):.1f}s/trial)")
        
        # æ”¶é›†çµæœ
        trials_df = self._study.trials_dataframe()
        
        self._results = OptimizationResult(
            best_params=self._study.best_params,
            best_value=self._study.best_value,
            study=self._study,
            all_trials=trials_df,
        )
        
        logger.info(self._results.summary())
        return self._results
    
    def run_oos_validation(
        self,
        best_params: dict,
        oos_data: dict[str, Path],
        objective_fn: Callable | str = "sharpe_ratio",
    ) -> dict:
        """
        ç”¨æœ€ä½³åƒæ•¸åœ¨ OOSï¼ˆOut-of-Sampleï¼‰æ•¸æ“šä¸Šé©—è­‰
        
        Args:
            best_params: æœ€ä½³åƒæ•¸
            oos_data: {symbol: oos_data_path} OOS æ•¸æ“š
            objective_fn: ç›®æ¨™å‡½æ•¸ï¼ˆç”¨æ–¼è¨ˆç®— OOS objectiveï¼‰
        
        Returns:
            OOS çµæœ dict
        """
        if isinstance(objective_fn, str):
            objective_fn = get_objective_fn(objective_fn)
        
        cfg = self.base_cfg.copy()
        cfg["strategy_params"] = {
            **cfg.get("strategy_params", {}),
            **best_params,
        }
        
        oos_results = {}
        obj_values = []
        
        for symbol, data_path in oos_data.items():
            try:
                stats = self._run_backtest_for_symbol(symbol, data_path, cfg)
                oos_results[symbol] = {
                    "total_return": stats.get("Total Return [%]", 0),
                    "sharpe_ratio": stats.get("Sharpe Ratio", 0),
                    "max_drawdown": stats.get("Max Drawdown [%]", 0),
                    "win_rate": stats.get("Win Rate [%]", 0),
                    "total_trades": stats.get("Total Trades", 0),
                }
                obj_values.append(objective_fn(stats))
            except Exception as e:
                logger.warning(f"OOS validation failed for {symbol}: {e}")
                oos_results[symbol] = {"error": str(e)}
        
        # åŒ¯ç¸½
        oos_summary = {
            "per_symbol": oos_results,
            "avg_objective": float(np.mean(obj_values)) if obj_values else None,
            "n_symbols": len(oos_data),
        }
        
        if self._results:
            self._results.oos_stats = oos_summary
        
        return oos_summary
    
    # â”€â”€ å¯è¦–åŒ–æ–¹æ³• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def plot_optimization_history(self, save_path: Path | None = None) -> None:
        """ç¹ªè£½å„ªåŒ–æ­·å²"""
        if self._study is None:
            raise ValueError("Run optimize() first")
        
        try:
            from optuna.visualization import plot_optimization_history
            
            fig = plot_optimization_history(self._study)
            fig.update_layout(title=f"Optimization History - {self.strategy_name}")
            if save_path:
                fig.write_image(str(save_path))
                logger.info(f"ğŸ“Š Saved optimization history: {save_path}")
            else:
                fig.show()
            return fig
        except ImportError:
            logger.warning("plotly/kaleido not installed, skipping visualization")
    
    def plot_param_importances(self, save_path: Path | None = None) -> None:
        """ç¹ªè£½åƒæ•¸é‡è¦æ€§"""
        if self._study is None:
            raise ValueError("Run optimize() first")
        
        try:
            from optuna.visualization import plot_param_importances
            
            fig = plot_param_importances(self._study)
            fig.update_layout(title=f"Parameter Importances - {self.strategy_name}")
            if save_path:
                fig.write_image(str(save_path))
                logger.info(f"ğŸ“Š Saved param importances: {save_path}")
            else:
                fig.show()
            return fig
        except ImportError:
            logger.warning("plotly/kaleido not installed, skipping visualization")
    
    def plot_contour(self, param1: str, param2: str, save_path: Path | None = None) -> None:
        """ç¹ªè£½åƒæ•¸ç­‰é«˜ç·šåœ–ï¼ˆç†±åŠ›åœ–ï¼‰"""
        if self._study is None:
            raise ValueError("Run optimize() first")
        
        try:
            from optuna.visualization import plot_contour
            
            fig = plot_contour(self._study, params=[param1, param2])
            fig.update_layout(title=f"Contour Plot: {param1} vs {param2}")
            if save_path:
                fig.write_image(str(save_path))
            else:
                fig.show()
            return fig
        except ImportError:
            logger.warning("plotly/kaleido not installed, skipping visualization")
    
    def plot_parallel_coordinate(self, save_path: Path | None = None) -> None:
        """ç¹ªè£½å¹³è¡Œåæ¨™åœ–ï¼ˆæ‰€æœ‰åƒæ•¸ï¼‰"""
        if self._study is None:
            raise ValueError("Run optimize() first")
        
        try:
            from optuna.visualization import plot_parallel_coordinate
            
            fig = plot_parallel_coordinate(self._study)
            fig.update_layout(title=f"Parallel Coordinate - {self.strategy_name}")
            if save_path:
                fig.write_image(str(save_path))
            else:
                fig.show()
            return fig
        except ImportError:
            logger.warning("plotly/kaleido not installed, skipping visualization")
    
    def get_top_trials(self, n: int = 10) -> pd.DataFrame:
        """ç²å–å‰ N å€‹æœ€ä½³è©¦é©—"""
        if self._results is None:
            raise ValueError("Run optimize() first")
        
        df = self._results.all_trials.copy()
        if "state" in df.columns:
            df = df[df["state"] == "COMPLETE"]
        df = df.sort_values("value", ascending=False)
        return df.head(n)
    
    def save_results(self, output_dir: Path) -> None:
        """å°‡çµæœå„²å­˜åˆ°ç›®éŒ„"""
        if self._results is None:
            raise ValueError("Run optimize() first")
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. æœ€ä½³åƒæ•¸ JSON
        result_dict = self._results.to_dict()
        with open(output_dir / "best_params.json", "w") as f:
            json.dump(result_dict, f, indent=2, default=str)
        
        # 2. æ‰€æœ‰ trial çš„ CSV
        self._results.all_trials.to_csv(output_dir / "all_trials.csv", index=False)
        
        # 3. Top 20 çµæœ
        top = self.get_top_trials(20)
        top.to_csv(output_dir / "top_trials.csv", index=False)
        
        # 4. æ‘˜è¦æ–‡å­—
        with open(output_dir / "summary.txt", "w") as f:
            f.write(self._results.summary())
        
        logger.info(f"ğŸ’¾ Results saved to: {output_dir}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Walk-Forward é©—è­‰ï¼ˆé˜²æ­¢éæ“¬åˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class WalkForwardFold:
    """å–®ä¸€ fold çš„çµæœ"""
    fold_idx: int
    train_start: str
    train_end: str
    test_start: str
    test_end: str
    best_params: dict
    train_objective: float
    test_objective: float
    test_stats: dict


class WalkForwardValidator:
    """
    Walk-Forward é©—è­‰å™¨
    
    å°‡æ•¸æ“šåˆ†å‰²ç‚ºå¤šå€‹è¨“ç·´/æ¸¬è©¦é›†ï¼Œåœ¨æ¯å€‹è¨“ç·´é›†ä¸Šå„ªåŒ–åƒæ•¸ï¼Œ
    ç„¶å¾Œåœ¨å°æ‡‰çš„æ¸¬è©¦é›†ä¸Šé©—è­‰ï¼Œæœ€å¾Œçµ±è¨ˆæ‰€æœ‰æ¸¬è©¦é›†çš„è¡¨ç¾ã€‚
    
    é€™å¯ä»¥æœ‰æ•ˆé˜²æ­¢éæ“¬åˆæ­·å²æ•¸æ“šã€‚
    
    ä½¿ç”¨ Anchored Walk-Forwardï¼š
    - è¨“ç·´é›†å¾æ•¸æ“šèµ·é»é–‹å§‹ï¼Œé€æ¼¸å¢é•·
    - æ¸¬è©¦é›†å›ºå®šå¤§å°ï¼Œé€æ­¥å¾€å‰æ¨ç§»
    """
    
    def __init__(
        self,
        strategy_name: str,
        symbol_data: dict[str, Path],
        base_cfg: dict,
        param_space: dict[str, ParamDef],
        market_type: str = "spot",
        direction: str = "both",
        data_dir: Path | None = None,
    ):
        self.strategy_name = strategy_name
        self.symbol_data = symbol_data
        self.base_cfg = base_cfg
        self.param_space = param_space
        self.market_type = market_type
        self.direction = direction
        self.data_dir = data_dir
        self._folds: list[WalkForwardFold] = []
    
    def run(
        self,
        n_splits: int = 5,
        n_trials_per_fold: int = 50,
        objective: str = "sharpe_ratio",
        method: str = "tpe",
        min_train_bars: int = 2000,
    ) -> pd.DataFrame:
        """
        é‹è¡Œ Anchored Walk-Forward é©—è­‰
        
        æ•¸æ“šè¢«åˆ†ç‚º n_splits+1 æ®µï¼š
        - Fold 1: train=[0, 1], test=[2]
        - Fold 2: train=[0, 1, 2], test=[3]
        - ...
        - Fold n: train=[0..n], test=[n+1]
        
        Args:
            n_splits: æ¸¬è©¦ fold æ•¸é‡
            n_trials_per_fold: æ¯å€‹ fold çš„å„ªåŒ–è©¦é©—æ•¸
            objective: å„ªåŒ–ç›®æ¨™
            method: æœç´¢ç®—æ³•
            min_train_bars: æœ€å°‘è¨“ç·´æ•¸æ“š bar æ•¸
        
        Returns:
            DataFrame with per-fold results
        """
        from ..data.storage import load_klines
        
        objective_fn = get_objective_fn(objective)
        self._folds = []
        
        # å…ˆè¼‰å…¥æ•¸æ“šç¢ºå®šå®Œæ•´é•·åº¦ï¼ˆç”¨ç¬¬ä¸€å€‹å¹£ç¨®çš„æ•¸æ“šé•·åº¦ï¼‰
        first_symbol = list(self.symbol_data.keys())[0]
        first_path = self.symbol_data[first_symbol]
        full_df = load_klines(first_path)
        total_len = len(full_df)
        
        # è¨ˆç®—æ¯å€‹ segment çš„å¤§å°
        n_segments = n_splits + 1
        segment_size = total_len // n_segments
        
        if segment_size < 500:
            logger.warning(f"æ¯å€‹ segment åªæœ‰ {segment_size} barsï¼Œå¯èƒ½ä¸è¶³ä»¥å¯é å„ªåŒ–")
        
        logger.info(f"ğŸ”„ Walk-Forward: {n_splits} folds, {total_len} total bars")
        logger.info(f"   Segment size: ~{segment_size} bars")
        
        for fold_i in range(n_splits):
            train_end_idx = (fold_i + 1) * segment_size
            test_start_idx = train_end_idx
            test_end_idx = min((fold_i + 2) * segment_size, total_len)
            
            if train_end_idx < min_train_bars:
                logger.warning(f"Fold {fold_i+1}: Training data ({train_end_idx} bars) < min_train_bars ({min_train_bars}), skipping")
                continue
            
            train_dates = (
                full_df.index[0].strftime("%Y-%m-%d"),
                full_df.index[train_end_idx - 1].strftime("%Y-%m-%d"),
            )
            test_dates = (
                full_df.index[test_start_idx].strftime("%Y-%m-%d"),
                full_df.index[test_end_idx - 1].strftime("%Y-%m-%d"),
            )
            
            logger.info(f"\nğŸ“Š Fold {fold_i+1}/{n_splits}")
            logger.info(f"   Train: {train_dates[0]} â†’ {train_dates[1]} ({train_end_idx} bars)")
            logger.info(f"   Test:  {test_dates[0]} â†’ {test_dates[1]} ({test_end_idx - test_start_idx} bars)")
            
            # è¨“ç·´ï¼šåœ¨ train æ•¸æ“šä¸Šå»ºç«‹å›æ¸¬é…ç½®ï¼ˆä¿®æ”¹ start/endï¼‰
            train_cfg = self.base_cfg.copy()
            train_cfg["start"] = train_dates[0]
            train_cfg["end"] = train_dates[1]
            
            engine = HyperoptEngine(
                strategy_name=self.strategy_name,
                symbol_data=self.symbol_data,
                base_cfg=train_cfg,
                param_space=self.param_space,
                market_type=self.market_type,
                direction=self.direction,
                data_dir=self.data_dir,
            )
            
            result = engine.optimize(
                n_trials=n_trials_per_fold,
                objective=objective,
                method=method,
                show_progress=False,
            )
            
            # æ¸¬è©¦ï¼šç”¨æœ€ä½³åƒæ•¸åœ¨ test æ•¸æ“šä¸Šå›æ¸¬
            test_cfg = self.base_cfg.copy()
            test_cfg["start"] = test_dates[0]
            test_cfg["end"] = test_dates[1]
            test_cfg["strategy_params"] = {
                **test_cfg.get("strategy_params", {}),
                **result.best_params,
            }
            
            test_stats_all = {}
            test_obj_values = []
            
            for symbol, data_path in self.symbol_data.items():
                try:
                    test_result = run_symbol_backtest(
                        symbol=symbol,
                        data_path=data_path,
                        cfg=test_cfg,
                        strategy_name=self.strategy_name,
                        market_type=self.market_type,
                        direction=self.direction,
                        data_dir=self.data_dir,
                    )
                    stats = test_result.stats
                    test_stats_all[symbol] = {
                        "total_return": stats.get("Total Return [%]", 0),
                        "sharpe_ratio": stats.get("Sharpe Ratio", 0),
                        "max_drawdown": stats.get("Max Drawdown [%]", 0),
                        "total_trades": stats.get("Total Trades", 0),
                    }
                    test_obj_values.append(objective_fn(stats))
                except Exception as e:
                    logger.warning(f"Fold {fold_i+1} test failed for {symbol}: {e}")
            
            test_obj = float(np.mean(test_obj_values)) if test_obj_values else -999
            
            fold = WalkForwardFold(
                fold_idx=fold_i + 1,
                train_start=train_dates[0],
                train_end=train_dates[1],
                test_start=test_dates[0],
                test_end=test_dates[1],
                best_params=result.best_params,
                train_objective=result.best_value,
                test_objective=test_obj,
                test_stats=test_stats_all,
            )
            self._folds.append(fold)
            
            logger.info(f"   Train obj: {result.best_value:.4f} â†’ Test obj: {test_obj:.4f}")
        
        # ç”Ÿæˆçµæœ DataFrame
        rows = []
        for f in self._folds:
            row = {
                "fold": f.fold_idx,
                "train_period": f"{f.train_start} â†’ {f.train_end}",
                "test_period": f"{f.test_start} â†’ {f.test_end}",
                "train_objective": f.train_objective,
                "test_objective": f.test_objective,
                "overfit_ratio": (f.train_objective / f.test_objective) if f.test_objective != 0 else float("inf"),
            }
            # åŠ å…¥æœ€ä½³åƒæ•¸
            for k, v in f.best_params.items():
                row[f"param_{k}"] = v
            rows.append(row)
        
        df = pd.DataFrame(rows)
        
        if not df.empty:
            avg_train = df["train_objective"].mean()
            avg_test = df["test_objective"].mean()
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“Š Walk-Forward Summary")
            logger.info(f"   Avg Train Objective: {avg_train:.4f}")
            logger.info(f"   Avg Test Objective:  {avg_test:.4f}")
            logger.info(f"   Overfit Ratio:       {avg_train/avg_test:.2f}x" if avg_test != 0 else "   Overfit Ratio: N/A")
            logger.info(f"   Test > 0 folds:      {(df['test_objective'] > 0).sum()}/{len(df)}")
            logger.info(f"{'='*60}")
        
        return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Train/Test OOS åˆ†å‰²å·¥å…·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def split_data_for_oos(
    data_path: Path,
    train_ratio: float = 0.7,
) -> tuple[Path, Path]:
    """
    å°‡æ•¸æ“šæŒ‰æ™‚é–“åˆ†å‰²ç‚º Train/Testï¼Œå¯«å…¥è‡¨æ™‚æª”æ¡ˆ
    
    Args:
        data_path: åŸå§‹æ•¸æ“šè·¯å¾‘
        train_ratio: è¨“ç·´é›†æ¯”ä¾‹
    
    Returns:
        (train_path, test_path)
    """
    from ..data.storage import load_klines
    
    df = load_klines(data_path)
    split_idx = int(len(df) * train_ratio)
    
    train_df = df.iloc[:split_idx]
    test_df = df.iloc[split_idx:]
    
    # å„²å­˜åˆ°è‡¨æ™‚ä½ç½®
    parent = data_path.parent
    stem = data_path.stem
    suffix = data_path.suffix
    
    train_path = parent / f"{stem}_train{suffix}"
    test_path = parent / f"{stem}_test{suffix}"
    
    train_df.to_parquet(train_path)
    test_df.to_parquet(test_path)
    
    logger.info(f"ğŸ“‚ Split data: Train {len(train_df)} bars ({train_df.index[0].strftime('%Y-%m-%d')} â†’ {train_df.index[-1].strftime('%Y-%m-%d')})")
    logger.info(f"              Test  {len(test_df)} bars ({test_df.index[0].strftime('%Y-%m-%d')} â†’ {test_df.index[-1].strftime('%Y-%m-%d')})")
    
    return train_path, test_path


def cleanup_oos_files(data_paths: dict[str, Path]) -> None:
    """æ¸…ç† OOS åˆ†å‰²ç”¢ç”Ÿçš„è‡¨æ™‚æª”æ¡ˆ"""
    for symbol, path in data_paths.items():
        for suffix in ["_train", "_test"]:
            tmp = path.parent / f"{path.stem}{suffix}{path.suffix}"
            if tmp.exists():
                tmp.unlink()
                logger.debug(f"Cleaned up: {tmp}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é å®šç¾©åƒæ•¸ç©ºé–“ï¼ˆå¸¸ç”¨ç­–ç•¥ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# RSI + ADX + ATR ç­–ç•¥ â€” æ ¸å¿ƒåƒæ•¸
RSI_ADX_ATR_PARAM_SPACE = {
    "rsi_period": ParamSpace.integer("rsi_period", 7, 28),
    "oversold": ParamSpace.float("oversold", 25, 40, step=5),
    "overbought": ParamSpace.float("overbought", 60, 80, step=5),
    "min_adx": ParamSpace.float("min_adx", 15, 35, step=5),
    "adx_period": ParamSpace.integer("adx_period", 10, 21),
    "stop_loss_atr": ParamSpace.float("stop_loss_atr", 1.5, 3.5, step=0.5),
    "take_profit_atr": ParamSpace.float("take_profit_atr", 2.0, 5.0, step=0.5),
    "atr_period": ParamSpace.integer("atr_period", 10, 21),
    "cooldown_bars": ParamSpace.integer("cooldown_bars", 3, 12),
}

# RSI + ADX + ATR â€” æ“´å±•åƒæ•¸ï¼ˆå« Dynamic RSI + Adaptive SL + HTFï¼‰
RSI_ADX_ATR_EXTENDED_PARAM_SPACE = {
    # æ ¸å¿ƒ
    "rsi_period": ParamSpace.integer("rsi_period", 7, 24),
    "min_adx": ParamSpace.float("min_adx", 12, 30, step=3),
    "short_min_adx": ParamSpace.float("short_min_adx", 15, 35, step=5),
    "adx_period": ParamSpace.integer("adx_period", 10, 21),
    "stop_loss_atr": ParamSpace.float("stop_loss_atr", 1.5, 3.0, step=0.5),
    "atr_period": ParamSpace.integer("atr_period", 10, 21),
    "cooldown_bars": ParamSpace.integer("cooldown_bars", 2, 8),
    "min_hold_bars": ParamSpace.integer("min_hold_bars", 1, 4),
    
    # Dynamic RSI
    "rsi_lookback_days": ParamSpace.integer("rsi_lookback_days", 7, 28),
    "rsi_quantile_low": ParamSpace.float("rsi_quantile_low", 0.05, 0.20, step=0.05),
    "rsi_quantile_high": ParamSpace.float("rsi_quantile_high", 0.80, 0.95, step=0.05),
    
    # Adaptive SL
    "er_sl_min": ParamSpace.float("er_sl_min", 1.0, 2.0, step=0.25),
    "er_sl_max": ParamSpace.float("er_sl_max", 2.0, 3.5, step=0.25),
    "adaptive_sl_er_period": ParamSpace.integer("adaptive_sl_er_period", 8, 14),
    
    # HTF soft weights
    "htf_ema_fast": ParamSpace.integer("htf_ema_fast", 10, 30),
    "htf_ema_slow": ParamSpace.integer("htf_ema_slow", 30, 70),
    "htf_counter_weight": ParamSpace.float("htf_counter_weight", 0.3, 0.7, step=0.1),
    "htf_neutral_weight": ParamSpace.float("htf_neutral_weight", 0.5, 0.9, step=0.1),
    
    # æ³¢å‹•ç‡éæ¿¾
    "min_atr_ratio": ParamSpace.float("min_atr_ratio", 0.003, 0.010, step=0.001),
    
    # æ³¢å‹•ç‡ Regime å€‰ä½ç¸®æ”¾
    "vol_regime_low_pct": ParamSpace.float("vol_regime_low_pct", 20, 50, step=5),
    "vol_regime_low_weight": ParamSpace.float("vol_regime_low_weight", 0.3, 0.7, step=0.1),
    "vol_regime_lookback": ParamSpace.integer("vol_regime_lookback", 96, 336),  # 4å¤©~14å¤©
}

# EMA Cross ç­–ç•¥çš„åƒæ•¸ç©ºé–“ï¼ˆé ç•™ï¼‰
EMA_CROSS_PARAM_SPACE = {
    "fast_period": ParamSpace.integer("fast_period", 5, 20),
    "slow_period": ParamSpace.integer("slow_period", 20, 100),
    "signal_period": ParamSpace.integer("signal_period", 5, 15),
}

# TSMOM ç­–ç•¥ â€” æ ¸å¿ƒåƒæ•¸
TSMOM_PARAM_SPACE = {
    "lookback": ParamSpace.integer("lookback", 48, 720),
    "vol_target": ParamSpace.float("vol_target", 0.05, 0.30, step=0.05),
}

# TSMOM + EMA â€” æ“´å±•åƒæ•¸
TSMOM_EMA_PARAM_SPACE = {
    "lookback": ParamSpace.integer("lookback", 48, 720),
    "vol_target": ParamSpace.float("vol_target", 0.05, 0.30, step=0.05),
    "ema_fast": ParamSpace.integer("ema_fast", 10, 30),
    "ema_slow": ParamSpace.integer("ema_slow", 30, 100),
    "agree_weight": ParamSpace.float("agree_weight", 0.8, 1.2, step=0.1),
    "disagree_weight": ParamSpace.float("disagree_weight", 0.1, 0.5, step=0.1),
}

# TSMOM Multi + EMA â€” å…¨åƒæ•¸ç©ºé–“
TSMOM_MULTI_EMA_PARAM_SPACE = {
    "vol_target": ParamSpace.float("vol_target", 0.05, 0.30, step=0.05),
    "ema_fast": ParamSpace.integer("ema_fast", 10, 30),
    "ema_slow": ParamSpace.integer("ema_slow", 30, 100),
    "agree_weight": ParamSpace.float("agree_weight", 0.8, 1.2, step=0.1),
    "disagree_weight": ParamSpace.float("disagree_weight", 0.1, 0.5, step=0.1),
    "vol_regime_enabled": ParamSpace.categorical("vol_regime_enabled", [True, False]),
    "vol_regime_lookback": ParamSpace.integer("vol_regime_lookback", 100, 300),
    "vol_regime_low_pct": ParamSpace.float("vol_regime_low_pct", 20.0, 40.0, step=5.0),
    "vol_regime_low_weight": ParamSpace.float("vol_regime_low_weight", 0.3, 0.7, step=0.1),
}

# é å®šç¾©ç©ºé–“åç¨±æŸ¥æ‰¾
XSMOM_PARAM_SPACE = {
    "lookbacks": ParamSpace.categorical("lookbacks", [
        "[336,720,1440]", "[336,720]", "[720,1440]", "[336,720,1440,2160]",
    ]),
    "skip_recent": ParamSpace.integer("skip_recent", 0, 72, step=24),
    "use_residual": ParamSpace.categorical("use_residual", [True, False]),
    "long_threshold": ParamSpace.float("long_threshold", 0.6, 0.8, step=0.05),
    "short_threshold": ParamSpace.float("short_threshold", 0.2, 0.4, step=0.05),
    "vol_target": ParamSpace.float("vol_target", 0.10, 0.30, step=0.05),
    "scale_mode": ParamSpace.categorical("scale_mode", ["threshold", "linear"]),
}

XSMOM_TSMOM_PARAM_SPACE = {
    **XSMOM_PARAM_SPACE,
    "xsmom_weight": ParamSpace.float("xsmom_weight", 0.2, 0.5, step=0.1),
    "tsmom_weight": ParamSpace.float("tsmom_weight", 0.5, 0.8, step=0.1),
    "tsmom_lookback": ParamSpace.integer("tsmom_lookback", 72, 336, step=24),
    "ema_fast": ParamSpace.integer("ema_fast", 10, 30),
    "ema_slow": ParamSpace.integer("ema_slow", 40, 80),
}

PREDEFINED_SPACES = {
    "rsi_adx_atr": RSI_ADX_ATR_PARAM_SPACE,
    "rsi_adx_atr_extended": RSI_ADX_ATR_EXTENDED_PARAM_SPACE,
    "ema_cross": EMA_CROSS_PARAM_SPACE,
    "tsmom": TSMOM_PARAM_SPACE,
    "tsmom_ema": TSMOM_EMA_PARAM_SPACE,
    "tsmom_multi_ema": TSMOM_MULTI_EMA_PARAM_SPACE,
    "xsmom": XSMOM_PARAM_SPACE,
    "xsmom_tsmom": XSMOM_TSMOM_PARAM_SPACE,
}


def get_param_space(name: str) -> dict[str, ParamDef]:
    """æ ¹æ“šåç¨±ç²å–é å®šç¾©åƒæ•¸ç©ºé–“"""
    if name in PREDEFINED_SPACES:
        return PREDEFINED_SPACES[name]
    raise ValueError(f"Unknown param space: {name}. Available: {list(PREDEFINED_SPACES.keys())}")
