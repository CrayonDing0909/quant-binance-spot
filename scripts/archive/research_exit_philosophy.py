#!/usr/bin/env python3
"""
å‡ºå ´å“²å­¸é©—è­‰ç ”ç©¶

æ¯”è¼ƒä¸‰ç¨®å‡ºå ´å“²å­¸åœ¨ TSMOM-EMA ç­–ç•¥ä¸Šçš„è¡¨ç¾ï¼š
  1) Trend-hold   â€” ç„¡ TPï¼Œå¯¬ SLï¼ˆç½é›£å‹ï¼‰ï¼Œç­–ç•¥åè½‰å‡ºå ´
  2) Hybrid-lock  â€” ç„¡ç¡¬ TPï¼Œtrailing stop é–ç›ˆ
  3) Mean-revert-take â€” å›ºå®š TP + SLï¼Œæ˜ç¢ºå‡ºå ´ç¯€å¥

Requirements:
  - å·²ä¸‹è¼‰ ETHUSDT / SOLUSDT / BTCUSDT 1h Futures K ç·š & funding rate
  - source .venv/bin/activate

Usage:
  PYTHONPATH=src python scripts/research_exit_philosophy.py
  PYTHONPATH=src python scripts/research_exit_philosophy.py --symbols ETHUSDT SOLUSDT
  PYTHONPATH=src python scripts/research_exit_philosophy.py --quick   # å¿«é€Ÿæ¨¡å¼ï¼ˆåªè·‘ ETHUSDT, æ¸›å°‘åƒæ•¸ï¼‰
"""
from __future__ import annotations

import argparse
import json
import logging
import warnings
from dataclasses import dataclass, field
from datetime import datetime
from itertools import product
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd

# â”€â”€ Project imports â”€â”€
from qtrade.data.storage import load_klines
from qtrade.data.quality import validate_data_quality, clean_data
from qtrade.data.funding_rate import load_funding_rates, get_funding_rate_path, align_funding_to_klines
from qtrade.strategy.base import StrategyContext
from qtrade.strategy import get_strategy
from qtrade.strategy.exit_rules import apply_exit_rules
from qtrade.backtest.run_backtest import (
    clip_positions_by_direction,
    to_vbt_direction,
    BacktestResult,
)
from qtrade.backtest.costs import compute_funding_costs, adjust_equity_for_funding, compute_adjusted_stats
from qtrade.backtest.metrics import trade_analysis, benchmark_buy_and_hold
from qtrade.indicators.atr import calculate_atr

try:
    import vectorbt as vbt
except ImportError:
    raise ImportError("vectorbt is required: pip install vectorbt")

warnings.filterwarnings("ignore", category=FutureWarning)
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger("exit_philosophy")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å¸¸æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATA_DIR = Path("data")
RESULTS_DIR = Path("reports/research/exit_philosophy")

# å›æ¸¬åŸºæœ¬åƒæ•¸ï¼ˆèˆ‡ prod ä¸€è‡´ï¼‰
BASE_CFG = dict(
    strategy_name="tsmom_ema",
    strategy_params=dict(
        lookback=168,
        vol_target=0.15,
        ema_fast=20,
        ema_slow=50,
        agree_weight=1.0,
        disagree_weight=0.3,
    ),
    initial_cash=10_000,
    fee_bps=5,
    slippage_bps=3,
    interval="1h",
    market_type="futures",
    direction="both",
    trade_on="next_open",
    leverage=3,
    validate_data=True,
    clean_data_before=True,
    funding_rate=dict(enabled=True, default_rate_8h=0.0001, use_historical=True),
    slippage_model=dict(enabled=False),
    position_sizing=dict(method="fixed", position_pct=1.0),
)

# æ™‚é–“åˆ†å‰²
PERIODS = {
    "IS":   ("2022-01-01", "2024-06-30"),   # In-sample
    "OOS":  ("2024-07-01", "2025-06-30"),   # Out-of-sample
    "Live": ("2025-07-01", None),           # Live-recent
    "Full": ("2022-01-01", None),           # å…¨æ®µ
}

DEFAULT_SYMBOLS = ["ETHUSDT", "SOLUSDT", "BTCUSDT"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  åƒæ•¸çŸ©é™£å®šç¾©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ExitConfig:
    """å–®ä¸€å‡ºå ´é…ç½®"""
    name: str
    philosophy: str  # "baseline", "trend_hold", "hybrid_lock", "mean_revert_take"
    stop_loss_atr: Optional[float] = None
    take_profit_atr: Optional[float] = None
    trailing_stop_atr: Optional[float] = None
    cooldown_bars: int = 0
    label: str = ""

    def __post_init__(self):
        if not self.label:
            parts = [self.philosophy]
            if self.stop_loss_atr is not None:
                parts.append(f"SL{self.stop_loss_atr}")
            if self.take_profit_atr is not None:
                parts.append(f"TP{self.take_profit_atr}")
            if self.trailing_stop_atr is not None:
                parts.append(f"TR{self.trailing_stop_atr}")
            parts.append(f"CD{self.cooldown_bars}")
            self.label = "_".join(parts)


def build_param_grid(quick: bool = False) -> list[ExitConfig]:
    """æ§‹å»ºåƒæ•¸ç¶²æ ¼

    è¨­è¨ˆåŸå‰‡ï¼š
      - Trend-hold: å¯¬ SLï¼ˆç½é›£å‹ï¼‰ï¼Œè®“è¶¨å‹¢è‡ªç„¶çµæŸã€‚SL 4-7Ã— ATRã€‚
      - Hybrid-lock: SL + Trailingï¼Œä¸è¨­ç¡¬ TPã€‚Trailing é–ç›ˆè€Œéæˆªæ–·åˆ©æ½¤ã€‚
      - Mean-revert-take: SL + TPï¼Œæ˜ç¢ºå‡ºå ´ç¯€å¥ã€‚TP 2-5Ã— ATRã€‚
      - Cooldown: 0 (æœ€è²¼è¿‘å¯¦ç›¤) å’Œ 3 (é˜²æ­¢ whipsaw re-entry)

    IMPORTANT: æ‰€æœ‰ exit overlay ä¿ç•™ TSMOM é€£çºŒä¿¡è™Ÿçš„ magnitudeï¼Œ
    åªåœ¨ SL/TP/cooldown æ™‚å¼·åˆ¶ flatã€‚
    """
    configs = []

    # â”€â”€ B0: åŸºæº–ï¼ˆç¾è¡Œè£¸ TSMOMï¼Œèˆ‡ production ä¸€è‡´ï¼‰â”€â”€
    configs.append(ExitConfig(
        name="B0_baseline",
        philosophy="baseline",
        stop_loss_atr=None,
        take_profit_atr=None,
        trailing_stop_atr=None,
        cooldown_bars=0,
        label="B0_baseline",
    ))

    # â”€â”€ Trend-hold: å¯¬ SLï¼ˆç½é›£å‹ä¿è­·ï¼‰ï¼Œç„¡ TPï¼Œç„¡ trailing â”€â”€
    # ç†å¿µï¼šè®“è¶¨å‹¢ä¿¡è™Ÿè‡ªç„¶ç®¡ç†å‡ºå ´ï¼ŒSL åƒ…ä½œç‚ºé»‘å¤©éµä¿è­·
    sl_vals = [3.5, 5.0, 7.0] if not quick else [5.0]
    cd_vals = [0, 3] if not quick else [0]
    for sl, cd in product(sl_vals, cd_vals):
        configs.append(ExitConfig(
            name=f"TH_SL{sl}_CD{cd}",
            philosophy="trend_hold",
            stop_loss_atr=sl,
            take_profit_atr=None,
            trailing_stop_atr=None,
            cooldown_bars=cd,
        ))

    # â”€â”€ Hybrid-lock: SL + Trailingï¼Œç„¡ TP â”€â”€
    # ç†å¿µï¼šä¿è­·æµ®ç›ˆï¼Œä½†ä¸è¨­ç¡¬å¤©èŠ±æ¿ã€‚Trailing è·Ÿè¹¤æ¥µå€¼ã€‚
    sl_vals = [3.0, 4.0, 5.0] if not quick else [4.0]
    tr_vals = [2.0, 3.0, 4.0] if not quick else [3.0]
    cd_vals = [0, 3] if not quick else [0]
    for sl, tr, cd in product(sl_vals, tr_vals, cd_vals):
        # trailing å¿…é ˆ <= SLï¼Œå¦å‰‡æ°¸é å…ˆè§¸ç™¼ trailing
        if tr > sl:
            continue
        configs.append(ExitConfig(
            name=f"HL_SL{sl}_TR{tr}_CD{cd}",
            philosophy="hybrid_lock",
            stop_loss_atr=sl,
            take_profit_atr=None,
            trailing_stop_atr=tr,
            cooldown_bars=cd,
        ))

    # â”€â”€ Mean-revert-take: SL + TPï¼Œç„¡ trailing â”€â”€
    # ç†å¿µï¼šå›ºå®šç¯€å¥å‡ºå ´ï¼Œé©åˆå‡å€¼å›æ­¸å‹åˆ©æ½¤
    sl_vals = [2.5, 3.5, 5.0] if not quick else [3.5]
    tp_vals = [2.0, 3.0, 5.0] if not quick else [3.0]
    cd_vals = [0, 3] if not quick else [0]
    for sl, tp, cd in product(sl_vals, tp_vals, cd_vals):
        configs.append(ExitConfig(
            name=f"MR_SL{sl}_TP{tp}_CD{cd}",
            philosophy="mean_revert_take",
            stop_loss_atr=sl,
            take_profit_atr=tp,
            trailing_stop_atr=None,
            cooldown_bars=cd,
        ))

    print(f"ğŸ“Š åƒæ•¸ç¶²æ ¼: {len(configs)} çµ„ "
          f"(baseline=1, trend_hold={sum(1 for c in configs if c.philosophy=='trend_hold')}, "
          f"hybrid_lock={sum(1 for c in configs if c.philosophy=='hybrid_lock')}, "
          f"mean_revert_take={sum(1 for c in configs if c.philosophy=='mean_revert_take')})")
    return configs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  æ ¸å¿ƒå›æ¸¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _load_and_prepare(symbol: str) -> pd.DataFrame:
    """è¼‰å…¥ + æ¸…æ´— K ç·šæ•¸æ“š"""
    data_path = DATA_DIR / "binance" / "futures" / "1h" / f"{symbol}.parquet"
    if not data_path.exists():
        raise FileNotFoundError(f"Data not found: {data_path}")
    df = load_klines(data_path)
    df = clean_data(df, fill_method="forward", remove_outliers=False, remove_duplicates=True)
    return df


def _generate_raw_signal(df: pd.DataFrame, symbol: str) -> pd.Series:
    """ç”¢ç”Ÿ TSMOM-EMA raw signalï¼ˆå« signal_delayï¼‰"""
    ctx = StrategyContext(
        symbol=symbol,
        interval="1h",
        market_type="futures",
        direction="both",
        signal_delay=1,  # trade_on=next_open
    )
    strategy_func = get_strategy("tsmom_ema")
    raw_pos = strategy_func(df, ctx, BASE_CFG["strategy_params"])
    return raw_pos


def _apply_exit_overlay(
    df: pd.DataFrame,
    raw_pos: pd.Series,
    ecfg: ExitConfig,
) -> tuple[pd.Series, pd.Series]:
    """
    å¥—ç”¨å‡ºå ´å“²å­¸ overlay

    CRITICAL: apply_exit_rules è¼¸å‡º binary positions (Â±1 / 0)ï¼Œ
    ä½† TSMOM ç”¢ç”Ÿé€£çºŒä¿¡è™Ÿ (e.g. 0.3, -0.7)ã€‚
    ç›´æ¥ç”¨ binary æœƒæ”¹è®Šæ§“æ¡¿å’Œç­–ç•¥ç‰¹æ€§ã€‚

    ä¿®æ­£æ–¹æ¡ˆï¼š
      - ç”¨ apply_exit_rules åˆ¤æ–· WHEN SL/TP/cooldown å¼·åˆ¶å¹³å€‰
      - å¼·åˆ¶å¹³å€‰æ™‚ â†’ pos = 0ï¼ˆå°Šé‡ exit_rules çš„ä¿è­·åŠŸèƒ½ï¼‰
      - éå¹³å€‰æ™‚ â†’ ä¿ç•™åŸå§‹ raw_pos çš„é€£çºŒ magnitude
      - exec_prices ä¿æŒä¸è®Šï¼ˆSL/TP å‡ºå ´åƒ¹æ ¼ï¼‰

    Returns:
        (positions, exec_prices)
    """
    if ecfg.philosophy == "baseline":
        # ç„¡ exit rulesï¼Œä¿ç•™åŸå§‹ä¿¡è™Ÿ
        exec_prices = pd.Series(np.nan, index=df.index)
        return raw_pos, exec_prices

    binary_pos, exec_prices = apply_exit_rules(
        df, raw_pos,
        stop_loss_atr=ecfg.stop_loss_atr,
        take_profit_atr=ecfg.take_profit_atr,
        trailing_stop_atr=ecfg.trailing_stop_atr,
        atr_period=14,
        cooldown_bars=ecfg.cooldown_bars,
    )

    # Merge: preserve continuous magnitude, respect forced-flat
    # binary_pos == 0 means: SL/TP triggered, cooldown, or signal-driven exit
    # binary_pos != 0 means: position held / entered
    result = raw_pos.copy()
    forced_flat = binary_pos == 0.0
    result[forced_flat] = 0.0

    return result, exec_prices


def _run_single_backtest(
    df: pd.DataFrame,
    pos: pd.Series,
    exec_prices: pd.Series,
    symbol: str,
    start: Optional[str] = None,
    end: Optional[str] = None,
    fee_bps: float = 5.0,
    slippage_bps: float = 3.0,
) -> Optional[dict]:
    """
    å–®æ¬¡å›æ¸¬ â†’ æ¨™æº–æŒ‡æ¨™ dict

    åš´æ ¼éµå®ˆï¼š
      - price=openï¼ˆnext_open æ©Ÿåˆ¶å·²ç”± signal_delay è™•ç†ï¼‰
      - SL/TP ç”¨ exec_prices ä¿®æ­£ï¼ˆæ¶ˆé™¤ look-aheadï¼‰
      - å« funding rate æˆæœ¬
    """
    # æ—¥æœŸéæ¿¾
    df_bt = df.copy()
    pos_bt = pos.copy()
    ep_bt = exec_prices.copy()

    if start:
        start_ts = pd.Timestamp(start, tz="UTC") if df_bt.index.tz else pd.Timestamp(start)
        mask = df_bt.index >= start_ts
        df_bt, pos_bt, ep_bt = df_bt.loc[mask], pos_bt.loc[mask], ep_bt.loc[mask]
    if end:
        end_ts = pd.Timestamp(end, tz="UTC") if df_bt.index.tz else pd.Timestamp(end)
        mask = df_bt.index <= end_ts
        df_bt, pos_bt, ep_bt = df_bt.loc[mask], pos_bt.loc[mask], ep_bt.loc[mask]

    if len(df_bt) < 500:
        return None  # æ•¸æ“šä¸è¶³

    # direction clip
    pos_bt = clip_positions_by_direction(pos_bt, "futures", "both")

    close = df_bt["close"]
    open_ = df_bt["open"]

    # æ§‹å»ºåŸ·è¡Œåƒ¹æ ¼
    exec_price = open_.copy()
    sl_tp_mask = ep_bt.notna()
    if sl_tp_mask.any():
        exec_price[sl_tp_mask] = ep_bt[sl_tp_mask]

    fee = fee_bps / 10_000.0
    slippage = slippage_bps / 10_000.0

    # VBT Portfolio
    pf = vbt.Portfolio.from_orders(
        close=close,
        size=pos_bt,
        size_type="targetpercent",
        price=exec_price,
        fees=fee,
        slippage=slippage,
        init_cash=BASE_CFG["initial_cash"],
        freq="1h",
        direction="both",
    )

    stats = pf.stats()
    equity = pf.value()

    # Funding rate adjustment
    fr_cost = None
    adj_equity = None
    adj_stats_dict = None

    try:
        fr_path = get_funding_rate_path(DATA_DIR, symbol)
        fr_df = load_funding_rates(fr_path)
        if fr_df is not None:
            fr_aligned = align_funding_to_klines(
                fr_df, df_bt.index, default_rate_8h=0.0001
            )
            fr_cost = compute_funding_costs(
                pos=pos_bt, equity=equity,
                funding_rates=fr_aligned, leverage=3,
            )
            adj_equity = adjust_equity_for_funding(equity, fr_cost)
            adj_stats_dict = compute_adjusted_stats(adj_equity, BASE_CFG["initial_cash"])
    except Exception:
        pass

    # è¨ˆç®—æŒ‡æ¨™
    use_stats = adj_stats_dict if adj_stats_dict else stats
    use_equity = adj_equity if adj_equity is not None else equity

    total_ret_pct = _safe_get(use_stats, "Total Return [%]", 0.0)
    max_dd_pct = abs(_safe_get(use_stats, "Max Drawdown [%]", 0.0))
    sharpe = _safe_get(use_stats, "Sharpe Ratio", 0.0)
    sortino = _safe_get(use_stats, "Sortino Ratio", 0.0)
    calmar = _safe_get(use_stats, "Calmar Ratio", 0.0)

    # è¨ˆç®—å¹´æ•¸å’Œ CAGR
    days = (df_bt.index[-1] - df_bt.index[0]).total_seconds() / 86400
    years = max(days / 365.25, 0.01)
    if total_ret_pct > -100:
        cagr = ((1 + total_ret_pct / 100) ** (1 / years) - 1) * 100
    else:
        cagr = -100.0

    # MAR = CAGR / MaxDD
    mar = cagr / max_dd_pct if max_dd_pct > 0 else 0.0

    # äº¤æ˜“åˆ†æ
    trades_df = trade_analysis(pf)
    n_trades = len(trades_df[trades_df["Status"] == "Closed"]) if not trades_df.empty else 0
    ann_trades = n_trades / years if years > 0 else 0

    # å‹ç‡ & profit factor
    if not trades_df.empty:
        closed = trades_df[trades_df["Status"] == "Closed"]
        winners = closed[closed["PnL"] > 0]
        losers = closed[closed["PnL"] < 0]
        win_rate = len(winners) / len(closed) * 100 if len(closed) > 0 else 0
        gross_profit = winners["PnL"].sum() if len(winners) > 0 else 0
        gross_loss = abs(losers["PnL"].sum()) if len(losers) > 0 else 1e-9
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else 0
    else:
        win_rate = 0
        profit_factor = 0
        closed = pd.DataFrame()

    # å¹³å‡æŒæœ‰æ™‚é–“ï¼ˆå°æ™‚ï¼‰
    avg_hold_hours = 0
    if not trades_df.empty and "Duration" in trades_df.columns:
        closed_dur = trades_df[trades_df["Status"] == "Closed"]["Duration"]
        if len(closed_dur) > 0:
            avg_hold_hours = closed_dur.mean().total_seconds() / 3600

    # Turnoverï¼ˆå¹´åŒ–æ›æ‰‹ï¼‰
    pos_changes = pos_bt.diff().abs()
    total_turnover = pos_changes.sum()
    ann_turnover = total_turnover / years if years > 0 else 0

    # äº¤æ˜“æˆæœ¬å æ¯”
    pf_gross_equity = pf.value()  # pre-cost equity approximation
    total_fees = n_trades * 2 * fee * BASE_CFG["initial_cash"]  # rough
    fee_pct = total_fees / BASE_CFG["initial_cash"] * 100 if BASE_CFG["initial_cash"] > 0 else 0
    funding_pct = fr_cost.total_cost_pct * 100 if fr_cost else 0

    return {
        "CAGR [%]": round(cagr, 2),
        "Sharpe": round(sharpe, 3),
        "Sortino": round(sortino, 3),
        "Calmar": round(calmar, 3),
        "MaxDD [%]": round(max_dd_pct, 2),
        "MAR": round(mar, 3),
        "Total Return [%]": round(total_ret_pct, 2),
        "Ann. Trades": round(ann_trades, 1),
        "Turnover": round(ann_turnover, 1),
        "Win Rate [%]": round(win_rate, 1),
        "Profit Factor": round(profit_factor, 2),
        "Avg Hold [h]": round(avg_hold_hours, 1),
        "Fee Cost [%]": round(fee_pct, 2),
        "Funding Cost [%]": round(funding_pct, 2),
        "N Trades": n_trades,
        "Years": round(years, 2),
        # raw objects for diagnostics
        "_pf": pf,
        "_trades_df": trades_df,
        "_equity": use_equity,
        "_pos": pos_bt,
    }


def _safe_get(obj, key, default=0.0):
    """Safe get from pd.Series or dict"""
    if isinstance(obj, dict):
        return obj.get(key, default)
    try:
        return obj.get(key, default)
    except Exception:
        return default


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å³å°¾è¨ºæ–·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_tail_diagnostics(result: dict) -> dict:
    """
    è¨ˆç®—å³å°¾/é«˜å‹ç‡è¨ºæ–·ï¼š
      - Top 10% äº¤æ˜“å°ç¸½æ”¶ç›Šè²¢ç»
      - å»é™¤ Top N äº¤æ˜“å¾Œç¸¾æ•ˆè¡°æ¸›
      - MFE/MAE åˆ†å¸ƒ
      - æµ®ç›ˆå›ååˆ†å¸ƒ
    """
    trades_df = result.get("_trades_df")
    pf = result.get("_pf")
    if trades_df is None or trades_df.empty:
        return {}

    closed = trades_df[trades_df["Status"] == "Closed"].copy()
    if len(closed) < 5:
        return {}

    pnl = closed["PnL"].values
    total_pnl = pnl.sum()
    n = len(pnl)

    # â”€â”€ Top 10% contribution â”€â”€
    sorted_pnl = np.sort(pnl)[::-1]  # descending
    top_n = max(1, int(np.ceil(n * 0.1)))
    top10_pnl = sorted_pnl[:top_n].sum()
    top10_contrib = top10_pnl / total_pnl * 100 if total_pnl != 0 else 0

    # â”€â”€ Remove top N analysis â”€â”€
    remove_top = {}
    for k in [1, 3, 5]:
        if k >= n:
            continue
        remaining_pnl = sorted_pnl[k:].sum()
        decay = (1 - remaining_pnl / total_pnl) * 100 if total_pnl != 0 else 0
        remove_top[f"Remove Top{k} Decay [%]"] = round(decay, 1)

    # â”€â”€ MFE/MAE from positions â”€â”€
    # Use vectorbt positions if available
    mfe_mae = {}
    try:
        positions = pf.positions.records_readable
        if len(positions) > 0 and "PnL" in positions.columns:
            # Approximate MFE/MAE from returns
            returns_arr = closed["Return [%]"].values
            mfe_mae["Avg Trade Return [%]"] = round(np.mean(returns_arr), 2)
            mfe_mae["Std Trade Return [%]"] = round(np.std(returns_arr), 2)
            mfe_mae["Skew Trade Return"] = round(float(pd.Series(returns_arr).skew()), 2)
            mfe_mae["Kurt Trade Return"] = round(float(pd.Series(returns_arr).kurtosis()), 2)
            # Positive PnL skew â†’ right-tail driven
            mfe_mae["Median Trade Return [%]"] = round(float(np.median(returns_arr)), 2)
    except Exception:
        pass

    return {
        "Top 10% PnL Contribution [%]": round(top10_contrib, 1),
        "Top 10% Count": top_n,
        **remove_top,
        **mfe_mae,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  æˆæœ¬å£“æ¸¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_cost_sensitivity(
    df: pd.DataFrame,
    pos: pd.Series,
    exec_prices: pd.Series,
    symbol: str,
    ecfg: ExitConfig,
) -> list[dict]:
    """fee/slippage Â±20% å£“æ¸¬"""
    base_fee = BASE_CFG["fee_bps"]
    base_slip = BASE_CFG["slippage_bps"]
    results = []

    for fee_mult, slip_mult, label in [
        (1.0,  1.0,  "Base"),
        (1.2,  1.0,  "Fee+20%"),
        (0.8,  1.0,  "Fee-20%"),
        (1.0,  1.2,  "Slip+20%"),
        (1.0,  0.8,  "Slip-20%"),
        (1.2,  1.2,  "Both+20%"),
    ]:
        r = _run_single_backtest(
            df, pos, exec_prices, symbol,
            start="2022-01-01", end=None,
            fee_bps=base_fee * fee_mult,
            slippage_bps=base_slip * slip_mult,
        )
        if r:
            results.append({
                "Scenario": label,
                "Config": ecfg.label,
                "CAGR [%]": r["CAGR [%]"],
                "Sharpe": r["Sharpe"],
                "MaxDD [%]": r["MaxDD [%]"],
            })
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ä¸»æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description="å‡ºå ´å“²å­¸é©—è­‰ç ”ç©¶")
    parser.add_argument("--symbols", nargs="+", default=DEFAULT_SYMBOLS,
                        help="äº¤æ˜“å°åˆ—è¡¨")
    parser.add_argument("--quick", action="store_true",
                        help="å¿«é€Ÿæ¨¡å¼ï¼ˆæ¸›å°‘åƒæ•¸çµ„åˆï¼‰")
    parser.add_argument("--no-sensitivity", action="store_true",
                        help="è·³éæˆæœ¬å£“æ¸¬")
    args = parser.parse_args()

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = RESULTS_DIR / timestamp
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 70)
    print("  ğŸ“Š å‡ºå ´å“²å­¸é©—è­‰ç ”ç©¶ (Exit Philosophy Research)")
    print("=" * 70)
    print(f"  Symbols:    {args.symbols}")
    print(f"  Quick mode: {args.quick}")
    print(f"  Output:     {output_dir}")
    print()

    # â”€â”€ 1. æ§‹å»ºåƒæ•¸ç¶²æ ¼ â”€â”€
    grid = build_param_grid(quick=args.quick)

    # â”€â”€ 2. é€å¹£ç¨®å›æ¸¬ â”€â”€
    all_results = []  # [{symbol, config, period, ...metrics}]
    all_tail = []     # [{symbol, config, ...diagnostics}]
    all_sensitivity = []

    for symbol in args.symbols:
        print(f"\n{'â•' * 60}")
        print(f"  ğŸ“ˆ {symbol}")
        print(f"{'â•' * 60}")

        try:
            df = _load_and_prepare(symbol)
        except FileNotFoundError as e:
            print(f"  âš ï¸  {e} â€” è·³é")
            continue

        # ç”¢ç”Ÿ raw signalï¼ˆåœ¨å®Œæ•´æ•¸æ“šä¸Šï¼‰
        raw_pos = _generate_raw_signal(df, symbol)
        print(f"  Raw signal: {len(df):,} bars, "
              f"long={( raw_pos > 0.01).sum():,}, "
              f"short={(raw_pos < -0.01).sum():,}, "
              f"flat={(raw_pos.abs() <= 0.01).sum():,}")

        for i, ecfg in enumerate(grid):
            # å¥—ç”¨å‡ºå ´ overlayï¼ˆåœ¨å®Œæ•´æ•¸æ“šä¸Šï¼‰
            pos, exec_prices = _apply_exit_overlay(df, raw_pos, ecfg)

            # å„æ™‚æ®µå›æ¸¬
            for period_name, (p_start, p_end) in PERIODS.items():
                r = _run_single_backtest(
                    df, pos, exec_prices, symbol,
                    start=p_start, end=p_end,
                )
                if r is None:
                    continue

                row = {
                    "Symbol": symbol,
                    "Config": ecfg.label,
                    "Philosophy": ecfg.philosophy,
                    "Period": period_name,
                    "SL": ecfg.stop_loss_atr,
                    "TP": ecfg.take_profit_atr,
                    "Trail": ecfg.trailing_stop_atr,
                    "CD": ecfg.cooldown_bars,
                }
                for k, v in r.items():
                    if not k.startswith("_"):
                        row[k] = v
                all_results.append(row)

                # å³å°¾è¨ºæ–·ï¼ˆåªåœ¨ Full æœŸé–“ç®—ï¼‰
                if period_name == "Full":
                    tail = compute_tail_diagnostics(r)
                    if tail:
                        tail_row = {"Symbol": symbol, "Config": ecfg.label, "Philosophy": ecfg.philosophy}
                        tail_row.update(tail)
                        all_tail.append(tail_row)

            # æˆæœ¬å£“æ¸¬ï¼ˆåªå° Full æœŸé–“ã€æœ€ä½³å€™é¸ + baselineï¼‰
            if not args.no_sensitivity and ecfg.philosophy == "baseline":
                sens = run_cost_sensitivity(df, pos, exec_prices, symbol, ecfg)
                for s in sens:
                    s["Symbol"] = symbol
                all_sensitivity.extend(sens)

            if (i + 1) % 10 == 0 or i == len(grid) - 1:
                print(f"  ... {i + 1}/{len(grid)} configs done")

    # â”€â”€ 3. å½™æ•´çµæœ â”€â”€
    results_df = pd.DataFrame(all_results)
    tail_df = pd.DataFrame(all_tail)
    sens_df = pd.DataFrame(all_sensitivity) if all_sensitivity else pd.DataFrame()

    # å„²å­˜åŸå§‹æ•¸æ“š
    results_df.to_csv(output_dir / "raw_results.csv", index=False)
    if not tail_df.empty:
        tail_df.to_csv(output_dir / "tail_diagnostics.csv", index=False)
    if not sens_df.empty:
        sens_df.to_csv(output_dir / "cost_sensitivity.csv", index=False)

    # â”€â”€ 4. ç”¢ç”Ÿå ±è¡¨ â”€â”€
    print(f"\n{'â•' * 70}")
    print("  ğŸ“Š çµæœå½™æ•´")
    print(f"{'â•' * 70}")

    # â”€â”€ ä¸»è¡¨ 1: æ¯ç¨®å“²å­¸ Ã— å…¨æ®µ çš„æœ€ä½³ & åŸºæº– â”€â”€
    _print_main_table(results_df, output_dir)

    # â”€â”€ ä¸»è¡¨ 2: å¤šæ™‚æ®µç©©å¥æ€§ â”€â”€
    _print_period_comparison(results_df, output_dir)

    # â”€â”€ ä¸»è¡¨ 3: å³å°¾è¨ºæ–· â”€â”€
    if not tail_df.empty:
        _print_tail_table(tail_df, output_dir)

    # â”€â”€ ä¸»è¡¨ 4: æˆæœ¬å£“æ¸¬ â”€â”€
    if not sens_df.empty:
        _print_sensitivity_table(sens_df, output_dir)

    # â”€â”€ ä¸»è¡¨ 5: å¯¦ç›¤è²¼è¿‘å·®ç•°å ±å‘Š â”€â”€
    _print_live_diff_report(output_dir)

    # â”€â”€ ä¸»è¡¨ 6: ä¿¡è™Ÿç‰¹æ€§åˆ†æï¼ˆbaselineï¼‰â”€â”€
    _print_signal_analysis(results_df, output_dir)

    # â”€â”€ çµè«– â”€â”€
    _print_conclusion(results_df, tail_df, output_dir)

    # å„²å­˜ metadata
    meta = {
        "timestamp": timestamp,
        "symbols": args.symbols,
        "quick_mode": args.quick,
        "n_configs": len(grid),
        "periods": {k: list(v) for k, v in PERIODS.items()},
        "base_cfg": {k: v for k, v in BASE_CFG.items() if k != "strategy_params"},
    }
    with open(output_dir / "metadata.json", "w") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False, default=str)

    print(f"\nâœ… å®Œæ•´çµæœå·²å„²å­˜: {output_dir}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å ±è¡¨è¼¸å‡ºå‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _print_main_table(results_df: pd.DataFrame, output_dir: Path):
    """ä¸»è¡¨: æ¯ç¨®å“²å­¸çš„æœ€ä½³èˆ‡åŸºæº–"""
    if results_df.empty:
        return

    full = results_df[results_df["Period"] == "Full"].copy()
    if full.empty:
        return

    # æŒ‰å“²å­¸èšåˆï¼ˆè·¨å¹£ç¨®å¹³å‡ï¼‰
    cols = ["Config", "Philosophy", "CAGR [%]", "Sharpe", "Sortino", "Calmar",
            "MaxDD [%]", "MAR", "Ann. Trades", "Turnover", "Win Rate [%]",
            "Profit Factor", "Avg Hold [h]", "Fee Cost [%]", "Funding Cost [%]"]
    available_cols = [c for c in cols if c in full.columns]

    avg_by_config = full.groupby(["Config", "Philosophy"])[
        [c for c in available_cols if c not in ["Config", "Philosophy"]]
    ].mean().reset_index()

    # æ¯ç¨®å“²å­¸å– Sharpe æœ€é«˜çš„
    best_rows = []
    for phil in ["baseline", "trend_hold", "hybrid_lock", "mean_revert_take"]:
        subset = avg_by_config[avg_by_config["Philosophy"] == phil]
        if subset.empty:
            continue
        best_idx = subset["Sharpe"].idxmax()
        best = subset.loc[best_idx].copy()
        best["Rank"] = "BEST"
        best_rows.append(best)

        # æ¬¡ä½³
        if len(subset) > 1:
            rest = subset.drop(best_idx)
            second_idx = rest["Sharpe"].idxmax()
            second = rest.loc[second_idx].copy()
            second["Rank"] = "2nd"
            best_rows.append(second)

    if not best_rows:
        return

    main_table = pd.DataFrame(best_rows)

    display_cols = ["Rank", "Philosophy", "Config", "CAGR [%]", "Sharpe", "Sortino",
                    "Calmar", "MaxDD [%]", "MAR", "Ann. Trades", "Turnover",
                    "Win Rate [%]", "Profit Factor", "Avg Hold [h]",
                    "Fee Cost [%]", "Funding Cost [%]"]
    display_cols = [c for c in display_cols if c in main_table.columns]

    print(f"\n{'â”€' * 70}")
    print("  ğŸ“‹ ä¸»è¡¨: å„å“²å­¸æœ€ä½³é…ç½®ï¼ˆFull æœŸé–“ï¼Œè·¨å¹£ç¨®å¹³å‡ï¼‰")
    print(f"{'â”€' * 70}")
    print(main_table[display_cols].to_string(index=False))
    main_table[display_cols].to_csv(output_dir / "T1_main_table.csv", index=False)


def _print_period_comparison(results_df: pd.DataFrame, output_dir: Path):
    """å¤šæ™‚æ®µç©©å¥æ€§æ¯”è¼ƒ"""
    if results_df.empty:
        return

    # å–æ¯ç¨®å“²å­¸åœ¨ Full ä¸Š Sharpe æœ€é«˜çš„ config
    full = results_df[results_df["Period"] == "Full"]
    best_configs = {}
    for phil in ["baseline", "trend_hold", "hybrid_lock", "mean_revert_take"]:
        subset = full[full["Philosophy"] == phil]
        if subset.empty:
            continue
        avg_sharpe = subset.groupby("Config")["Sharpe"].mean()
        best_configs[phil] = avg_sharpe.idxmax()

    # æŠ½å–é€™äº› config çš„å„æ™‚æ®µçµæœ
    rows = []
    for phil, cfg_name in best_configs.items():
        for period in ["IS", "OOS", "Live", "Full"]:
            mask = (results_df["Config"] == cfg_name) & (results_df["Period"] == period)
            subset = results_df[mask]
            if subset.empty:
                continue
            row = {
                "Philosophy": phil,
                "Config": cfg_name,
                "Period": period,
                "CAGR [%]": round(subset["CAGR [%]"].mean(), 2),
                "Sharpe": round(subset["Sharpe"].mean(), 3),
                "MaxDD [%]": round(subset["MaxDD [%]"].mean(), 2),
                "Win Rate [%]": round(subset["Win Rate [%]"].mean(), 1),
                "N Trades": round(subset["N Trades"].mean(), 0),
            }
            rows.append(row)

    if not rows:
        return

    period_df = pd.DataFrame(rows)
    print(f"\n{'â”€' * 70}")
    print("  ğŸ“‹ å¤šæ™‚æ®µç©©å¥æ€§ï¼ˆå„å“²å­¸ Full-best configï¼‰")
    print(f"{'â”€' * 70}")
    print(period_df.to_string(index=False))
    period_df.to_csv(output_dir / "T2_period_comparison.csv", index=False)


def _print_tail_table(tail_df: pd.DataFrame, output_dir: Path):
    """å³å°¾è¨ºæ–·è¡¨"""
    # æ‰¾å„å“²å­¸ Full ä¸Šæœ€ä½³çš„ configï¼Œå–å…¶ tail
    display_cols = ["Philosophy", "Config",
                    "Top 10% PnL Contribution [%]", "Top 10% Count",
                    "Remove Top1 Decay [%]", "Remove Top3 Decay [%]",
                    "Remove Top5 Decay [%]",
                    "Avg Trade Return [%]", "Median Trade Return [%]",
                    "Skew Trade Return", "Kurt Trade Return"]
    display_cols = [c for c in display_cols if c in tail_df.columns]

    avg_tail = tail_df.groupby(["Config", "Philosophy"])[
        [c for c in display_cols if c not in ["Config", "Philosophy"]]
    ].mean().reset_index()

    print(f"\n{'â”€' * 70}")
    print("  ğŸ“‹ å³å°¾ / é«˜å‹ç‡è¨ºæ–·ï¼ˆFull æœŸé–“ï¼Œè·¨å¹£ç¨®å¹³å‡ï¼‰")
    print(f"{'â”€' * 70}")
    print(avg_tail[display_cols].to_string(index=False))
    avg_tail[display_cols].to_csv(output_dir / "T3_tail_diagnostics.csv", index=False)


def _print_sensitivity_table(sens_df: pd.DataFrame, output_dir: Path):
    """æˆæœ¬å£“æ¸¬è¡¨"""
    print(f"\n{'â”€' * 70}")
    print("  ğŸ“‹ æˆæœ¬å£“æ¸¬ï¼ˆBaselineï¼ŒFull æœŸé–“ï¼‰")
    print(f"{'â”€' * 70}")
    avg = sens_df.groupby("Scenario")[["CAGR [%]", "Sharpe", "MaxDD [%]"]].mean().reset_index()
    print(avg.to_string(index=False))
    avg.to_csv(output_dir / "T4_cost_sensitivity.csv", index=False)


def _print_live_diff_report(output_dir: Path):
    """å›æ¸¬ vs å¯¦ç›¤å·®ç•°å ±å‘Š"""
    report = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  å›æ¸¬ vs å¯¦ç›¤ åŸ·è¡Œé‚è¼¯å·®ç•°å ±å‘Š                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                â•‘
â•‘  1. Min Trade Gate (2%)                                        â•‘
â•‘     å›æ¸¬: ç„¡ï¼ˆä»»æ„å¤§å°èª¿å€‰ï¼‰                                     â•‘
â•‘     å¯¦ç›¤: |target - current| < 2% â†’ è·³é                       â•‘
â•‘     åå·®: å›æ¸¬åæ¨‚è§€ï¼ˆæ›´å¤šå¾®äº¤æ˜“ â†’ æ›´å¤šæ‰‹çºŒè²»ä½†ä¹Ÿæ›´å¤šä¿¡è™Ÿï¼‰       â•‘
â•‘                                                                â•‘
â•‘  2. Fill Gate (80%)                                            â•‘
â•‘     å›æ¸¬: 100% fillï¼ˆå‡è¨­å®Œç¾æˆäº¤ï¼‰                              â•‘
â•‘     å¯¦ç›¤: current/target â‰¥ 80% â†’ è¦–ç‚ºå·²å®Œæˆ                    â•‘
â•‘     åå·®: å›æ¸¬åæ¨‚è§€ï¼ˆå‡è¨­ç²¾ç¢ºåˆ°ä½ï¼‰                             â•‘
â•‘                                                                â•‘
â•‘  3. Rebalance Band (3%)                                        â•‘
â•‘     å›æ¸¬: ç„¡                                                    â•‘
â•‘     å¯¦ç›¤: diff < 3% ä¸”åŒæ–¹å‘ â†’ è·³é                            â•‘
â•‘     åå·®: å›æ¸¬åæ¨‚è§€ï¼ˆæ›´å¤šå¾®èª¿å€‰ â†’ turnover æ›´é«˜ï¼‰              â•‘
â•‘                                                                â•‘
â•‘  4. Order Type                                                 â•‘
â•‘     å›æ¸¬: Market order fee (5bps)                              â•‘
â•‘     å¯¦ç›¤: Maker å„ªå…ˆ (2bps) + timeout fallback Market          â•‘
â•‘     åå·®: å›æ¸¬åä¿å®ˆï¼ˆå¤šç®— 3bps æ‰‹çºŒè²» Ã— ~60% maker fill ç‡ï¼‰   â•‘
â•‘                                                                â•‘
â•‘  5. SL/TP Execution                                            â•‘
â•‘     å›æ¸¬: intra-bar simulationï¼ˆhigh/low æª¢æ¸¬ + exec_pricesï¼‰  â•‘
â•‘     å¯¦ç›¤: äº¤æ˜“æ‰€æ› STOP_MARKET / TAKE_PROFIT_MARKET å–®         â•‘
â•‘     åå·®: åŸºæœ¬ä¸€è‡´ï¼ˆSL å„ªå…ˆä¿å®ˆè™•ç†ï¼‰                            â•‘
â•‘                                                                â•‘
â•‘  6. Funding Rate                                               â•‘
â•‘     å›æ¸¬: æ­·å²è³‡æ–™é€ bar å°é½Š                                   â•‘
â•‘     å¯¦ç›¤: æ¯ 8h å³æ™‚çµç®—                                        â•‘
â•‘     åå·®: åŸºæœ¬ä¸€è‡´ï¼ˆæ­·å² vs å³æ™‚å·®ç•° < 0.5%/yrï¼‰               â•‘
â•‘                                                                â•‘
â•‘  7. æ–¹å‘åˆ‡æ›ç¢ºèª (flip_confirmation)                            â•‘
â•‘     å›æ¸¬: ç„¡ï¼ˆä¿¡è™Ÿç¿»è½‰å³åŸ·è¡Œï¼‰                                   â•‘
â•‘     å¯¦ç›¤: å¯é¸ 2-tick ç¢ºèªï¼ˆprod é—œé–‰ï¼‰                         â•‘
â•‘     åå·®: ä¸€è‡´ï¼ˆå‡ç‚ºç«‹å³åŸ·è¡Œï¼‰                                   â•‘
â•‘                                                                â•‘
â•‘  ç¶œåˆè©•ä¼°: å›æ¸¬æ•´é«”åæ¨‚è§€ 1~3%/yr                              â•‘
â•‘  ä¸»å› : min trade gate + fill gate + rebalance band             â•‘
â•‘  æŠµæ¶ˆ: maker å„ªå…ˆçœ ~1.5%/yr æ‰‹çºŒè²»                            â•‘
â•‘  æ·¨åå·®ä¼°è¨ˆ: å›æ¸¬åæ¨‚è§€ 0~2%/yr                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """.strip()
    print(f"\n{report}")
    with open(output_dir / "T5_live_diff_report.txt", "w") as f:
        f.write(report)


def _print_signal_analysis(results_df: pd.DataFrame, output_dir: Path):
    """TSMOM ä¿¡è™Ÿç‰¹æ€§åˆ†æï¼ˆå¹«åŠ©ç†è§£ exit overlay çš„å½±éŸ¿ï¼‰"""
    full = results_df[results_df["Period"] == "Full"]
    if full.empty:
        return

    print(f"\n{'â”€' * 70}")
    print("  ğŸ“‹ ä¿¡è™Ÿç‰¹æ€§åˆ†æï¼ˆFull æœŸé–“ï¼‰")
    print(f"{'â”€' * 70}")

    # Per-symbol breakdown for baseline
    baseline = full[full["Philosophy"] == "baseline"]
    if not baseline.empty:
        print("\n  [Baseline â€” è£¸ TSMOM å„å¹£ç¨®è¡¨ç¾]")
        display_cols = ["Symbol", "CAGR [%]", "Sharpe", "MaxDD [%]",
                       "Win Rate [%]", "Profit Factor", "N Trades",
                       "Avg Hold [h]", "Turnover"]
        display_cols = [c for c in display_cols if c in baseline.columns]
        print(baseline[display_cols].to_string(index=False))

    # Per-symbol breakdown for each philosophy best
    for phil in ["trend_hold", "hybrid_lock", "mean_revert_take"]:
        subset = full[full["Philosophy"] == phil]
        if subset.empty:
            continue
        avg_sharpe = subset.groupby("Config")["Sharpe"].mean()
        best_cfg = avg_sharpe.idxmax()
        best_sub = subset[subset["Config"] == best_cfg]
        print(f"\n  [{phil} BEST ({best_cfg}) å„å¹£ç¨®è¡¨ç¾]")
        display_cols = ["Symbol", "CAGR [%]", "Sharpe", "MaxDD [%]",
                       "Win Rate [%]", "Profit Factor", "N Trades",
                       "Avg Hold [h]", "Turnover"]
        display_cols = [c for c in display_cols if c in best_sub.columns]
        print(best_sub[display_cols].to_string(index=False))

    # Save
    full_display = full[["Symbol", "Config", "Philosophy", "CAGR [%]", "Sharpe",
                          "MaxDD [%]", "Win Rate [%]", "N Trades", "Avg Hold [h]"]].copy()
    full_display.to_csv(output_dir / "T6_signal_analysis.csv", index=False)


def _print_conclusion(results_df: pd.DataFrame, tail_df: pd.DataFrame, output_dir: Path):
    """çµè«–"""
    if results_df.empty:
        return

    full = results_df[results_df["Period"] == "Full"]
    if full.empty:
        return

    # å„å“²å­¸æœ€ä½³ config
    best = {}
    for phil in ["baseline", "trend_hold", "hybrid_lock", "mean_revert_take"]:
        subset = full[full["Philosophy"] == phil]
        if subset.empty:
            continue
        avg = subset.groupby("Config").agg({
            "Sharpe": "mean",
            "CAGR [%]": "mean",
            "MaxDD [%]": "mean",
            "Win Rate [%]": "mean",
            "Avg Hold [h]": "mean",
        }).reset_index()
        idx = avg["Sharpe"].idxmax()
        best[phil] = avg.loc[idx]

    # å³å°¾åˆ¤æ–·ï¼ˆåŸºæ–¼ baselineï¼Œä¸å— exit overlay æ±¡æŸ“ï¼‰
    tail_driven = "unknown"
    if not tail_df.empty:
        baseline_tail = tail_df[tail_df["Philosophy"] == "baseline"]
        if not baseline_tail.empty and "Top 10% PnL Contribution [%]" in baseline_tail.columns:
            avg_top10 = baseline_tail["Top 10% PnL Contribution [%]"].mean()
        else:
            avg_top10 = tail_df["Top 10% PnL Contribution [%]"].mean()
        baseline_wr = full[full["Philosophy"] == "baseline"]["Win Rate [%]"].mean()
        if avg_top10 > 60:
            tail_driven = "right_tail"
        elif baseline_wr > 55:
            tail_driven = "high_win_rate"
        else:
            tail_driven = "mixed"

    lines = [
        "",
        "â•" * 70,
        "  ğŸ¯ çµè«–èˆ‡å»ºè­°",
        "â•" * 70,
        "",
    ]

    # â”€â”€ 1. é©…å‹•æ¨¡å¼åˆ¤æ–· â”€â”€
    lines.append("  â”â”â” 1. é©…å‹•æ¨¡å¼åˆ¤æ–· â”â”â”")
    if tail_driven == "right_tail":
        lines.append("  ğŸ“Š æ­¤ç­–ç•¥ç‚ºã€å³å°¾é©…å‹•ã€‘å‹")
        lines.append("     â†’ å°‘æ•¸å¤§è´å®¶è²¢ç»ä¸»è¦æ”¶ç›Šï¼ˆTop 10% trades > 60% PnLï¼‰")
        lines.append("     â†’ ä¸å»ºè­°è¨­ç·Š TP â€” æœƒç³»çµ±æ€§æˆªæ–·å³å°¾")
        lines.append("     â†’ Trend-following ç­–ç•¥çš„å…¸å‹ç‰¹å¾µï¼Œç¬¦åˆ TSMOM è¨­è¨ˆ")
    elif tail_driven == "high_win_rate":
        lines.append("  ğŸ“Š æ­¤ç­–ç•¥ç‚ºã€é«˜å‹ç‡é©…å‹•ã€‘å‹")
        lines.append("     â†’ å¤šæ•¸äº¤æ˜“å°è´ï¼Œå°‘æ•¸äº¤æ˜“å¤§è¼¸")
        lines.append("     â†’ é©åˆè¨­å®šæ˜ç¢º TP é–åˆ© + åš´æ ¼ SL æ§æ")
    else:
        lines.append("  ğŸ“Š æ­¤ç­–ç•¥ç‚ºã€æ··åˆã€‘å‹")
        lines.append("     â†’ å³å°¾è²¢ç»èˆ‡å‹ç‡ä»‹æ–¼å…©è€…ä¹‹é–“")
        lines.append("     â†’ Trailing stop æ˜¯æœ€ä½³æŠ˜è¡·ï¼ˆä¿è­·æµ®ç›ˆè€Œä¸æˆªæ–·è¶¨å‹¢ï¼‰")
    lines.append("")

    # â”€â”€ 2. å„å“²å­¸è¡¨ç¾æ¯”è¼ƒ â”€â”€
    lines.append("  â”â”â” 2. å„å“²å­¸è¡¨ç¾æ¯”è¼ƒ â”â”â”")
    for phil, b in sorted(best.items(), key=lambda x: x[1]["Sharpe"], reverse=True):
        marker = "â­" if b["Sharpe"] == max(v["Sharpe"] for v in best.values()) else "  "
        lines.append(f"  {marker} {phil:20s}: Sharpe={b['Sharpe']:.3f}, "
                     f"CAGR={b['CAGR [%]']:.1f}%, MDD={b['MaxDD [%]']:.1f}%, "
                     f"WR={b['Win Rate [%]']:.0f}%")
    lines.append("")

    # â”€â”€ 3. æ ¸å¿ƒæ´å¯Ÿ â”€â”€
    lines.append("  â”â”â” 3. æ ¸å¿ƒæ´å¯Ÿ â”â”â”")
    if "baseline" in best:
        b_sharpe = best["baseline"]["Sharpe"]
        all_worse = all(best[p]["Sharpe"] < b_sharpe for p in best if p != "baseline")
        if all_worse:
            lines.append("  âš ï¸  æ‰€æœ‰ exit overlay å‡åŠ£æ–¼è£¸ TSMOM baseline")
            lines.append("     åŸå› åˆ†æï¼š")
            lines.append("     a) TSMOM é€£çºŒä¿¡è™Ÿå·²å…§å»ºå‡ºå ´æ©Ÿåˆ¶ï¼ˆå‹•é‡æ¶ˆå¤± â†’ ä¿¡è™Ÿè¶¨é›¶ï¼‰")
            lines.append("     b) SL/TP è§¸ç™¼å¾Œçš„ cooldown æœŸé–“éŒ¯éè¶¨å‹¢å»¶çºŒ")
            lines.append("     c) SL åœ¨é«˜æ³¢å‹•ç’°å¢ƒè¢«é »ç¹è§¸ç™¼ï¼ˆcrypto å¸¸è¦‹ 3-5 ATR å›æ’¤ï¼‰")
            lines.append("     d) TP æˆªæ–·åˆ©æ½¤ï¼Œä½† TSMOM çš„åˆ©æ½¤ä¸»è¦ä¾†è‡ªæŒæœ‰è¶¨å‹¢")
        else:
            improved = [p for p in best if p != "baseline" and best[p]["Sharpe"] >= b_sharpe]
            lines.append(f"  âœ… æœ‰å“²å­¸è¶…è¶Š baseline: {', '.join(improved)}")
    lines.append("")

    # â”€â”€ 4. TP å»ºè­° â”€â”€
    lines.append("  â”â”â” 4. TP/SL å»ºè­° â”â”â”")
    if "baseline" in best:
        b_sharpe = best["baseline"]["Sharpe"]
        phil_sharpes = {p: best[p]["Sharpe"] for p in best}
        best_phil = max(phil_sharpes, key=phil_sharpes.get)

        if best_phil == "baseline":
            lines.append("  ğŸ’¡ å»ºè­°: ã€ç¶­æŒç¾ç‹€ â€” ä¸ä¸Š TP/SLã€‘")
            lines.append("     â†’ TSMOM ä¿¡è™Ÿæœ¬èº«å°±æ˜¯æœ€ä½³å‡ºå ´æ©Ÿåˆ¶")
            lines.append("     â†’ è‹¥æ“”å¿ƒå°¾éƒ¨é¢¨éšªï¼Œå¯è€ƒæ…®:")
            lines.append("       â€¢ å¸³æˆ¶å±¤ç´š Drawdown Circuit Breakerï¼ˆç¾æœ‰ 40%ï¼‰")
            lines.append("       â€¢ æ¥µå¯¬ç½é›£å‹ SLï¼ˆâ‰¥7Ã— ATRï¼‰ï¼Œåƒ…é˜²é–ƒå´©")
            lines.append("       â€¢ ä¸åŠ  cooldownï¼ˆè§¸ç™¼å¾Œç«‹å³æ¢å¾©ä¿¡è™Ÿæ§åˆ¶ï¼‰")
        elif best_phil == "trend_hold":
            lines.append("  ğŸ’¡ å»ºè­°: ã€åŠ å¯¬å¹…ç½é›£å‹ SLã€‘")
            lines.append(f"     â†’ æœ€ä½³: {best['trend_hold']['Config']}")
            lines.append("     â†’ SL åƒ…åšé»‘å¤©éµä¿è­·ï¼Œä¸å¹²é æ­£å¸¸å‡ºå ´")
        elif best_phil == "hybrid_lock":
            lines.append("  ğŸ’¡ å»ºè­°: ã€ä¸Š Trailing Stopã€‘")
            lines.append(f"     â†’ æœ€ä½³: {best['hybrid_lock']['Config']}")
            lines.append("     â†’ Trailing é–ç›ˆè€Œéæˆªæ–·è¶¨å‹¢")
            lines.append("     â†’ éœ€ç›£æ§: trailing è§¸ç™¼é »ç‡æ˜¯å¦éé«˜")
        elif best_phil == "mean_revert_take":
            lines.append("  ğŸ’¡ å»ºè­°: ã€ä¸Šå›ºå®š TPã€‘")
            lines.append(f"     â†’ æœ€ä½³: {best['mean_revert_take']['Config']}")
            lines.append("     â†’ ç­–ç•¥å¯èƒ½æœ‰å‡å€¼å›æ­¸ç‰¹æ€§ï¼ŒTP æœ‰æ•ˆ")

    lines.append("")

    # â”€â”€ 5. Paper-trade å€™é¸ â”€â”€
    lines.append("  â”â”â” 5. Paper-trade å€™é¸é…ç½® â”â”â”")
    candidates = []
    for phil in ["baseline", "trend_hold", "hybrid_lock", "mean_revert_take"]:
        if phil in best:
            b = best[phil]
            lines.append(f"    #{len(candidates)+1}. {phil}: {b['Config']}")
            lines.append(f"        Sharpe={b['Sharpe']:.3f}, CAGR={b['CAGR [%]']:.1f}%, "
                        f"MDD={b['MaxDD [%]']:.1f}%, WR={b['Win Rate [%]']:.0f}%")
            candidates.append(phil)

    lines.append("")

    # â”€â”€ 6. ç›£æ§æŒ‡æ¨™ â”€â”€
    lines.append("  â”â”â” 6. Paper-trade ç›£æ§æŒ‡æ¨™ â”â”â”")
    lines.append("    1. Rolling 30d Sharpe: IS è¡°æ¸› > 30% â†’ è­¦æˆ’")
    lines.append("    2. Avg holding time: åé›¢å›æ¸¬å‡å€¼ > 50% â†’ æª¢æŸ¥ä¿¡è™Ÿå“è³ª")
    lines.append("    3. Win rate: åé›¢å›æ¸¬ > 10pp â†’ æª¢æŸ¥å¸‚å ´ç‹€æ…‹")
    lines.append("    4. SL è§¸ç™¼ç‡: > 30% trades hit SL â†’ SL å¤ªçª„æˆ–å¸‚å ´åŠ‡çƒˆ")
    lines.append("    5. Funding cost / ç¸½æ”¶ç›Šå æ¯”: > 50% â†’ é‡æ–°è©•ä¼°å€‰ä½æ–¹å‘")
    lines.append("    6. Max consecutive losses: > å›æ¸¬ 2Ïƒ â†’ æš«åœæª¢è¨")
    lines.append("")

    # â”€â”€ 7. TSMOM ç‰¹æ®Šè€ƒé‡ â”€â”€
    lines.append("  â”â”â” 7. TSMOM ç­–ç•¥ç‰¹æ®Šè€ƒé‡ â”â”â”")
    lines.append("    â€¢ TSMOM çš„å‡ºå ´æ©Ÿåˆ¶æ˜¯ã€Œä¿¡è™Ÿè¡°æ¸›ã€è€Œéã€Œè§¸åƒ¹å‡ºå ´ã€")
    lines.append("    â€¢ ä¿¡è™Ÿé€£çºŒæ€§æ˜¯ TSMOM çš„æ ¸å¿ƒå„ªå‹¢ï¼ˆvol-scaled position sizingï¼‰")
    lines.append("    â€¢ ç–ŠåŠ  exit rules çš„æœ€å¤§é¢¨éšª: æ‰“æ–·ä¿¡è™Ÿé€£çºŒæ€§ï¼Œå¢åŠ  whipsaw")
    lines.append("    â€¢ è‹¥ç”Ÿç”¢ç’°å¢ƒæ±ºå®šåŠ  SL: å»ºè­° SL â‰¥ 5Ã— ATR + CD=0")
    lines.append("    â€¢ åŸå‰‡: exit overlay æ‡‰ç‚ºã€Œä¿éšªã€è€Œéã€Œä¸»è¦å‡ºå ´æ©Ÿåˆ¶ã€")
    lines.append("")

    conclusion = "\n".join(lines)
    print(conclusion)
    with open(output_dir / "T7_conclusion.txt", "w") as f:
        f.write(conclusion)


if __name__ == "__main__":
    main()
