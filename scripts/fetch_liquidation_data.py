"""
æ¸…ç®—/çˆ†å€‰æ•¸æ“šä¸‹è¼‰å·¥å…· (Phase 0B)

å¾ Binance Futures API ä¸‹è¼‰æ¸…ç®—æ•¸æ“šï¼š
    1. Force Orders (è¿‘æœŸå¼·åˆ¶å¹³å€‰è¨‚å–®)
    2. Aggregate Liquidation Volume (å¾ Coinglassï¼Œå¦‚æœ‰ API key)

æ•¸æ“šä¾†æºï¼š
    A. Binance API: GET /fapi/v1/allForceOrders â€” æœ€è¿‘æ¸…ç®—è¨‚å–®
       é™åˆ¶: ä¸éœ€ API key, ä½†åªæœ‰æœ€è¿‘ ~7 å¤©, æœ€å¤š 1000 ç­†
    B. Coinglass API: /api/futures/liquidation/v2/history â€” æ­·å²æ¸…ç®—æ•¸æ“š
       éœ€è¦ COINGLASS_API_KEY, æ”¯æ´æ›´é•·æ­·å²

è¡ç”ŸæŒ‡æ¨™ï¼š
    - liq_volume_long:  åšå¤šæ¸…ç®—é‡ (USDT)
    - liq_volume_short: åšç©ºæ¸…ç®—é‡ (USDT)
    - liq_imbalance:    æ¸…ç®—ä¸å¹³è¡¡ = (long_liq - short_liq) / (long_liq + short_liq)
    - liq_cascade:      æ¸…ç®—ç€‘å¸ƒæŒ‡æ¨™ = rolling z-score of total liq volume

å„²å­˜è·¯å¾‘ï¼š
    data/binance/futures/liquidation/{SYMBOL}.parquet

ä½¿ç”¨ç¯„ä¾‹ï¼š
    # å¾ Binance ä¸‹è¼‰æœ€è¿‘æ¸…ç®—æ•¸æ“š
    PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT ETHUSDT

    # å¾ Coinglass ä¸‹è¼‰æ­·å²æ¸…ç®—ï¼ˆéœ€è¦ API keyï¼‰
    PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT --source coinglass

    # æŸ¥çœ‹è¦†è“‹ç‡å ±å‘Š
    PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT --coverage
"""
from __future__ import annotations

import argparse
import logging
import os
import time
from datetime import datetime, timezone
from pathlib import Path

import numpy as np
import pandas as pd

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)

DATA_DIR = Path("data/binance/futures/liquidation")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Binance Force Orders
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_binance_force_orders(
    symbol: str,
    limit: int = 1000,
) -> pd.DataFrame:
    """
    å¾ Binance /fapi/v1/allForceOrders ä¸‹è¼‰æœ€è¿‘æ¸…ç®—è¨‚å–®

    å›å‚³ DataFrame æ¬„ä½:
        timestamp, symbol, side, price, qty, quote_qty, time_in_force
    """
    from qtrade.data.binance_futures_client import BinanceFuturesHTTP

    client = BinanceFuturesHTTP()
    try:
        records = client.get("/fapi/v1/allForceOrders", {
            "symbol": symbol,
            "limit": min(limit, 1000),
        })
    except Exception as e:
        logger.error(f"âŒ Binance force orders {symbol}: {e}")
        return pd.DataFrame()

    if not records:
        logger.warning(f"âš ï¸  No force orders for {symbol}")
        return pd.DataFrame()

    df = pd.DataFrame(records)
    df["timestamp"] = pd.to_datetime(df["time"], unit="ms", utc=True)
    df["price"] = pd.to_numeric(df["price"], errors="coerce")
    df["origQty"] = pd.to_numeric(df["origQty"], errors="coerce")
    df["executedQty"] = pd.to_numeric(df["executedQty"], errors="coerce")
    df["averagePrice"] = pd.to_numeric(df["averagePrice"], errors="coerce")

    # è¨ˆç®—æ¸…ç®—é‡‘é¡ (USDT)
    df["quote_qty"] = df["executedQty"] * df["averagePrice"]

    result = df[["timestamp", "symbol", "side", "averagePrice", "executedQty", "quote_qty"]].copy()
    result.columns = ["timestamp", "symbol", "side", "price", "qty", "quote_qty"]
    result = result.set_index("timestamp").sort_index()

    logger.info(
        f"âœ… Binance force orders {symbol}: {len(result)} orders "
        f"({result.index[0]:%Y-%m-%d %H:%M} â†’ {result.index[-1]:%Y-%m-%d %H:%M})"
    )
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Coinglass Liquidation History
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_coinglass_liquidation(
    symbol: str,
    interval: str = "1h",
    start: str | None = None,
    end: str | None = None,
) -> pd.DataFrame:
    """
    å¾ Coinglass API ä¸‹è¼‰æ­·å²æ¸…ç®—èšåˆæ•¸æ“š

    Returns:
        DataFrame with columns: liq_volume_long, liq_volume_short
    """
    import requests

    api_key = os.getenv("COINGLASS_API_KEY", "")
    if not api_key:
        logger.warning("âš ï¸  COINGLASS_API_KEY not set. Cannot fetch liquidation data.")
        return pd.DataFrame()

    cg_symbol_map = {
        "BTCUSDT": "BTC", "ETHUSDT": "ETH", "SOLUSDT": "SOL",
        "BNBUSDT": "BNB", "DOGEUSDT": "DOGE", "ADAUSDT": "ADA",
        "AVAXUSDT": "AVAX", "LINKUSDT": "LINK", "XRPUSDT": "XRP",
    }
    cg_symbol = cg_symbol_map.get(symbol, symbol.replace("USDT", ""))

    interval_map = {
        "1h": "h1", "2h": "h2", "4h": "h4", "12h": "h12", "1d": "1d",
    }
    cg_interval = interval_map.get(interval, "h1")

    headers = {
        "accept": "application/json",
        "CoinGlass-API-Key": api_key,
    }

    # åˆ†é ä¸‹è¼‰
    if start:
        start_ts = int(pd.Timestamp(start, tz="UTC").timestamp())
    else:
        start_ts = int(pd.Timestamp("2022-01-01", tz="UTC").timestamp())
    if end:
        end_ts = int(pd.Timestamp(end, tz="UTC").timestamp())
    else:
        end_ts = int(pd.Timestamp.now(tz="UTC").timestamp())

    all_records = []
    current_end = end_ts
    page = 0

    logger.info(f"ğŸ“¥ Coinglass liquidation: {symbol} ({cg_symbol}) {interval}")

    while page < 100:
        params = {
            "symbol": cg_symbol,
            "timeType": cg_interval,
            "endTime": current_end,
            "limit": 500,
        }

        try:
            resp = requests.get(
                "https://open-api-v3.coinglass.com/api/futures/liquidation/v2/history",
                params=params,
                headers=headers,
                timeout=30,
            )
            resp.raise_for_status()
            body = resp.json()
        except Exception as e:
            logger.warning(f"âš ï¸  Coinglass liquidation page {page}: {e}")
            break

        data = body.get("data", [])
        if not data:
            break

        all_records.extend(data)
        page += 1

        timestamps = [r.get("t", 0) for r in data if r.get("t")]
        if not timestamps:
            break
        earliest = min(timestamps)
        if earliest <= start_ts:
            break

        current_end = earliest - 1
        time.sleep(2.5)  # Rate limiting

    if not all_records:
        logger.warning(f"âš ï¸  Coinglass: no liquidation data for {symbol}")
        return pd.DataFrame()

    rows = []
    for r in all_records:
        ts = r.get("t")
        if ts is None:
            continue
        rows.append({
            "timestamp": pd.Timestamp(ts, unit="s", tz="UTC"),
            "liq_volume_long": float(r.get("longVolUsd", 0)),
            "liq_volume_short": float(r.get("shortVolUsd", 0)),
        })

    df = pd.DataFrame(rows)
    df = df.set_index("timestamp").sort_index()
    df = df[~df.index.duplicated(keep="last")]

    if not df.empty:
        logger.info(
            f"âœ… Coinglass liq {symbol}: {len(df)} records "
            f"({df.index[0]:%Y-%m-%d} â†’ {df.index[-1]:%Y-%m-%d})"
        )
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å¾ Force Orders èšåˆæˆæ™‚é–“åºåˆ—
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def aggregate_force_orders(
    orders: pd.DataFrame,
    interval: str = "1h",
) -> pd.DataFrame:
    """
    å°‡é€ç­†æ¸…ç®—è¨‚å–®èšåˆæˆå›ºå®šæ™‚é–“å€é–“çš„æ¸…ç®—é‡

    Returns:
        DataFrame with columns: liq_volume_long, liq_volume_short, liq_count_long, liq_count_short
    """
    if orders.empty:
        return pd.DataFrame(
            columns=["liq_volume_long", "liq_volume_short", "liq_count_long", "liq_count_short"]
        )

    resample_map = {
        "5m": "5min", "15m": "15min", "30m": "30min",
        "1h": "1h", "2h": "2h", "4h": "4h", "1d": "1D",
    }
    freq = resample_map.get(interval, "1h")

    # SELL side = å¤šé ­è¢«æ¸…ç®— (long liquidation)
    # BUY side = ç©ºé ­è¢«æ¸…ç®— (short liquidation)
    long_liq = orders[orders["side"] == "SELL"]["quote_qty"]
    short_liq = orders[orders["side"] == "BUY"]["quote_qty"]

    result = pd.DataFrame(index=pd.DatetimeIndex([], name="timestamp"))

    if not long_liq.empty:
        result["liq_volume_long"] = long_liq.resample(freq).sum()
        result["liq_count_long"] = long_liq.resample(freq).count()
    if not short_liq.empty:
        result["liq_volume_short"] = short_liq.resample(freq).sum()
        result["liq_count_short"] = short_liq.resample(freq).count()

    result = result.fillna(0)
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  è¡ç”ŸæŒ‡æ¨™è¨ˆç®—
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_liquidation_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    è¨ˆç®—æ¸…ç®—è¡ç”ŸæŒ‡æ¨™

    æ–°å¢æ¬„ä½ï¼š
        liq_total:      ç¸½æ¸…ç®—é‡
        liq_imbalance:  æ¸…ç®—ä¸å¹³è¡¡ [-1, 1]ï¼ˆæ­£=ç©ºé ­è¢«æ¸…ç®—å¤šï¼Œçœ‹å¤šï¼‰
        liq_cascade_z:  æ¸…ç®—ç€‘å¸ƒ z-scoreï¼ˆæ¥µç«¯å€¼=æ¸…ç®—äº‹ä»¶ï¼‰
    """
    if df.empty:
        return df

    result = df.copy()

    long_vol = result.get("liq_volume_long", pd.Series(0, index=result.index))
    short_vol = result.get("liq_volume_short", pd.Series(0, index=result.index))

    result["liq_total"] = long_vol + short_vol

    # ä¸å¹³è¡¡: (short - long) / (short + long)
    # æ­£å€¼ = ç©ºé ­è¢«æ¸…ç®—å¤š = æ½›åœ¨çœ‹å¤šä¿¡è™Ÿ
    total = long_vol + short_vol
    result["liq_imbalance"] = np.where(
        total > 0,
        (short_vol - long_vol) / total,
        0.0,
    )

    # æ¸…ç®—ç€‘å¸ƒ z-score
    rolling_mean = result["liq_total"].rolling(168, min_periods=24).mean()  # 7d
    rolling_std = result["liq_total"].rolling(168, min_periods=24).std()
    result["liq_cascade_z"] = np.where(
        rolling_std > 0,
        (result["liq_total"] - rolling_mean) / rolling_std,
        0.0,
    )
    result["liq_cascade_z"] = result["liq_cascade_z"].clip(-5, 5).fillna(0)

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  å„²å­˜ / è¼‰å…¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_liquidation(
    df: pd.DataFrame,
    symbol: str,
    data_dir: Path = DATA_DIR,
) -> Path:
    """å„²å­˜æ¸…ç®—æ•¸æ“šåˆ° parquet"""
    path = data_dir / f"{symbol}.parquet"
    path.parent.mkdir(parents=True, exist_ok=True)
    df.to_parquet(path, index=True)
    logger.info(f"ğŸ’¾ Saved liquidation/{symbol}: {len(df)} rows â†’ {path}")
    return path


def load_liquidation(
    symbol: str,
    data_dir: Path = DATA_DIR,
) -> pd.DataFrame | None:
    """è¼‰å…¥æ¸…ç®—æ•¸æ“š"""
    path = data_dir / f"{symbol}.parquet"
    if not path.exists():
        return None
    try:
        return pd.read_parquet(path)
    except Exception as e:
        logger.warning(f"âš ï¸  Load liquidation/{symbol} failed: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ä¸»ç¨‹å¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="æ¸…ç®—/çˆ†å€‰æ•¸æ“šä¸‹è¼‰å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # å¾ Binance ä¸‹è¼‰æœ€è¿‘æ¸…ç®—æ•¸æ“š
  PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT ETHUSDT

  # å¾ Coinglass ä¸‹è¼‰æ­·å²æ¸…ç®—ï¼ˆéœ€ COINGLASS_API_KEYï¼‰
  PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT --source coinglass

  # æŸ¥çœ‹å·²ä¸‹è¼‰æ•¸æ“š
  PYTHONPATH=src python scripts/fetch_liquidation_data.py --symbols BTCUSDT --coverage
        """,
    )
    parser.add_argument(
        "--symbols", nargs="+", required=True,
        help="äº¤æ˜“å°åˆ—è¡¨",
    )
    parser.add_argument(
        "--source", default="binance",
        choices=["binance", "coinglass", "both"],
        help="æ•¸æ“šä¾†æº (é è¨­: binance)",
    )
    parser.add_argument(
        "--interval", default="1h",
        help="èšåˆå€é–“ (é è¨­: 1h)",
    )
    parser.add_argument(
        "--start", default=None,
        help="é–‹å§‹æ—¥æœŸ (Coinglass æ¨¡å¼, YYYY-MM-DD)",
    )
    parser.add_argument(
        "--end", default=None,
        help="çµæŸæ—¥æœŸ (YYYY-MM-DD)",
    )
    parser.add_argument(
        "--coverage", action="store_true",
        help="åªé¡¯ç¤ºè¦†è“‹ç‡å ±å‘Š",
    )
    parser.add_argument(
        "--data-dir", default=str(DATA_DIR),
        help=f"æ•¸æ“šå„²å­˜ç›®éŒ„ (é è¨­: {DATA_DIR})",
    )

    args = parser.parse_args()
    data_dir = Path(args.data_dir)

    # è¦†è“‹ç‡å ±å‘Š
    if args.coverage:
        print("\nğŸ“Š æ¸…ç®—æ•¸æ“šè¦†è“‹ç‡å ±å‘Š")
        print("=" * 60)
        for symbol in args.symbols:
            df = load_liquidation(symbol, data_dir)
            if df is None or df.empty:
                print(f"  {symbol}: âŒ ç„¡æ•¸æ“š")
            else:
                print(
                    f"  {symbol}: âœ… {len(df)} rows  "
                    f"{df.index[0]:%Y-%m-%d} â†’ {df.index[-1]:%Y-%m-%d}  "
                    f"({(df.index[-1] - df.index[0]).days}d)"
                )
                if "liq_total" in df.columns:
                    print(f"           avg_total={df['liq_total'].mean():,.0f} USDT/bar")
        print()
        return

    # ä¸‹è¼‰æ¨¡å¼
    for symbol in args.symbols:
        print(f"\n{'='*50}")
        print(f"  ğŸ“¥ {symbol} æ¸…ç®—æ•¸æ“š")
        print(f"{'='*50}")

        frames = []

        # Binance force orders
        if args.source in ("binance", "both"):
            orders = fetch_binance_force_orders(symbol)
            if not orders.empty:
                agg = aggregate_force_orders(orders, args.interval)
                frames.append(agg)

        # Coinglass
        if args.source in ("coinglass", "both"):
            cg = fetch_coinglass_liquidation(
                symbol, args.interval, args.start, args.end,
            )
            if not cg.empty:
                frames.append(cg)

        if not frames:
            logger.warning(f"âš ï¸  {symbol}: ç„¡æ¸…ç®—æ•¸æ“š")
            continue

        # åˆä½µ
        if len(frames) == 1:
            combined = frames[0]
        else:
            combined = pd.concat(frames)
            combined = combined[~combined.index.duplicated(keep="last")]
            combined = combined.sort_index()
            combined = combined.fillna(0)

        # è¨ˆç®—è¡ç”ŸæŒ‡æ¨™
        combined = compute_liquidation_indicators(combined)

        # å„²å­˜
        save_liquidation(combined, symbol, data_dir)

    print(f"\nâœ… ä¸‹è¼‰å®Œæˆï¼æ•¸æ“šç›®éŒ„: {data_dir}")


if __name__ == "__main__":
    main()
