"""
å¤šæ•¸æ“šæº K ç·šæ•¸æ“šä¸‹è¼‰å·¥å…·

æ”¯æ´çš„æ•¸æ“šæº:
1. binance (é»˜èª) - Binance APIï¼Œæ”¯æ´æœ€è¿‘çš„æ•¸æ“š
2. binance_vision - Binance å®˜æ–¹æ­·å²æ•¸æ“šï¼Œ2017-08 é–‹å§‹
3. yfinance - Yahoo Financeï¼ŒBTC æ•¸æ“šå¯è¿½æº¯åˆ° 2014-09
4. ccxt - å¤šäº¤æ˜“æ‰€ API (kraken, coinbasepro, bitstamp ç­‰)

ä½¿ç”¨ç¯„ä¾‹:
    # é»˜èªå¾ Binance ä¸‹è¼‰
    python scripts/download_data.py -c config/base.yaml
    
    # å¾ Yahoo Finance ä¸‹è¼‰é•·æœŸæ­·å² (2015 å¹´é–‹å§‹)
    python scripts/download_data.py --source yfinance --start 2015-01-01
    
    # å¾ Kraken ä¸‹è¼‰ (2013 å¹´é–‹å§‹)
    python scripts/download_data.py --source ccxt --exchange kraken --start 2013-10-01
    
    # å¾ Binance Data Vision æ‰¹é‡ä¸‹è¼‰ (æ›´å¿«)
    python scripts/download_data.py --source binance_vision --start 2017-08-17
    
    # æŸ¥çœ‹å¯ç”¨æ•¸æ“šæºè³‡è¨Š
    python scripts/download_data.py --list-sources
"""
from __future__ import annotations
import argparse
from datetime import datetime, timezone, timedelta
from pathlib import Path
import pandas as pd
from qtrade.config import load_config
from qtrade.data.klines import fetch_klines
from qtrade.data.storage import save_klines, load_klines, get_local_data_range, merge_klines


def _interval_to_timedelta(interval: str) -> timedelta:
    """å°‡ K ç·šé€±æœŸè½‰æ›ç‚º timedelta"""
    mapping = {
        "1m": timedelta(minutes=1),
        "3m": timedelta(minutes=3),
        "5m": timedelta(minutes=5),
        "15m": timedelta(minutes=15),
        "30m": timedelta(minutes=30),
        "1h": timedelta(hours=1),
        "2h": timedelta(hours=2),
        "4h": timedelta(hours=4),
        "6h": timedelta(hours=6),
        "8h": timedelta(hours=8),
        "12h": timedelta(hours=12),
        "1d": timedelta(days=1),
    }
    return mapping.get(interval, timedelta(hours=1))


def fetch_from_source(
    source: str,
    symbol: str,
    interval: str,
    start: str,
    end: str | None,
    market_type: str = "spot",
    exchange: str | None = None,
) -> "pd.DataFrame":
    """
    å¾æŒ‡å®šæ•¸æ“šæºç²å– K ç·šæ•¸æ“š
    
    Args:
        source: æ•¸æ“šæºåç¨±
        symbol: äº¤æ˜“å°
        interval: K ç·šé€±æœŸ
        start: é–‹å§‹æ—¥æœŸ
        end: çµæŸæ—¥æœŸ
        market_type: å¸‚å ´é¡å‹
        exchange: CCXT äº¤æ˜“æ‰€åç¨±
    """
    if source == "binance":
        return fetch_klines(symbol, interval, start, end, market_type=market_type)
    
    elif source == "binance_vision":
        from qtrade.data.binance_vision import download_binance_vision_klines
        return download_binance_vision_klines(symbol, interval, start, end, market_type=market_type)
    
    elif source == "yfinance":
        from qtrade.data.yfinance_client import fetch_yfinance_klines
        return fetch_yfinance_klines(symbol, interval, start, end)
    
    elif source == "ccxt":
        from qtrade.data.ccxt_client import fetch_ccxt_klines
        exchange_id = exchange or "binance"
        return fetch_ccxt_klines(symbol, interval, start, end, exchange=exchange_id)
    
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æ•¸æ“šæº: {source}")


def download_incremental(
    symbol: str,
    interval: str,
    start_date: str,
    end_date: str | None,
    data_path: Path,
    force_full: bool = False,
    market_type: str = "spot",
    source: str = "binance",
    exchange: str | None = None,
) -> tuple[int, int]:
    """
    å¢é‡ä¸‹è¼‰ K ç·šæ•¸æ“š
    
    Args:
        symbol: äº¤æ˜“å°
        interval: K ç·šé€±æœŸ
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        data_path: å„²å­˜è·¯å¾‘
        force_full: æ˜¯å¦å¼·åˆ¶å…¨é‡ä¸‹è¼‰
        market_type: å¸‚å ´é¡å‹ "spot" æˆ– "futures"
        source: æ•¸æ“šæºåç¨±
        exchange: CCXT äº¤æ˜“æ‰€åç¨±
    
    Returns:
        (ä¸‹è¼‰çš„æ–°è³‡æ–™ç­†æ•¸, ç¸½è³‡æ–™ç­†æ•¸)
    """
    import pandas as pd
    
    # å–å¾—æœ¬åœ°æ•¸æ“šç¯„åœ
    local_start, local_end = get_local_data_range(data_path)
    
    # è§£æç›®æ¨™ç¯„åœ
    target_start = datetime.strptime(start_date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
    target_end = (
        datetime.strptime(end_date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
        if end_date
        else datetime.now(timezone.utc)
    )
    
    interval_delta = _interval_to_timedelta(interval)
    new_rows = 0
    
    # åˆ¤æ–·æ˜¯å¦éœ€è¦ä¸‹è¼‰
    if force_full or local_start is None:
        # å…¨é‡ä¸‹è¼‰
        print(f"  ğŸ“¥ å…¨é‡ä¸‹è¼‰ {start_date} â†’ {end_date or 'ç¾åœ¨'} (ä¾†æº: {source})")
        df = fetch_from_source(source, symbol, interval, start_date, end_date, market_type, exchange)
        if not df.empty:
            save_klines(df, data_path)
            return len(df), len(df)
        return 0, 0
    
    # å¢é‡ä¸‹è¼‰ç­–ç•¥
    existing_df = load_klines(data_path)
    chunks_to_merge = [existing_df]
    
    # 1. æª¢æŸ¥æ˜¯å¦éœ€è¦è£œé½Šå‰é¢çš„æ•¸æ“š
    if target_start < local_start:
        gap_end = (local_start - interval_delta).strftime("%Y-%m-%d")
        print(f"  ğŸ“¥ è£œé½Šå‰æ®µ: {start_date} â†’ {gap_end} (ä¾†æº: {source})")
        front_df = fetch_from_source(source, symbol, interval, start_date, gap_end, market_type, exchange)
        if not front_df.empty:
            chunks_to_merge.append(front_df)
            new_rows += len(front_df)
    
    # 2. æª¢æŸ¥æ˜¯å¦éœ€è¦ä¸‹è¼‰å¾Œé¢çš„æ–°æ•¸æ“š
    # åŠ ä¸€å€‹å°ç·©è¡ï¼Œç¢ºä¿æœ‰é‡ç–Šä»¥è™•ç†å¯èƒ½çš„æ•¸æ“šæ›´æ–°
    overlap_buffer = interval_delta * 2
    fetch_start = local_end - overlap_buffer
    
    if target_end > fetch_start:
        fetch_start_str = fetch_start.strftime("%Y-%m-%d")
        fetch_end_str = target_end.strftime("%Y-%m-%d") if end_date else None
        print(f"  ğŸ“¥ æ›´æ–°å¾Œæ®µ: {fetch_start_str} â†’ {fetch_end_str or 'ç¾åœ¨'} (ä¾†æº: {source})")
        back_df = fetch_from_source(source, symbol, interval, fetch_start_str, fetch_end_str, market_type, exchange)
        if not back_df.empty:
            # è¨ˆç®—çœŸæ­£çš„æ–°æ•¸æ“šï¼ˆæ’é™¤é‡ç–Šéƒ¨åˆ†ï¼‰
            truly_new = back_df[back_df.index > local_end]
            new_rows += len(truly_new)
            chunks_to_merge.append(back_df)
    
    # åˆä½µæ‰€æœ‰æ•¸æ“š
    if len(chunks_to_merge) > 1:
        from functools import reduce
        merged = reduce(merge_klines, chunks_to_merge)
        save_klines(merged, data_path)
        return new_rows, len(merged)
    
    return 0, len(existing_df)


def list_data_sources() -> None:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•¸æ“šæºåŠå…¶è³‡è¨Š"""
    print("\nğŸ“Š å¯ç”¨çš„æ•¸æ“šæº:")
    print("=" * 70)
    
    # Binance API
    print("\n1ï¸âƒ£  binance (é»˜èª)")
    print("   - ä¾†æº: Binance REST API")
    print("   - BTC èµ·å§‹: 2017-08-17")
    print("   - å„ªé»: å¯¦æ™‚æ•¸æ“šã€æ”¯æ´ spot/futures")
    print("   - ç”¨æ³•: --source binance")
    
    # Binance Data Vision
    print("\n2ï¸âƒ£  binance_vision")
    print("   - ä¾†æº: Binance å®˜æ–¹æ­·å²æ•¸æ“šåº«")
    print("   - BTC èµ·å§‹: 2017-08-17")
    print("   - å„ªé»: æ‰¹é‡ä¸‹è¼‰ã€é€Ÿåº¦å¿«ã€å®Œæ•´æ­·å²")
    print("   - ç”¨æ³•: --source binance_vision")
    
    # Yahoo Finance
    print("\n3ï¸âƒ£  yfinance")
    print("   - ä¾†æº: Yahoo Finance")
    print("   - BTC èµ·å§‹: ~2014-09")
    print("   - å„ªé»: æœ€é•·å…è²»æ­·å²ã€ç„¡éœ€ API key")
    print("   - ç¼ºé»: åªæ”¯æ´ä¸»æµå¹£ã€æ•¸æ“šå¯èƒ½æœ‰å»¶é²")
    print("   - ç”¨æ³•: --source yfinance --start 2015-01-01")
    
    # CCXT
    print("\n4ï¸âƒ£  ccxt")
    print("   - ä¾†æº: å¤šäº¤æ˜“æ‰€çµ±ä¸€ API")
    print("   - æ”¯æ´äº¤æ˜“æ‰€åŠ BTC èµ·å§‹æ™‚é–“:")
    
    try:
        from qtrade.data.ccxt_client import EXCHANGE_HISTORY
        for ex_id, info in EXCHANGE_HISTORY.items():
            print(f"      â€¢ {ex_id}: {info['btc_start']} ({info['note']})")
    except ImportError:
        print("      â€¢ bitstamp: 2011-08 (æœ€æ—©)")
        print("      â€¢ kraken: 2013-10")
        print("      â€¢ bitfinex: 2013-04")
        print("      â€¢ coinbasepro: 2015-01")
        print("      â€¢ binance: 2017-08")
    
    print("   - ç”¨æ³•: --source ccxt --exchange kraken --start 2013-10-01")
    
    print("\n" + "=" * 70)
    print("\nğŸ’¡ å»ºè­°:")
    print("   â€¢ å¦‚éœ€ 2017 å¹´å‰çš„æ•¸æ“š: ä½¿ç”¨ yfinance æˆ– ccxt (kraken/bitstamp)")
    print("   â€¢ å¦‚éœ€ 2017-ç¾åœ¨å®Œæ•´æ•¸æ“š: ä½¿ç”¨ binance_vision + binance çµ„åˆ")
    print("   â€¢ å¦‚éœ€å¯¦æ™‚æ›´æ–°: ä½¿ç”¨ binance (é»˜èª)")


def check_data_availability(symbol: str, source: str, exchange: str | None = None) -> None:
    """æª¢æŸ¥æŒ‡å®šæ•¸æ“šæºçš„æ•¸æ“šå¯ç”¨æ€§"""
    print(f"\nğŸ” æª¢æŸ¥ {symbol} åœ¨ {source} çš„æ•¸æ“šå¯ç”¨æ€§...")
    
    if source == "yfinance":
        try:
            from qtrade.data.yfinance_client import get_yfinance_data_range
            earliest, latest = get_yfinance_data_range(symbol)
            if earliest:
                print(f"   âœ… {symbol}: {earliest} â†’ {latest}")
            else:
                print(f"   âŒ {symbol}: æ•¸æ“šä¸å¯ç”¨")
        except ImportError:
            print("   âŒ yfinance æœªå®‰è£")
    
    elif source == "ccxt":
        try:
            from qtrade.data.ccxt_client import get_earliest_data_timestamp
            exchange_id = exchange or "binance"
            earliest = get_earliest_data_timestamp(exchange_id, symbol)
            if earliest:
                print(f"   âœ… {symbol} @ {exchange_id}: å¾ {earliest} é–‹å§‹")
            else:
                print(f"   âŒ {symbol} @ {exchange_id}: æ•¸æ“šä¸å¯ç”¨")
        except ImportError:
            print("   âŒ ccxt æœªå®‰è£")
    
    elif source == "binance_vision":
        try:
            from qtrade.data.binance_vision import check_data_availability
            result = check_data_availability(symbol, "1h")
            print(f"   {result['message']}")
        except ImportError:
            print("   âŒ binance_vision æ¨¡çµ„éŒ¯èª¤")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="å¤šæ•¸æ“šæº K ç·šæ•¸æ“šä¸‹è¼‰å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # é»˜èªå¾ Binance ä¸‹è¼‰
  python scripts/download_data.py -c config/base.yaml
  
  # å¾ Yahoo Finance ä¸‹è¼‰é•·æœŸæ­·å²
  python scripts/download_data.py --source yfinance --symbol BTCUSDT --start 2015-01-01
  
  # å¾ Kraken ä¸‹è¼‰æ›´æ—©çš„æ•¸æ“š
  python scripts/download_data.py --source ccxt --exchange kraken --symbol BTCUSDT --start 2013-10-01
  
  # æŸ¥çœ‹å¯ç”¨æ•¸æ“šæº
  python scripts/download_data.py --list-sources
        """
    )
    parser.add_argument(
        "-c", "--config",
        type=str,
        default="config/base.yaml",
        help="é…ç½®æª”æ¡ˆè·¯å¾‘ï¼ˆé»˜èª: config/base.yamlï¼‰"
    )
    parser.add_argument(
        "--symbol",
        type=str,
        default=None,
        help="åªä¸‹è¼‰æŒ‡å®šçš„äº¤æ˜“å°"
    )
    parser.add_argument(
        "--full",
        action="store_true",
        help="å¼·åˆ¶å…¨é‡ä¸‹è¼‰ï¼ˆå¿½ç•¥æœ¬åœ°ç·©å­˜ï¼‰"
    )
    parser.add_argument(
        "--status",
        action="store_true",
        help="åªé¡¯ç¤ºæœ¬åœ°æ•¸æ“šç‹€æ…‹ï¼Œä¸ä¸‹è¼‰"
    )
    
    # å¤šæ•¸æ“šæºé¸é …
    parser.add_argument(
        "--source",
        type=str,
        default="binance",
        choices=["binance", "binance_vision", "yfinance", "ccxt"],
        help="æ•¸æ“šæº (é»˜èª: binance)"
    )
    parser.add_argument(
        "--exchange",
        type=str,
        default=None,
        help="CCXT äº¤æ˜“æ‰€åç¨± (ç”¨æ–¼ --source ccxt)"
    )
    parser.add_argument(
        "--start",
        type=str,
        default=None,
        help="è¦†è“‹é…ç½®æª”æ¡ˆä¸­çš„é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--end",
        type=str,
        default=None,
        help="è¦†è“‹é…ç½®æª”æ¡ˆä¸­çš„çµæŸæ—¥æœŸ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--interval",
        type=str,
        default=None,
        help="è¦†è“‹é…ç½®æª”æ¡ˆä¸­çš„ K ç·šé€±æœŸï¼ˆæ”¯æ´é€—è™Ÿåˆ†éš”æ‰¹é‡ä¸‹è¼‰: 5m,15m,1h,4h,1dï¼‰"
    )
    
    # Funding rate ä¸‹è¼‰
    parser.add_argument(
        "--funding-rate",
        action="store_true",
        help="åŒæ™‚ä¸‹è¼‰ Futures æ­·å² Funding Rateï¼ˆåˆç´„æ¨¡å¼è‡ªå‹•å•Ÿç”¨ï¼‰"
    )
    
    # OI ä¸‹è¼‰
    parser.add_argument(
        "--oi",
        action="store_true",
        help="åŒæ™‚ä¸‹è¼‰ Open Interest æ•¸æ“šï¼ˆoi_liq_bounce ç­‰ç­–ç•¥è‡ªå‹•å•Ÿç”¨ï¼‰"
    )
    parser.add_argument(
        "--clean-cache",
        action="store_true",
        help="OI åˆä½µå¾Œè‡ªå‹•åˆªé™¤ vision_cache åŸå§‹ CSVï¼ˆç¯€çœ ~400MB ç£ç¢Ÿï¼‰"
    )
    
    # è¡ç”Ÿå“æ•¸æ“šä¸‹è¼‰ï¼ˆLSR, Taker Vol, CVD, Liquidationï¼‰
    parser.add_argument(
        "--derivatives",
        action="store_true",
        help="åŒæ™‚ä¸‹è¼‰è¡ç”Ÿå“æ•¸æ“šï¼ˆLSRã€Taker Volã€CVDï¼‰åˆ° data/binance/futures/derivatives/"
    )
    
    # è³‡è¨ŠæŸ¥è©¢é¸é …
    parser.add_argument(
        "--list-sources",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•¸æ“šæº"
    )
    parser.add_argument(
        "--check",
        action="store_true",
        help="æª¢æŸ¥æŒ‡å®šæ•¸æ“šæºçš„æ•¸æ“šå¯ç”¨æ€§"
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæ•¸æ“šæº
    if args.list_sources:
        list_data_sources()
        return
    
    # è¼‰å…¥é…ç½®
    cfg = load_config(args.config)
    m = cfg.market
    market_type = cfg.market_type_str  # "spot" or "futures"
    
    # ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸è¦†è“‹é…ç½®
    start_date = args.start or m.start
    end_date = args.end or m.end

    # æ”¯æ´é€—è™Ÿåˆ†éš”çš„å¤šæ™‚é–“æ¡†æ¶ä¸‹è¼‰ (e.g. "5m,15m,1h,4h,1d")
    interval_arg = args.interval or m.interval
    intervals = [iv.strip() for iv in interval_arg.split(",")]
    
    # å¦‚æœæŒ‡å®šäº† symbolï¼Œåªè™•ç†è©²äº¤æ˜“å°
    symbols = [args.symbol] if args.symbol else m.symbols
    
    # æª¢æŸ¥æ•¸æ“šå¯ç”¨æ€§
    if args.check:
        for sym in symbols:
            check_data_availability(sym, args.source, args.exchange)
        return
    
    # å¸‚å ´é¡å‹æ¨™ç±¤
    market_emoji = "ğŸŸ¢" if market_type == "spot" else "ğŸ”´"
    market_label = "SPOT" if market_type == "spot" else "FUTURES"
    
    # æ•¸æ“šæºæ¨™ç±¤
    source_label = args.source.upper()
    if args.source == "ccxt" and args.exchange:
        source_label = f"CCXT/{args.exchange.upper()}"
    
    # é¡¯ç¤ºç‹€æ…‹æ¨¡å¼
    if args.status:
        print(f"\nğŸ“Š æœ¬åœ°æ•¸æ“šç‹€æ…‹ {market_emoji} [{market_label}]:")
        print("-" * 60)
        for interval in intervals:
            for sym in symbols:
                data_path = cfg.data_dir / "binance" / market_type / interval / f"{sym}.parquet"
                local_start, local_end = get_local_data_range(data_path)
                if local_start:
                    print(f"  {sym} @ {interval}: {local_start.strftime('%Y-%m-%d')} â†’ {local_end.strftime('%Y-%m-%d %H:%M')}")
                else:
                    print(f"  {sym} @ {interval}: âŒ ç„¡æœ¬åœ°æ•¸æ“š")
        print("-" * 60)
        return
    
    # ä¸‹è¼‰æ¨¡å¼ â€” éæ­·æ‰€æœ‰ interval
    total_new = 0
    for interval in intervals:
        print(f"\nğŸš€ é–‹å§‹ä¸‹è¼‰ K ç·šæ•¸æ“š {market_emoji} [{market_label}] ğŸ“¡ [{source_label}] â± {interval}")
        print("-" * 60)
        print(f"   æ™‚é–“ç¯„åœ: {start_date} â†’ {end_date or 'ç¾åœ¨'}")
        print(f"   K ç·šé€±æœŸ: {interval}")
        print(f"   äº¤æ˜“å°: {', '.join(symbols)}")
        print("-" * 60)
        
        for sym in symbols:
            # æ ¹æ“š market_type æ±ºå®šå­˜å„²è·¯å¾‘
            data_path = cfg.data_dir / "binance" / market_type / interval / f"{sym}.parquet"
            
            # å…ˆé¡¯ç¤ºæœ¬åœ°ç‹€æ…‹
            local_start, local_end = get_local_data_range(data_path)
            if local_start and not args.full:
                print(f"\nğŸ“ {sym} @ {interval} æœ¬åœ°: {local_start.strftime('%Y-%m-%d')} â†’ {local_end.strftime('%Y-%m-%d %H:%M')}")
            else:
                print(f"\nğŸ“ {sym} @ {interval} æœ¬åœ°: ç„¡æ•¸æ“š")
            
            # ä¸‹è¼‰
            try:
                new_rows, total_rows = download_incremental(
                    symbol=sym,
                    interval=interval,
                    start_date=start_date,
                    end_date=end_date,
                    data_path=data_path,
                    force_full=args.full,
                    market_type=market_type,
                    source=args.source,
                    exchange=args.exchange,
                )
                
                total_new += new_rows
                
                if new_rows > 0:
                    print(f"  âœ… æ–°å¢ {new_rows} ç­†ï¼Œå…± {total_rows} ç­† â†’ {data_path}")
                else:
                    print(f"  âœ… æ•¸æ“šå·²æ˜¯æœ€æ–°ï¼Œå…± {total_rows} ç­†")
                    
            except Exception as e:
                print(f"  âŒ ä¸‹è¼‰å¤±æ•—: {e}")
    
    print("-" * 60)
    print(f"ğŸ‰ å®Œæˆï¼å…±æ–°å¢ {total_new} ç­†æ•¸æ“š")

    # ä½¿ç”¨ä¸»è¦ intervalï¼ˆç¬¬ä¸€å€‹ï¼‰ä½œç‚º FR / OI çš„ interval
    primary_interval = intervals[0]

    # â”€â”€ Funding Rate ä¸‹è¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # åˆç´„æ¨¡å¼ä¸‹ --funding-rate æˆ– config å•Ÿç”¨æ™‚è‡ªå‹•ä¸‹è¼‰
    should_download_fr = (
        args.funding_rate
        or (market_type == "futures" and getattr(cfg.backtest.funding_rate, 'enabled', False))
    )
    if should_download_fr and market_type == "futures":
        from qtrade.data.funding_rate import (
            download_funding_rates,
            save_funding_rates,
            get_funding_rate_path,
            load_funding_rates,
        )
        print(f"\nğŸ“¥ ä¸‹è¼‰ Futures Funding Rate...")
        print("-" * 60)
        for sym in symbols:
            fr_path = get_funding_rate_path(cfg.data_dir, sym)
            try:
                existing = load_funding_rates(fr_path)
                if existing is not None and not args.full:
                    last_date = existing.index[-1].strftime("%Y-%m-%d")
                    print(f"  ğŸ“¥ {sym} Funding rate å¢é‡æ›´æ–°: {last_date} â†’ {end_date or 'ç¾åœ¨'}")
                    
                    # å¢é‡ä¸‹è¼‰
                    new_df = download_funding_rates(sym, last_date, end_date)
                    
                    if not new_df.empty:
                        # éæ¿¾æ‰èˆŠæ•¸æ“š (ä¿ç•™ index > existing.last)
                        new_data = new_df[new_df.index > existing.index[-1]]
                        if not new_data.empty:
                            merged = pd.concat([existing, new_data])
                            merged = merged[~merged.index.duplicated(keep='last')]
                            save_funding_rates(merged, fr_path)
                            print(f"  âœ… æ–°å¢ {len(new_data)} ç­†ï¼Œå…± {len(merged)} ç­†")
                        else:
                            print(f"  âœ… æ•¸æ“šå·²æ˜¯æœ€æ–°")
                    else:
                        print(f"  âš ï¸  ç„¡æ–°æ•¸æ“š")
                else:
                    fr_df = download_funding_rates(sym, start_date, end_date)
                    if not fr_df.empty:
                        save_funding_rates(fr_df, fr_path)
                        print(f"  âœ… {sym} Funding rate: {len(fr_df)} ç­† â†’ {fr_path}")
                    else:
                        print(f"  âš ï¸  {sym} ç„¡ funding rate è³‡æ–™")
            except Exception as e:
                print(f"  âŒ {sym} Funding rate ä¸‹è¼‰å¤±æ•—: {e}")
        print("-" * 60)

    # â”€â”€ OI ä¸‹è¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # oi_liq_bounce ç­‰ç­–ç•¥è‡ªå‹•å•Ÿç”¨ï¼Œæˆ– --oi æ‰‹å‹•å•Ÿç”¨
    oi_strategies = {"oi_liq_bounce", "oi_bb_rv"}
    strategy_name = getattr(cfg.strategy, "name", "")
    should_download_oi = (
        args.oi
        or (market_type == "futures" and strategy_name in oi_strategies)
    )
    if should_download_oi:
        try:
            from qtrade.data.open_interest import (
                download_open_interest,
                save_open_interest,
                load_open_interest,
                get_oi_path,
                merge_oi_sources,
            )
        except ImportError:
            print("âš ï¸  open_interest æ¨¡çµ„ä¸å¯ç”¨ï¼Œè·³é OI ä¸‹è¼‰")
            should_download_oi = False

    if should_download_oi:
        print(f"\nğŸ“¥ ä¸‹è¼‰ Open Interest æ•¸æ“š...")
        print("-" * 60)

        # 1) binance_visionï¼ˆå®Œæ•´æ­·å²ï¼‰
        for sym in symbols:
            try:
                print(f"  ğŸ“¥ {sym} OI via binance_vision...")
                df_vision = download_open_interest(
                    symbol=sym,
                    start=start_date,
                    end=end_date,
                    interval=primary_interval,
                    provider="binance_vision",
                )
                if not df_vision.empty:
                    path = get_oi_path(cfg.data_dir, sym, "binance_vision")
                    save_open_interest(df_vision, path)
                    print(f"  âœ… {sym} binance_vision: {len(df_vision)} ç­†")
                else:
                    print(f"  âš ï¸  {sym} binance_vision: ç„¡æ•¸æ“š")
            except Exception as e:
                print(f"  âŒ {sym} binance_vision OI ä¸‹è¼‰å¤±æ•—: {e}")

        # 2) binance APIï¼ˆè¿‘æœŸè£œé½Šï¼‰
        for sym in symbols:
            try:
                print(f"  ğŸ“¥ {sym} OI via binance API...")
                df_api = download_open_interest(
                    symbol=sym,
                    start=start_date,
                    end=end_date,
                    interval=primary_interval,
                    provider="binance",
                )
                if not df_api.empty:
                    path = get_oi_path(cfg.data_dir, sym, "binance")
                    save_open_interest(df_api, path)
                    print(f"  âœ… {sym} binance API: {len(df_api)} ç­†")
                else:
                    print(f"  âš ï¸  {sym} binance API: ç„¡æ•¸æ“š")
            except Exception as e:
                print(f"  âŒ {sym} binance API OI ä¸‹è¼‰å¤±æ•—: {e}")

        # 3) åˆä½µæ‰€æœ‰ä¾†æº
        print(f"\n  ğŸ”€ åˆä½µ OI ä¾†æº...")
        for sym in symbols:
            try:
                sources = []
                for prov in ["binance_vision", "coinglass", "binance"]:
                    path = get_oi_path(cfg.data_dir, sym, prov)
                    loaded = load_open_interest(path)
                    if loaded is not None and not loaded.empty:
                        sources.append(loaded)
                if sources:
                    combined = merge_oi_sources(sources, max_ffill_bars=2)
                    save_path = get_oi_path(cfg.data_dir, sym, "merged")
                    save_open_interest(combined, save_path)
                    print(f"  âœ… {sym} merged: {len(combined)} ç­†")
                else:
                    print(f"  âš ï¸  {sym}: ç„¡ä»»ä½• OI ä¾†æºå¯åˆä½µ")
            except Exception as e:
                print(f"  âŒ {sym} OI åˆä½µå¤±æ•—: {e}")

        # 4) æ¸…ç† vision_cacheï¼ˆåˆä½µå¾ŒåŸå§‹ CSV ä¸å†éœ€è¦ï¼‰
        if getattr(args, "clean_cache", False):
            import shutil
            cache_base = cfg.data_dir / "binance" / "futures" / "open_interest" / "vision_cache"
            if cache_base.exists():
                n_files = sum(1 for f in cache_base.rglob("*") if f.is_file())
                size_mb = sum(f.stat().st_size for f in cache_base.rglob("*") if f.is_file()) / (1024 * 1024)
                shutil.rmtree(cache_base)
                print(f"  ğŸ—‘ï¸  vision_cache å·²æ¸…ç†: {n_files} æª”æ¡ˆ, {size_mb:.1f} MB")
            else:
                print(f"  â­ï¸  vision_cache ä¸å­˜åœ¨ï¼Œç„¡éœ€æ¸…ç†")

        print("-" * 60)

    # â”€â”€ è¡ç”Ÿå“æ•¸æ“šä¸‹è¼‰ (LSR, Taker Vol, CVD) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    should_download_derivatives = args.derivatives and market_type == "futures"
    if should_download_derivatives:
        from qtrade.data.long_short_ratio import download_lsr, save_lsr, LSR_TYPES
        from qtrade.data.taker_volume import (
            download_taker_volume, save_taker_volume,
            compute_cvd, save_cvd,
        )

        derivatives_dir = cfg.data_dir / "binance" / "futures" / "derivatives"

        print(f"\nğŸ“¥ ä¸‹è¼‰è¡ç”Ÿå“æ•¸æ“š (LSR + Taker Vol + CVD)...")
        print("-" * 60)

        for sym in symbols:
            # 1) Long/Short Ratioï¼ˆå…¨å¸³æˆ¶ + å¤§æˆ¶å¸³æˆ¶ + å¤§æˆ¶æŒå€‰ï¼‰
            for lsr_type in LSR_TYPES:
                try:
                    series = download_lsr(
                        sym, lsr_type=lsr_type, start=start_date, end=end_date,
                        interval=primary_interval, provider="vision",
                    )
                    if not series.empty:
                        save_lsr(series, sym, lsr_type=lsr_type, data_dir=derivatives_dir)
                        print(f"  âœ… {sym} {lsr_type}: {len(series)} ç­†")
                    else:
                        print(f"  âš ï¸  {sym} {lsr_type}: ç„¡æ•¸æ“š")
                except Exception as e:
                    print(f"  âŒ {sym} {lsr_type}: {e}")

            # 2) Taker Buy/Sell Volume Ratio
            try:
                taker = download_taker_volume(
                    sym, start=start_date, end=end_date,
                    interval=primary_interval, provider="vision",
                )
                if not taker.empty:
                    save_taker_volume(taker, sym, data_dir=derivatives_dir)
                    print(f"  âœ… {sym} taker_vol_ratio: {len(taker)} ç­†")

                    # 3) CVD è¡ç”Ÿè¨ˆç®—
                    cvd = compute_cvd(taker)
                    save_cvd(cvd, sym, data_dir=derivatives_dir)
                    print(f"  âœ… {sym} cvd: {len(cvd)} ç­†")
                else:
                    print(f"  âš ï¸  {sym} taker_vol: ç„¡æ•¸æ“š")
            except Exception as e:
                print(f"  âŒ {sym} taker_vol/cvd: {e}")

        print("-" * 60)
        print(f"ğŸ‰ è¡ç”Ÿå“æ•¸æ“šä¸‹è¼‰å®Œæˆï¼å­˜æ”¾ä½ç½®: {derivatives_dir}")


if __name__ == "__main__":
    main()
