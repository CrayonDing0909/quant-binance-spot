#!/usr/bin/env python3
"""
é€²éšé©—è­‰è…³æœ¬

æ•´åˆ Cross-Asset é©—è­‰ + Monte Carlo æ¨¡æ“¬ï¼Œæä¾›å®Œæ•´çš„ç­–ç•¥ç©©å¥æ€§åˆ†æã€‚

ä½¿ç”¨æ–¹å¼:
    python scripts/run_advanced_validation.py --config config/rsi_adx_atr.yaml

åŠŸèƒ½:
    1. Cross-Asset é©—è­‰
       - Leave-One-Asset-Out (LOAO)
       - ç›¸é—œæ€§åˆ†å±¤é©—è­‰
       - å¸‚å ´ç‹€æ…‹é©—è­‰

    2. Monte Carlo æ¨¡æ“¬
       - VaR / CVaR è¨ˆç®—
       - Bootstrap ç¸¾æ•ˆä¿¡è³´å€é–“
       - Drawdown åˆ†å¸ƒåˆ†æ
"""
from __future__ import annotations

import argparse
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd


# ç¢ºä¿å¯ä»¥ import qtrade
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from qtrade.config import load_config

from qtrade.backtest import (
    run_symbol_backtest,
    trade_analysis,
    leave_one_asset_out,
    correlation_stratified_validation,
    market_regime_validation,
    ValidationResultAnalyzer,
    CrossAssetValidationConfig,
)
from qtrade.risk import (
    MonteCarloSimulator,
    MonteCarloConfig,
    BootstrapConfig,
    bootstrap_strategy_ci,
    monte_carlo_var,
    simulate_strategy_outcomes,
)
from qtrade.data.storage import load_klines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ValidationPipelineConfig:
    """é©—è­‰æµç¨‹é…ç½®"""
    # è³‡ç”¢è¨­å®š
    symbols: List[str]
    data_dir: Path
    
    # é©—è­‰é¸é …
    run_loao: bool = True
    run_correlation: bool = True
    run_regime: bool = True
    run_monte_carlo: bool = True
    
    # æ•¸æ“šåˆ†å‰²è¨­å®šï¼ˆå°ˆæ¥­é‡åŒ–å¿…å‚™ï¼‰
    train_ratio: float = 0.6  # è¨“ç·´é›†æ¯”ä¾‹
    val_ratio: float = 0.2    # é©—è­‰é›†æ¯”ä¾‹ï¼ˆç”¨æ–¼é¸æ¨¡å‹ï¼‰
    # test_ratio = 1 - train_ratio - val_ratio = 0.2ï¼ˆæœ€çµ‚é©—è­‰ï¼‰
    use_test_set_only: bool = True  # Monte Carlo åªç”¨ Test Set
    
    # Monte Carlo è¨­å®š
    mc_n_simulations: int = 10000
    mc_confidence_levels: tuple = (0.95, 0.99)
    
    # è¼¸å‡ºè¨­å®š
    output_dir: Optional[Path] = None
    verbose: bool = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•¸æ“šåˆ†å‰²å·¥å…·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_val_test_split(
    df: pd.DataFrame,
    train_ratio: float = 0.6,
    val_ratio: float = 0.2,
) -> Dict[str, pd.DataFrame]:
    """
    æ™‚é–“åºåˆ—çš„ Train/Val/Test åˆ†å‰²
    
    å°ˆæ¥­é‡åŒ–äº¤æ˜“çš„æ¨™æº–åšæ³•ï¼š
    - Train: ç”¨æ–¼åƒæ•¸å„ªåŒ–
    - Val: ç”¨æ–¼é¸æ“‡æœ€ä½³æ¨¡å‹/åƒæ•¸
    - Test: æœ€çµ‚é©—è­‰ï¼ˆåªç¢°ä¸€æ¬¡ï¼ï¼‰
    
    Args:
        df: K ç·šæ•¸æ“š
        train_ratio: è¨“ç·´é›†æ¯”ä¾‹
        val_ratio: é©—è­‰é›†æ¯”ä¾‹
    
    Returns:
        {"train": df, "val": df, "test": df, "periods": {...}}
    """
    n = len(df)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    train_df = df.iloc[:train_end].copy()
    val_df = df.iloc[train_end:val_end].copy()
    test_df = df.iloc[val_end:].copy()
    
    return {
        "train": train_df,
        "val": val_df,
        "test": test_df,
        "periods": {
            "train": f"{train_df.index[0].strftime('%Y-%m-%d')} â†’ {train_df.index[-1].strftime('%Y-%m-%d')}" if len(train_df) > 0 else "N/A",
            "val": f"{val_df.index[0].strftime('%Y-%m-%d')} â†’ {val_df.index[-1].strftime('%Y-%m-%d')}" if len(val_df) > 0 else "N/A",
            "test": f"{test_df.index[0].strftime('%Y-%m-%d')} â†’ {test_df.index[-1].strftime('%Y-%m-%d')}" if len(test_df) > 0 else "N/A",
        },
        "sizes": {
            "train": len(train_df),
            "val": len(val_df),
            "test": len(test_df),
        }
    }


def save_split_data(
    split_data: Dict[str, pd.DataFrame],
    symbol: str,
    data_dir: Path,
) -> Dict[str, Path]:
    """
    ä¿å­˜åˆ†å‰²å¾Œçš„æ•¸æ“šåˆ°è‡¨æ™‚æ–‡ä»¶
    
    Returns:
        {"train": Path, "val": Path, "test": Path}
    """
    paths = {}
    for split_name in ["train", "val", "test"]:
        df = split_data[split_name]
        if len(df) > 0:
            path = data_dir / f"_temp_{symbol}_{split_name}.parquet"
            df.to_parquet(path)
            paths[split_name] = path
    return paths


def cleanup_split_data(paths: Dict[str, Path]) -> None:
    """æ¸…ç†è‡¨æ™‚æ–‡ä»¶"""
    for path in paths.values():
        if path.exists():
            path.unlink()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å ±å‘Šç”Ÿæˆå™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ValidationReporter:
    """é©—è­‰çµæœå ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
    
    def print_header(self, title: str, char: str = "â•", width: int = 60):
        """æ‰“å°å€å¡Šæ¨™é¡Œ"""
        if self.verbose:
            print(f"\n{char * width}")
            print(f"  {title}")
            print(f"{char * width}")
    
    def print_subheader(self, title: str):
        """æ‰“å°å­æ¨™é¡Œ"""
        if self.verbose:
            print(f"\nâ–¶ {title}")
            print("-" * 50)
    
    def print_metric(self, name: str, value, format_spec: str = ""):
        """æ‰“å°æŒ‡æ¨™"""
        if self.verbose:
            if format_spec:
                print(f"  {name}: {value:{format_spec}}")
            else:
                print(f"  {name}: {value}")
    
    def print_table(self, df: pd.DataFrame, max_rows: int = 20):
        """æ‰“å°è¡¨æ ¼"""
        if self.verbose:
            print(df.head(max_rows).to_string())
    
    def print_warning(self, message: str):
        """æ‰“å°è­¦å‘Š"""
        if self.verbose:
            print(f"  âš ï¸  {message}")
    
    def print_success(self, message: str):
        """æ‰“å°æˆåŠŸè¨Šæ¯"""
        if self.verbose:
            print(f"  âœ… {message}")
    
    def print_error(self, message: str):
        """æ‰“å°éŒ¯èª¤"""
        if self.verbose:
            print(f"  âŒ {message}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é©—è­‰æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ValidationPipeline:
    """
    é©—è­‰æµç¨‹ç®¡ç†å™¨
    
    æ•´åˆæ‰€æœ‰é©—è­‰æ­¥é©Ÿï¼Œæä¾›çµ±ä¸€çš„åŸ·è¡Œä»‹é¢ã€‚
    """
    
    def __init__(
        self,
        pipeline_config: ValidationPipelineConfig,
        strategy_config: dict,
        backtest_func=None,
        data_loader=None,
    ):
        self.pipeline_config = pipeline_config
        self.strategy_config = strategy_config
        self.reporter = ValidationReporter(pipeline_config.verbose)
        
        # è‡ªå®šç¾©å‡½æ•¸ï¼ˆç”¨æ–¼æ³¨å…¥å°ˆæ¡ˆç‰¹å®šçš„å›æ¸¬é‚è¼¯ï¼‰
        self._backtest_func = backtest_func
        self._data_loader = data_loader
        
        # å»ºç«‹æ•¸æ“šè·¯å¾‘æ˜ å°„
        # æ”¯æ´å…©ç¨®è·¯å¾‘æ ¼å¼ï¼š
        # 1. data/binance/spot/1h/BTCUSDT.parquet (å°ˆæ¡ˆæ¨™æº–æ ¼å¼)
        # 2. data/BTCUSDT_1h.parquet (ç°¡åŒ–æ ¼å¼)
        self.data_paths = {}
        for s in pipeline_config.symbols:
            # å„ªå…ˆä½¿ç”¨å°ˆæ¡ˆæ¨™æº–æ ¼å¼
            standard_path = pipeline_config.data_dir / f"{s}.parquet"
            simple_path = pipeline_config.data_dir / f"{s}_1h.parquet"
            
            if standard_path.exists():
                self.data_paths[s] = standard_path
            elif simple_path.exists():
                self.data_paths[s] = simple_path
            else:
                # è¨˜éŒ„é æœŸè·¯å¾‘ï¼Œå¾ŒçºŒæœƒå ±å‘Šæ‰¾ä¸åˆ°
                self.data_paths[s] = standard_path
        
        # éæ¿¾å­˜åœ¨çš„è³‡ç”¢
        self.available_symbols = [
            s for s in pipeline_config.symbols
            if self.data_paths[s].exists()
        ]
        
        if len(self.available_symbols) < len(pipeline_config.symbols):
            missing = set(pipeline_config.symbols) - set(self.available_symbols)
            self.reporter.print_warning(f"æ‰¾ä¸åˆ°æ•¸æ“š: {missing}")
    
    def run(self) -> dict:
        """
        åŸ·è¡Œå®Œæ•´é©—è­‰æµç¨‹
        
        Returns:
            åŒ…å«æ‰€æœ‰é©—è­‰çµæœçš„å­—å…¸
        """
        results = {}
        
        self.reporter.print_header("ğŸ”¬ é€²éšç­–ç•¥é©—è­‰", "â•")
        self.reporter.print_metric("ç­–ç•¥", self.strategy_config.get("strategy_name", "unknown"))
        self.reporter.print_metric("è³‡ç”¢æ•¸é‡", len(self.available_symbols))
        self.reporter.print_metric("å¯ç”¨è³‡ç”¢", self.available_symbols)
        
        # 1. Cross-Asset é©—è­‰
        if self.pipeline_config.run_loao:
            results["loao"] = self._run_loao_validation()
        
        if self.pipeline_config.run_correlation:
            results["correlation"] = self._run_correlation_validation()
        
        if self.pipeline_config.run_regime:
            results["regime"] = self._run_regime_validation()
        
        # 2. Monte Carlo æ¨¡æ“¬
        if self.pipeline_config.run_monte_carlo:
            results["monte_carlo"] = self._run_monte_carlo()
        
        # 3. ç¸½çµå ±å‘Š
        self._print_summary(results)
        
        return results
    
    def _run_loao_validation(self) -> dict:
        """åŸ·è¡Œ Leave-One-Asset-Out é©—è­‰"""
        self.reporter.print_header("ğŸ“Š Leave-One-Asset-Out é©—è­‰", "â”€")
        
        if len(self.available_symbols) < 3:
            self.reporter.print_warning("è³‡ç”¢æ•¸é‡ä¸è¶³ï¼ˆéœ€è‡³å°‘ 3 å€‹ï¼‰")
            return {}
        
        try:
            result = leave_one_asset_out(
                symbols=self.available_symbols,
                data_paths=self.data_paths,
                cfg=self.strategy_config,
                backtest_func=self._backtest_func,
                data_loader=self._data_loader,
                parallel=True,
            )
            
            # æ‰“å°çµæœ
            self.reporter.print_subheader("é©—è­‰çµæœ")
            self.reporter.print_table(result.to_dataframe())
            
            self.reporter.print_subheader("æ‘˜è¦")
            summary = ValidationResultAnalyzer.summarize(result)
            self.reporter.print_metric("ç©©å¥æ€§ç­‰ç´š", result.robustness_level.value)
            self.reporter.print_metric("å¹³å‡ç¸¾æ•ˆè¡°é€€", f"{result.avg_sharpe_degradation:.1%}")
            self.reporter.print_metric("è¡°é€€æ¨™æº–å·®", f"{result.std_sharpe_degradation:.2f}")
            
            if result.overfitted_assets:
                self.reporter.print_warning(f"å¯èƒ½éæ“¬åˆ: {list(result.overfitted_assets)}")
            
            # å»ºè­°
            recommendations = ValidationResultAnalyzer.get_recommendations(result)
            self.reporter.print_subheader("å»ºè­°")
            for rec in recommendations:
                print(f"  â€¢ {rec}")
            
            return {"result": result, "summary": summary}
        
        except Exception as e:
            self.reporter.print_error(f"LOAO é©—è­‰å¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _run_correlation_validation(self) -> dict:
        """åŸ·è¡Œç›¸é—œæ€§åˆ†å±¤é©—è­‰"""
        self.reporter.print_header("ğŸ”— ç›¸é—œæ€§åˆ†å±¤é©—è­‰", "â”€")
        
        if len(self.available_symbols) < 4:
            self.reporter.print_warning("è³‡ç”¢æ•¸é‡ä¸è¶³ï¼ˆéœ€è‡³å°‘ 4 å€‹ï¼‰")
            return {}
        
        try:
            result = correlation_stratified_validation(
                symbols=self.available_symbols,
                data_paths=self.data_paths,
                cfg=self.strategy_config,
                n_groups=min(3, len(self.available_symbols) // 2),
                backtest_func=self._backtest_func,
                data_loader=self._data_loader,
            )
            
            self.reporter.print_subheader("é©—è­‰çµæœ")
            self.reporter.print_table(result.to_dataframe())
            
            self.reporter.print_metric("ç©©å¥æ€§ç­‰ç´š", result.robustness_level.value)
            
            return {"result": result}
        
        except Exception as e:
            self.reporter.print_error(f"ç›¸é—œæ€§é©—è­‰å¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _run_regime_validation(self) -> dict:
        """åŸ·è¡Œå¸‚å ´ç‹€æ…‹é©—è­‰ï¼ˆä½¿ç”¨ Train/Test åˆ†å‰²ï¼‰"""
        self.reporter.print_header("ğŸ“ˆ å¸‚å ´ç‹€æ…‹é©—è­‰", "â”€")
        
        try:
            # æº–å‚™æ•¸æ“šè·¯å¾‘ï¼ˆä½¿ç”¨ Test Setï¼‰
            temp_paths = {}
            if self.pipeline_config.use_test_set_only:
                self.reporter.print_subheader("æ•¸æ“šåˆ†å‰²")
                for symbol in self.available_symbols:
                    data_path = self.data_paths[symbol]
                    if self._data_loader:
                        full_df = self._data_loader(data_path)
                    else:
                        full_df = load_klines(data_path)
                    
                    split_data = train_val_test_split(
                        full_df,
                        train_ratio=self.pipeline_config.train_ratio,
                        val_ratio=self.pipeline_config.val_ratio,
                    )
                    
                    # ä½¿ç”¨ Test Set
                    test_df = split_data["test"]
                    temp_path = data_path.parent / f"_temp_{symbol}_test.parquet"
                    test_df.to_parquet(temp_path)
                    temp_paths[symbol] = temp_path
                    self.reporter.print_metric(f"{symbol} Test Set", f"{split_data['periods']['test']}")
                
                data_paths_to_use = temp_paths
            else:
                data_paths_to_use = self.data_paths
            
            try:
                results_list, summary_df = market_regime_validation(
                    symbols=self.available_symbols,
                    data_paths=data_paths_to_use,
                    cfg=self.strategy_config,
                    indicator="volatility",
                    backtest_func=self._backtest_func,
                    data_loader=self._data_loader,
                )
            finally:
                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                for path in temp_paths.values():
                    path.unlink(missing_ok=True)
            
            if not summary_df.empty:
                self.reporter.print_subheader("ä¸åŒå¸‚å ´ç‹€æ…‹ä¸‹çš„è¡¨ç¾")
                self.reporter.print_table(summary_df)
                
                # åˆ†æé«˜/ä½æ³¢å‹•æ€§è¡¨ç¾å·®ç•°
                high_vol = summary_df[summary_df["regime"].str.contains("high")]
                low_vol = summary_df[summary_df["regime"].str.contains("low")]
                
                if not high_vol.empty and not low_vol.empty:
                    self.reporter.print_subheader("æ³¢å‹•æ€§ç‹€æ…‹æ¯”è¼ƒ")
                    self.reporter.print_metric(
                        "é«˜æ³¢å‹• Sharpe",
                        f"{high_vol['sharpe'].mean():.2f}"
                    )
                    self.reporter.print_metric(
                        "ä½æ³¢å‹• Sharpe",
                        f"{low_vol['sharpe'].mean():.2f}"
                    )
            
            return {"results": results_list, "summary": summary_df}
        
        except Exception as e:
            self.reporter.print_error(f"å¸‚å ´ç‹€æ…‹é©—è­‰å¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _run_monte_carlo(self) -> dict:
        """åŸ·è¡Œ Monte Carlo æ¨¡æ“¬ï¼ˆä½¿ç”¨ Train/Test åˆ†å‰²ï¼‰"""
        self.reporter.print_header("ğŸ² Monte Carlo æ¨¡æ“¬", "â”€")
        
        # é¸æ“‡ç¬¬ä¸€å€‹å¯ç”¨è³‡ç”¢é€²è¡Œæ¨¡æ“¬
        if not self.available_symbols:
            self.reporter.print_warning("ç„¡å¯ç”¨è³‡ç”¢")
            return {}
        
        symbol = self.available_symbols[0]
        data_path = self.data_paths[symbol]
        
        try:
            # è¼‰å…¥åŸå§‹æ•¸æ“šä¸¦åˆ†å‰²
            if self._data_loader:
                full_df = self._data_loader(data_path)
            else:
                full_df = load_klines(data_path)
            
            # æ•¸æ“šåˆ†å‰²
            split_data = train_val_test_split(
                full_df,
                train_ratio=self.pipeline_config.train_ratio,
                val_ratio=self.pipeline_config.val_ratio,
            )
            
            self.reporter.print_subheader(f"æ•¸æ“šåˆ†å‰² ({symbol})")
            self.reporter.print_metric("Train", f"{split_data['periods']['train']} ({split_data['sizes']['train']} bars)")
            self.reporter.print_metric("Val", f"{split_data['periods']['val']} ({split_data['sizes']['val']} bars)")
            self.reporter.print_metric("Test", f"{split_data['periods']['test']} ({split_data['sizes']['test']} bars)")
            
            # æ±ºå®šä½¿ç”¨å“ªå€‹æ•¸æ“šé›†
            if self.pipeline_config.use_test_set_only:
                eval_df = split_data["test"]
                eval_name = "Test Set (Out-of-Sample)"
            else:
                eval_df = full_df
                eval_name = "Full Data (In-Sample)"
            
            self.reporter.print_subheader(f"åˆ†æè³‡ç”¢: {symbol} - {eval_name}")
            
            if len(eval_df) < 100:
                self.reporter.print_warning(f"æ•¸æ“šé‡ä¸è¶³ï¼ˆ{len(eval_df)} barsï¼‰ï¼Œè·³é")
                return {}
            
            # ä¿å­˜è‡¨æ™‚æ•¸æ“š
            temp_path = data_path.parent / f"_temp_{symbol}_eval.parquet"
            eval_df.to_parquet(temp_path)
            
            try:
                # åŸ·è¡Œå›æ¸¬
                if self._backtest_func:
                    res = self._backtest_func(
                        symbol,
                        temp_path,
                        self.strategy_config,
                        self.strategy_config.get("strategy_name"),
                    )
                else:
                    res = run_symbol_backtest(
                        symbol,
                        temp_path,
                        self.strategy_config,
                        self.strategy_config.get("strategy_name"),
                    )
            finally:
                temp_path.unlink(missing_ok=True)
            
            pf = res["pf"]
            
            # è¨ˆç®—æ—¥æ”¶ç›Šç‡ï¼ˆç›¸å®¹è¼ƒæ–°ç‰ˆæœ¬çš„ pandasï¼‰
            try:
                daily_returns = pf.daily_returns()
            except TypeError:
                # pandas 2.0+ ç§»é™¤äº† resample çš„ axis åƒæ•¸
                # ä½¿ç”¨æ›¿ä»£æ–¹å¼è¨ˆç®—
                equity = pf.value()
                daily_returns = equity.resample('D').last().pct_change().dropna()
            
            # å–å¾—äº¤æ˜“æ•¸æ“š
            trades_df = trade_analysis(pf)
            
            results = {}
            
            # 1. Monte Carlo VaR
            self.reporter.print_subheader("VaR / CVaR åˆ†æ")
            
            mc_config = MonteCarloConfig(
                n_simulations=self.pipeline_config.mc_n_simulations,
                confidence_levels=self.pipeline_config.mc_confidence_levels,
            )
            simulator = MonteCarloSimulator(mc_config=mc_config)
            
            var_result = simulator.calculate_var(
                daily_returns,
                portfolio_value=self.strategy_config["initial_cash"],
            )
            
            for conf in self.pipeline_config.mc_confidence_levels:
                self.reporter.print_metric(
                    f"{conf*100:.0f}% VaR",
                    f"${var_result.get_var(conf):,.0f}"
                )
                self.reporter.print_metric(
                    f"{conf*100:.0f}% CVaR",
                    f"${var_result.get_cvar(conf):,.0f}"
                )
            
            results["var"] = var_result
            
            # 2. Bootstrap ç¸¾æ•ˆä¿¡è³´å€é–“
            if not trades_df.empty and "Return [%]" in trades_df.columns:
                trade_returns = trades_df["Return [%]"] / 100
                
                self.reporter.print_subheader("Bootstrap ç¸¾æ•ˆä¿¡è³´å€é–“ (95%)")
                
                ci = bootstrap_strategy_ci(
                    trade_returns,
                    confidence=0.95,
                    n_simulations=self.pipeline_config.mc_n_simulations,
                )
                
                for metric, (lower, median, upper) in ci.items():
                    self.reporter.print_metric(
                        metric,
                        f"[{lower:.2%}, {median:.2%}, {upper:.2%}]"
                    )
                
                results["bootstrap_ci"] = ci
            
            # 3. ç­–ç•¥çµæœåˆ†å¸ƒ
            self.reporter.print_subheader("ç­–ç•¥çµæœåˆ†å¸ƒæ¨¡æ“¬")
            
            outcomes = simulate_strategy_outcomes(
                daily_returns,
                n_simulations=self.pipeline_config.mc_n_simulations,
            )
            
            self.reporter.print_metric(
                "æœŸæœ›æœ€çµ‚æ”¶ç›Š",
                f"{outcomes['percentiles']['final_return'][50]:.1%}"
            )
            self.reporter.print_metric(
                "95% CI",
                f"[{outcomes['percentiles']['final_return'][5]:.1%}, "
                f"{outcomes['percentiles']['final_return'][95]:.1%}]"
            )
            self.reporter.print_metric(
                "è™§ææ©Ÿç‡",
                f"{outcomes['probability_of_loss']:.1%}"
            )
            self.reporter.print_metric(
                ">20% Drawdown æ©Ÿç‡",
                f"{outcomes['probability_of_drawdown_gt_20']:.1%}"
            )
            
            results["outcomes"] = outcomes
            
            return results
        
        except Exception as e:
            self.reporter.print_error(f"Monte Carlo æ¨¡æ“¬å¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _print_summary(self, results: dict):
        """æ‰“å°ç¸½çµå ±å‘Š"""
        self.reporter.print_header("ğŸ“‹ é©—è­‰ç¸½çµ", "â•")
        
        # ç©©å¥æ€§è©•ä¼°
        robust_checks = []
        
        if "loao" in results and "result" in results["loao"]:
            loao_result = results["loao"]["result"]
            is_robust = ValidationResultAnalyzer.is_strategy_robust(loao_result)
            robust_checks.append(("Cross-Asset", is_robust))
        
        if "monte_carlo" in results and "outcomes" in results["monte_carlo"]:
            outcomes = results["monte_carlo"]["outcomes"]
            is_safe = outcomes["probability_of_loss"] < 0.5
            robust_checks.append(("Monte Carlo", is_safe))
        
        self.reporter.print_subheader("ç©©å¥æ€§æª¢æŸ¥")
        for check_name, passed in robust_checks:
            status = "âœ… é€šé" if passed else "âŒ æœªé€šé"
            print(f"  {check_name}: {status}")
        
        # ç¸½é«”è©•ä¼°
        all_passed = all(passed for _, passed in robust_checks)
        
        self.reporter.print_subheader("ç¸½é«”è©•ä¼°")
        if all_passed:
            self.reporter.print_success("ç­–ç•¥é€šéæ‰€æœ‰ç©©å¥æ€§æª¢æŸ¥ï¼Œå¯é€²è¡Œä¸‹ä¸€æ­¥æ¸¬è©¦")
        else:
            self.reporter.print_warning("ç­–ç•¥æœªé€šééƒ¨åˆ†æª¢æŸ¥ï¼Œå»ºè­°é€²ä¸€æ­¥å„ªåŒ–")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI ä»‹é¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_args():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(
        description="é€²éšç­–ç•¥é©—è­‰ï¼šCross-Asset é©—è­‰ + Monte Carlo æ¨¡æ“¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
    # ä½¿ç”¨é è¨­é…ç½®
    python scripts/run_advanced_validation.py --config config/rsi_adx_atr.yaml

    # æŒ‡å®šè³‡ç”¢
    python scripts/run_advanced_validation.py --config config/rsi_adx_atr.yaml \\
        --symbols BTCUSDT ETHUSDT BNBUSDT SOLUSDT ADAUSDT

    # åªåŸ·è¡Œ Monte Carlo æ¨¡æ“¬
    python scripts/run_advanced_validation.py --config config/rsi_adx_atr.yaml \\
        --no-loao --no-correlation --no-regime
        """,
    )
    
    parser.add_argument(
        "--config",
        type=Path,
        required=True,
        help="ç­–ç•¥é…ç½®æª”æ¡ˆè·¯å¾‘",
    )
    parser.add_argument(
        "--symbols",
        nargs="+",
        default=["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT", "ADAUSDT"],
        help="è¦é©—è­‰çš„è³‡ç”¢åˆ—è¡¨",
    )
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("data/binance/spot/1h"),
        help="æ•¸æ“šç›®éŒ„è·¯å¾‘ï¼ˆé»˜èª: data/binance/spot/1hï¼‰",
    )
    parser.add_argument(
        "--no-loao",
        action="store_true",
        help="è·³é Leave-One-Asset-Out é©—è­‰",
    )
    parser.add_argument(
        "--no-correlation",
        action="store_true",
        help="è·³éç›¸é—œæ€§åˆ†å±¤é©—è­‰",
    )
    parser.add_argument(
        "--no-regime",
        action="store_true",
        help="è·³éå¸‚å ´ç‹€æ…‹é©—è­‰",
    )
    parser.add_argument(
        "--no-monte-carlo",
        action="store_true",
        help="è·³é Monte Carlo æ¨¡æ“¬",
    )
    parser.add_argument(
        "--n-simulations",
        type=int,
        default=10000,
        help="Monte Carlo æ¨¡æ“¬æ¬¡æ•¸",
    )
    parser.add_argument(
        "--train-ratio",
        type=float,
        default=0.6,
        help="è¨“ç·´é›†æ¯”ä¾‹ï¼ˆé»˜èª: 0.6ï¼‰",
    )
    parser.add_argument(
        "--val-ratio",
        type=float,
        default=0.2,
        help="é©—è­‰é›†æ¯”ä¾‹ï¼ˆé»˜èª: 0.2ï¼ŒTest = 1 - train - valï¼‰",
    )
    parser.add_argument(
        "--use-full-data",
        action="store_true",
        help="ä½¿ç”¨å…¨éƒ¨æ•¸æ“šï¼ˆä¸åˆ†å‰²ï¼Œåƒ…ç”¨æ–¼èª¿è©¦ï¼‰",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="å®‰éœæ¨¡å¼ï¼ˆæ¸›å°‘è¼¸å‡ºï¼‰",
    )
    
    return parser.parse_args()


def build_backtest_config(cfg, symbol: str) -> dict:
    """
    å°‡å°ˆæ¡ˆé…ç½®è½‰æ›ç‚ºå›æ¸¬å‡½æ•¸æœŸæœ›çš„æ ¼å¼
    
    Args:
        cfg: load_config() è¿”å›çš„é…ç½®ç‰©ä»¶
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ
    
    Returns:
        å›æ¸¬é…ç½®å­—å…¸
    """
    return {
        "initial_cash": cfg.backtest.initial_cash,
        "fee_bps": cfg.backtest.fee_bps,
        "slippage_bps": cfg.backtest.slippage_bps,
        "strategy_params": cfg.strategy.get_params(symbol),
        "strategy_name": cfg.strategy.name,
        "validate_data": cfg.backtest.validate_data,
        "clean_data_before": cfg.backtest.clean_data,
        "interval": cfg.market.interval,
    }


def main():
    """ä¸»ç¨‹å¼"""
    args = parse_args()
    
    # è¼‰å…¥ç­–ç•¥é…ç½®ï¼ˆä½¿ç”¨å°ˆæ¡ˆçš„ load_configï¼‰
    if not args.config.exists():
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æª”æ¡ˆ: {args.config}")
        sys.exit(1)
    
    cfg = load_config(str(args.config))
    
    # ä½¿ç”¨é…ç½®æª”æ¡ˆä¸­çš„äº¤æ˜“å°ï¼ˆå¦‚æœæ²’æœ‰æŒ‡å®šï¼‰
    symbols = args.symbols
    if symbols == ["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT", "ADAUSDT"]:
        # ä½¿ç”¨é è¨­å€¼ï¼Œå˜—è©¦ç”¨é…ç½®æª”æ¡ˆä¸­çš„äº¤æ˜“å°
        symbols = cfg.market.symbols
    
    # ç¢ºå®šæ•¸æ“šç›®éŒ„
    data_dir = args.data_dir
    if data_dir == Path("data/binance/spot/1h"):
        # ä½¿ç”¨é è¨­å€¼ï¼Œæ ¹æ“šé…ç½®å‹•æ…‹è¨­å®š
        data_dir = cfg.data_dir / "binance" / "spot" / cfg.market.interval
    
    # å»ºç«‹ç¬¬ä¸€å€‹äº¤æ˜“å°çš„å›æ¸¬é…ç½®ï¼ˆç”¨æ–¼é¡¯ç¤ºç­–ç•¥åç¨±ç­‰ï¼‰
    first_symbol = symbols[0] if symbols else "BTCUSDT"
    strategy_config = build_backtest_config(cfg, first_symbol)
    
    # å»ºç«‹æµç¨‹é…ç½®
    pipeline_config = ValidationPipelineConfig(
        symbols=symbols,
        data_dir=data_dir,
        run_loao=not args.no_loao,
        run_correlation=not args.no_correlation,
        run_regime=not args.no_regime,
        run_monte_carlo=not args.no_monte_carlo,
        train_ratio=args.train_ratio,
        val_ratio=args.val_ratio,
        use_test_set_only=not args.use_full_data,  # é è¨­ä½¿ç”¨ Test Set
        mc_n_simulations=args.n_simulations,
        verbose=not args.quiet,
    )
    
    # å»ºç«‹è‡ªå®šç¾©å›æ¸¬å‡½æ•¸ï¼Œç‚ºæ¯å€‹äº¤æ˜“å°ä½¿ç”¨æ­£ç¢ºçš„åƒæ•¸
    def custom_backtest_func(symbol: str, data_path: Path, bt_cfg: dict, strategy_name=None):
        """ç‚ºæ¯å€‹äº¤æ˜“å°ä½¿ç”¨æ­£ç¢ºçš„åƒæ•¸è¦†å¯«"""
        # ä½¿ç”¨è©²äº¤æ˜“å°çš„å°ˆå±¬åƒæ•¸
        symbol_cfg = build_backtest_config(cfg, symbol)
        return run_symbol_backtest(symbol, data_path, symbol_cfg, symbol_cfg["strategy_name"])
    
    # åŸ·è¡Œé©—è­‰ï¼ˆä½¿ç”¨è‡ªå®šç¾©å›æ¸¬å‡½æ•¸ï¼‰
    from qtrade.data.storage import load_klines
    
    pipeline = ValidationPipeline(
        pipeline_config,
        strategy_config,
        backtest_func=custom_backtest_func,
        data_loader=load_klines,
    )
    
    results = pipeline.run()
    
    print("\nâœ… é©—è­‰å®Œæˆï¼")


if __name__ == "__main__":
    main()
